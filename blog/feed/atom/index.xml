<?xml version="1.0" encoding="UTF-8"?>
<feed
  xmlns="http://www.w3.org/2005/Atom"
  xmlns:thr="http://purl.org/syndication/thread/1.0"
  xml:lang="en"
   >
  <title type="text">Gregory Szorc's Digital Home</title>
  <subtitle type="text">Rambling on</subtitle>

  <updated>2014-07-25T03:22:13Z</updated>
  <generator uri="http://blogofile.com/">Blogofile</generator>

  <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog" />
  <id>http://gregoryszorc.com/blog/feed/atom/</id>
  <link rel="self" type="application/atom+xml" href="http://gregoryszorc.com/blog/feed/atom/" />
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Repository-Centric Development]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/07/24/repository-centric-development" />
    <id>http://gregoryszorc.com/blog/2014/07/24/repository-centric-development</id>
    <updated>2014-07-24T20:23:00Z</updated>
    <published>2014-07-24T20:23:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Git" />
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Repository-Centric Development]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/07/24/repository-centric-development"><![CDATA[<p>I was editing a wiki page yesterday and I think I coined a new term
which I'd like to enter the common nomenclature: <em>repository-centric
development</em>. The term refers to development/version control
workflows that place repositories - not patches - first.</p>
<p>When collaborating on version controlled code with modern tools like
Git and Mercurial, you essentially have two choices on how to
share version control data: patches or repositories.</p>
<p>Patches have been around since the dawn of version control. Everyone
knows how they work: your version control system has a copy of
the canonical data and it can export a view of a specific change
into what's called a patch. A patch is essentially a diff with
extra metadata.</p>
<p>When distributed version control systems came along, they brought
with them an alternative to patch-centric development:
repository-centric development. You could still exchange patches if you
wanted, but distributed version control allowed you to <em>pull</em> changes
directly from multiple <em>repositories</em>. You weren't limited to a single
master server (that's what the <em>distributed</em> in <em>distributed version
control</em> means). You also didn't have to go through an intermediate
transport such as email to exchange patches: you communicate directly
with a peer repository instance.</p>
<p>Repository-centric development eliminates the <em>middle man</em> required
for patch exchange: instead of exchanging derived data, you exchange
the actual data, speaking the repository's native language.</p>
<p>One advantage of repository-centric development is it eliminates the
problem of patch non-uniformity. Patches come in many different flavors.
You have plain diffs. You have diffs with metadata. You have Git style
metadata. You have Mercurial style metadata. You can produce patches
with various lines of context in the diff. There are different methods
for handling binary content. There are different ways to express
file adds, removals, and renames. It's all a hot mess. Any system
that consumes patches needs to deal with the non-uniformity. Do you
think this isn't a problem in the real world? Think again. If you are
involved with an open source project that collects patches via email
or by uploading patches to a bug tracker, have you ever seen someone
accidentally upload a patch in the wrong format? That's patch
non-uniformity. New contributors to Firefox do this all the time. I
also see it in the Mercurial project. With repository-centric
development, patches never enter the picture, so patch non-uniformity
is a non-issue. (Don't confuse the superficial formatting of patches
with the content, such as an incorrect commit message format.)</p>
<p>Another advantage of repository-centric development is it makes the
act of exchanging data easier. Just have two repositories talk to
each other. This used to be difficult, but hosting services like
GitHub and Bitbucket make this easy. Contrast with patches, which
require hooking your version control tool up to wherever those patches
are located. The Linux Kernel, like so many other projects,
<a href="https://www.kernel.org/doc/Documentation/SubmittingPatches">uses email for contributing changes</a>.
So now Git, Mercurial, etc all fulfill Zawinski's law. This means your
version control tool is talking to your inbox to send and receive code.
Firefox development uses Bugzilla to hold patches as attachments. So now your
version control tool needs to talk to your issue tracker. (Not the worst
idea in the world I will concede.) While, yes, the tools around using
email or uploading patches to issue trackers or whatever else you are
using to exchange patches exist and can work pretty well, the grim
reality is that these tools are all reinventing the wheel of repository
exchange and are solving a problem that has already been solved by
<em>git push</em>, <em>git fetch</em>, <em>hg pull</em>, <em>hg push</em>, etc. Personally, I would
rather <em>hg push</em> to a remote and have tools like issue trackers and
mailing lists pull directly from repositories. At least that way they
have a direct line into the source of truth and are guaranteed a
consistent output format.</p>
<p>It is a fair criticism to say that not everyone can host a server or
that permissions and authorization are hard. Although I think concerns
about impact are overblown. If you are a small project, just create a
GitHub or Bitbucket account. If you are a larger project, realize that
people time is one of your largest expenses and invest in tools like
proper and efficient repository hosting (often this can be GitHub) to
reduce this waste and keep your developers happier and more efficient.</p>
<p>One of the clearest examples of repository-centric development is
GitHub. There are no patches in GitHub. Instead, you <em>git push</em>
and <em>git fetch</em>. Want to apply someone else's work? Just add a remote
and <em>git fetch</em>! Contrast with first locating patches, hooking up
Git to consume them (this part was always confusing to me - do you
need to retroactively have them sent to your email inbox so you can
import them from there), and finally actually importing them. Just
give me a URL to a repository already. But the benefits of
repository-centric development with GitHub don't stop at pushing and
pulling. GitHub has built code review functionality into pushes. They
call these <em>pull requests</em>. While I have significant issues with
GitHub's implemention of pull requests (I need to blog about those some
day), I can't deny the utility of the repository-centric workflow and
all the benefits around it. Once you switch to GitHub and its
repository-centric workflow, you more clearly see how lacking
patch-centric development is and quickly lose your desire to go back
to the 1990's state-of-the-art methods for software development.</p>
<p>I hope you now know what repository-centric development is and will join
me in championing it over patch-based development.</p>
<p>Mozillians reading this will be very happy to learn that work is under
way to shift Firefox's development workflow to a more repository-centric
world. Stay tuned.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Updates to firefoxtree Mercurial extension]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/07/16/updates-to-firefoxtree-mercurial-extension" />
    <id>http://gregoryszorc.com/blog/2014/07/16/updates-to-firefoxtree-mercurial-extension</id>
    <updated>2014-07-16T19:55:00Z</updated>
    <published>2014-07-16T19:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Updates to firefoxtree Mercurial extension]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/07/16/updates-to-firefoxtree-mercurial-extension"><![CDATA[<p>My <a href="/blog/2014/06/23/please-stop-using-mq/">Please Stop Using MQ</a> post,
has been generating a lot of interest for bookmark-based workflows at
Mozilla. To make adoption easier, I
<a href="/blog/2014/06/30/track-firefox-repositories-with-local-only-mercurial-tags/">quickly authored</a>
an <a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/default/hgext/firefoxtree/__init__.py">extension</a>
to add <em>remote refs</em> of Firefox repositories to Mercurial.</p>
<p>There was still a bit of confusion and gripes about workflows that I
thought it would be best to update the extension to make things more
pleasant.</p>
<h2>Automatic tree names</h2>
<p>People wanted an ability to easy pull/aggregate the various Firefox
trees without additional configuration to an hgrc file.</p>
<p>With <em>firefoxtree</em>, you can now <em>hg pull central</em> or <em>hg pull inbound</em>
or <em>hg pull aurora</em> and it just works.</p>
<p>Pushing with aliases doesn't yet work. It is slightly harder to do in
the Mercurial API. I have a solution, but I'm validating some code paths
to ensure it is safe. This feature will likely appear soon.</p>
<h2>fxheads commands</h2>
<p>Once people adopted unified repositories with heads from multiple
repositories, they asked how they could quickly identify the heads of
the pulled Firefox repositories.</p>
<p><em>firefoxtree</em> now provides a <em>hg fxheads</em> command that prints a
concise output of the commits constituting the heads of the Firefox
repos. e.g.</p>
<div class="pygments_murphy"><pre>$ hg fxheads
224969:0ec0b9ac39f0 aurora (sort of) bug 898554 - raise expected hazard count for b2g to 4 until they are fixed, a=bustage+hazbuild-only
224290:6befadcaa685 beta Tagging /src/mdauto/build/mozilla-beta 1772e55568e4 with FIREFOX_RELEASE_31_BASE a=release CLOSED TREE
224848:8e8f3ba64655 central Merge inbound to m-c a=merge
225035:ec7f2245280c fx-team fx-team/default Merge m-c to fx-team
224877:63c52b7ddc28 inbound Bug 1039197 - Always build js engine with zlib. r=luke
225044:1560f67f4f93 release release/default tip Automated checkin: version bump for firefox 31.0 release. DONTBUILD CLOSED TREE a=release
</pre></div>

<p>Please note that the output is based upon local-only knowledge: you'll
need to pull to ensure data is current.</p>
<h2>Reject pushing multiple heads</h2>
<p>People were complaining that bookmark-based workflows resulted in
Mercurial trying to push multiple heads to a remote. This complaint
stems from the fact that Mercurial's default push behavior is to find
all commits missing from the remote and push them. This behavior is
extremely frustrating for Firefox development because the Firefox repos
only have a single head and pushing multiple heads will only result in
a server hook rejecting the push (after wasting a lot of time
transferring that commit data).</p>
<p><em>firefoxtree</em> now will refuse to push multiple heads to a known Firefox
repo before any commit data is sent. In other words, we fail fast so
your time is saved.</p>
<p><em>firefoxtree</em> also changes the default behavior of <em>hg push</em> when
pushing to a Firefox repo. If no <em>-r</em> argument is specified, <em>hg push</em>
to a Firefox repo will automatically remap to <em>hg push -r .</em>. In other
words, we attempt to push the working copy's commit by default. This
change establishes sensible default and likely working behavior when
typing just <em>hg push</em>.</p>
<p>I am a bit on the fence about changing the default behavior of <em>hg
push</em>. On one hand, it makes total sense. On the other, silently
changing the default behavior of a built-in command is a little
dangerous. I can easily see this backfiring when people interact with
non-Firefox repos. I encourage people to get in the habit of typing
<em>hg push -r <rev></em> because that's what you should be doing.</p>
<h2>Installing firefoxtree</h2>
<p>Within the next 48 hours, <em>mach mercurial-setup</em> should prompt to
install <em>firefoxtree</em>. Until then, clone
<em>https://hg.mozilla.org/hgcustom/version-control-tools</em> and ensure your
<em>~/.hgrc</em> file has the following:</p>
<pre><code>[extensions]
firefoxtree = /path/to/version-control-tools/hgext/firefoxtree
</code></pre>
<p>You likely already have a copy of version-control-tools
in <em>~/.mozbuild/version-control-tools</em>.</p>
<p>It is completely safe to install <em>firefoxtree</em> globally: the extension
will only modify behavior of repositories that are clones of Firefox
repositories.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Python Packaging Do's and Don'ts]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/07/15/python-packaging-do's-and-don'ts" />
    <id>http://gregoryszorc.com/blog/2014/07/15/python-packaging-do's-and-don'ts</id>
    <updated>2014-07-15T17:20:00Z</updated>
    <published>2014-07-15T17:20:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Python" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Python Packaging Do's and Don'ts]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/07/15/python-packaging-do's-and-don'ts"><![CDATA[<p>Are you someone who casually interacts with Python but don't know the
inner workings of Python? Then this post is for you. Read on to learn
why some things are the way they are and how to avoid making some
common mistakes.</p>
<h2>Always use Virtualenvs</h2>
<p>It is an easy trap to view <a href="https://virtualenv.pypa.io/en/latest/virtualenv.html">virtualenvs</a>
as an obstacle, a distraction towards accomplishing something. People
see me adding virtualenvs to build instructions and they say <em>I don't
use virtualenvs, they aren't necessary, why are you doing that?</em></p>
<p>A virtualenv is effectively an overlay on top of your system Python
install. Creating a virtualenv can be thought of as copying your system
Python environment into a local location. When you modify virtualenvs,
you are modifying an isolated container. Modifying virtualenvs has no
impact on your system Python.</p>
<p>A goal of a virtualenv is to isolate your system/global Python install
from unwanted changes. When you accidentally make a change to a
virtualenv, you can just delete the virtualenv and start over from
scratch. When you accidentally make a change to your system Python, it
can be much, much harder to recover from that.</p>
<p>Another goal of virtualenvs is to allow different versions of packages
to exist. Say you are working on two different projects and each
requires a specific version of Django. With virtualenvs, you install one
version in one virtualenv and a different version in another virtualenv.
Things happily coexist because the virtualenvs are independent.
Contrast with trying to manage both versions of Django in your system
Python installation. Trust me, it's not fun.</p>
<p>Casual Python users may not encounter scenarios where virtualenvs make
their lives better... until they do, at which point they realize their
system Python install is beyond saving. People who eat, breath, and die
Python run into these scenarios all the time. We've learned how bad life
without virtualenvs can be and so we use them everywhere.</p>
<p>Use of virtualenvs is a best practice. Not using virtualenvs will result
in something unexpected happening. It's only a matter of time.</p>
<p>Please use virtualenvs.</p>
<h2>Never use sudo</h2>
<p>Do you use sudo to install a Python package? You are doing it wrong.</p>
<p>If you need to use sudo to install a Python package, that almost
certainly means you are installing a Python package to your
system/global Python install. And this means you are modifying your
system Python instead of isolating it and keeping it pristine.</p>
<p>Instead of using sudo to install packages, create a virtualenv and
install things into the virtualenv. There should never be permissions
issues with virtualenvs - the user that creates a virtualenv has full
realm over it.</p>
<h2>Never modify the system Python environment</h2>
<p>On some systems, such as OS X with Homebrew, you don't need sudo to
install Python packages because the user has write access to the Python
directory (<em>/usr/local</em> in Homebrew).</p>
<p>For the reasons given above, don't muck around with the system Python
environment. Instead, use a virtualenv.</p>
<h2>Beware of the package manager</h2>
<p>Your system's package manager (apt, yum, etc) is likely using root and/or
installing Python packages into the system Python.</p>
<p>For the reasons given above, this is bad. Try to use a virtualenv, if
possible. Try to not use the system package manager for installing
Python packages.</p>
<h2>Use pip for installing packages</h2>
<p>Python packaging has historically been a mess. There are a handful of
tools and APIs for installing Python packages. As a casual Python user,
you only need to know of one of them:
<a href="https://pip.pypa.io/en/latest/">pip</a>.</p>
<p>If someone says <em>install a package</em>, you should be thinking <em>create a
virtualenv, activate a virtualenv, <code>pip install &lt;package&gt;</code></em>. <strong>You
should never run <code>pip install</code> outside of a virtualenv.</strong> (The exception
is to install virtualenv and pip itself, which you almost certainly want
in your system/global Python.)</p>
<p>Running <em>pip install <package></em> will install packages from
<a href="https://pypi.python.org/pypi">PyPI</a>, the Python Packaging Index by
default. It's Python's official package repository.</p>
<p>There are a lot of old and outdated tutorials online about Python
packaging. Beware of bad content. For example, if you see documentation
that says <em>use easy_install</em>, you should be thinking, <em>easy_install is
a legacy package installer that has largely been replaced by pip, I
should use pip instead</em>. When in doubt, consult the
<a href="https://python-packaging-user-guide.readthedocs.org/en/latest/index.html">Python packaging user guide</a>
and do what it recommends.</p>
<h2>Don't trust the Python in your package manager</h2>
<p>The more Python programming you do, the more you learn to not trust the
Python package provided by your system / package manager.</p>
<p>Linux distributions such as Ubuntu that sit on the forward edge of
versions are better than others. But I've run into enough problems with
the OS or package manager maintained Python (especially on OS X), that
I've learned to distrust them.</p>
<p>I use <a href="https://github.com/yyuu/pyenv">pyenv</a> for installing and managing
Python distributions from source. pyenv also installs virtualenv and
pip for me, packages that I believe should be in all Python installs
by default. As a more experienced Python programmer, I find pyenv 
<em>just works</em>.</p>
<p>If you are just a beginner with Python, it is probably safe to ignore
this section. Just know that as soon as something weird happens, start
suspecting your default Python install, especially if you are on OS X.
If you suspect trouble, use something like pyenv to enforce a buffer so
the system can have its Python and you can have yours.</p>
<h2>Recovering from the past</h2>
<p>Now that you know the preferred way to interact with Python, you are
probably thinking <em>oh crap, I've been wrong all these years - how do I
fix it?</em></p>
<p>The goal is to get a Python install <em>somewhere</em> that is as pristine as
possible. You have two approaches here: cleaning your existing Python or
creating a new Python install.</p>
<p>To clean your existing Python, you'll want to purge it of pretty much
all packages not installed by the core Python distribution. The
exception is virtualenv, pip, and setuptools - you almost certainly want
those installed globally. On Homebrew, you can uninstall everything related to
Python and blow away your Python directory, typically
/usr/local/lib/python*. Then, <em>brew install python</em>. On Linux distros,
this is a bit harder, especially since most Linux distros rely on Python
for OS features and thus they may have installed extra packages. You
could try a similar approach on Linux, but I don't think it's worth it.</p>
<p>Cleaning your system Python and attempting to keep it pure are ongoing
tasks that are very difficult to keep up with. All it takes is one
dependency to get pulled in that trashes your system Python. Therefore,
I shy away from this approach.</p>
<p>Instead, I install and run Python from my user directory. I use
<a href="https://github.com/yyuu/pyenv">pyenv</a>. I've also heard great things
about <a href="http://conda.pydata.org/miniconda.html">Miniconda</a>. With either
solution, you get a Python in your home directory that starts clean and
pure. Even better, it is completely independent from your system Python.
So if your package manager does something funky, there is a buffer. And,
if things go wrong with your userland Python install, you can always
nuke it without fear of breaking something in system land. This seems to
be the best of both worlds.</p>
<p>Please note that installing packages in the system Python shouldn't be
evil. When you create virtualenvs, you can - and should - tell
virtualenv to not use the system site-packages (i.e. <em>don't use
non-core packages from the system installation</em>). This is the default
behavior in virtualenv. It should provide an adequate buffer. But from
my experience, things still manage to bleed through. My userland Python
install is extra safety. If something wrong happens, I can only blame
myself.</p>
<h2>Conclusion</h2>
<p>Python's long and complicated history of package management makes it
very easy for you to shoot yourself in the foot. The long list of
outdated tutorials on The Internet make this a near certainty for casual
Python users. Using the guidelines in this post, you can adhere to best
practices that will cut down on surprises and rage and keep your Python
running smoothly.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Update Bugzilla Automatically on Push]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/06/30/update-bugzilla-automatically-on-push" />
    <id>http://gregoryszorc.com/blog/2014/06/30/update-bugzilla-automatically-on-push</id>
    <updated>2014-06-30T23:15:00Z</updated>
    <published>2014-06-30T23:15:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Update Bugzilla Automatically on Push]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/06/30/update-bugzilla-automatically-on-push"><![CDATA[<p>Do you manually create Bugzilla comments when you push changes to a
Firefox source repository? Yeah, I do too.</p>
<p>That's always annoyed me.</p>
<p>It is screaming to be automated.</p>
<p>So I automated it.</p>
<p>You can too. From a Firefox source checkout:</p>
<p>$ ./mach mercurial-setup</p>
<p>That should clone the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
repository into <em>~/.mozbuild/version-control-tools</em>.</p>
<p>Then, add the following to your <em>~/.hgrc</em> file:</p>
<div class="pygments_murphy"><pre><span class="k">[extensions]</span>
<span class="na">bzpost</span> <span class="o">=</span> <span class="s">~/.mozbuild/version-control-tools/hgext/bzpost</span>

<span class="k">[bugzilla]</span>
<span class="na">username</span> <span class="o">=</span> <span class="s">me@example.com</span>
<span class="na">password</span> <span class="o">=</span> <span class="s">password</span>
</pre></div>

<p>Now, when you <em>hg push</em> to a Firefox repository, the commit URLs will
get posted to referenced bugs automatically.</p>
<p>Please note that pushing to <em>release</em> trees such as mozilla-central is
not yet supported. In due time.</p>
<p>Please let me know if you run into any issues.</p>
<h2>Estimated Cost Savings</h2>
<p>Assuming the following:</p>
<ul>
<li>It costs Mozilla $200,000 per year per full-time engineer working on
  Firefox (a general rule of thumb for non-senior positions is that your
  true employee cost is 2x your base salary).</li>
<li>Each full-time engineer works 40 hours per week for 46 weeks out of
  the year.</li>
<li>It takes 15 seconds to manually update Bugzilla for each push.</li>
<li>There are 20,000 pushes requiring Bugzilla attention per year.</li>
</ul>
<p>We arrive at the following:</p>
<ul>
<li>Cost per employee per hour worked: $108.70</li>
<li>Total person-time to manually update Bugzilla: ~83 hours</li>
<li>Total cost to manually update Bugzilla after push: $9,058.</li>
</ul>
<p>I was intentionally conservative with all the inputs except time
worked (I think many of us work more than 40 hour weeks).
My estimates also don't take into account the lost productivity
associated with getting mentally derailed by interacting with Bugzilla.
With this in mind, I could very easily justify a total cost at
least 2x-3x higher.</p>
<p>It took me maybe 3 hours to crank this out. I could spend another few
weeks on it full time and Mozilla would still save money (assuming
100% adoption).</p>
<p>I encourage people to run their own cost calculations on other tasks
that can be automated. Inefficiencies multiplied by millions of dollars
(your collective employee cost) result in large piles of money. Not
having tools (even simple ones like this) is equivalent to setting
loads of cash on fire.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Track Firefox Repositories with Local-Only Mercurial Tags]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/06/30/track-firefox-repositories-with-local-only-mercurial-tags" />
    <id>http://gregoryszorc.com/blog/2014/06/30/track-firefox-repositories-with-local-only-mercurial-tags</id>
    <updated>2014-06-30T10:25:00Z</updated>
    <published>2014-06-30T10:25:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Track Firefox Repositories with Local-Only Mercurial Tags]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/06/30/track-firefox-repositories-with-local-only-mercurial-tags"><![CDATA[<p>After reading my recent
<a href="/blog/2014/06/23/please-stop-using-mq/">Please Stop Using MQ</a> post,
a number of people asked me about my development workflow. While I
still owe a full answer to that question, one of the cornerstores
is a unified Mercurial repository. Instead of having separate clones
for mozilla-central, mozilla-inbound, aurora, beta, etc, I have a
single clone with the changesets from all the repositories.</p>
<p>I feel having a unified repository has made me more productive. I no
longer have to waste time shuffling changesets between local clones.
This introduced all kinds of extra cognitive load and manual
processes that slowed me down. I highly encourage others to adopt
unified repositories.</p>
<p>Because the various Firefox repositories don't have unique branches
or bookmarks tracking the various heads, aggregating multiple
repositories introduces a client-side problem of identifying
which head is which. If you merely do a <em>hg pull</em>, you'll get a
bunch of anonymous heads.</p>
<p>To solve this problem, you'll need to employ minor client-side
magic. Previously, I <a href="/2013/07/22/mercurial-extension-for-gecko-development/">recommended</a>
my heavyweight <em>mozext</em> extension.</p>
<p>Today, I'm proud to announce a new, lighter extension:
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/default/hgext/firefoxtree/__init__.py">firefoxtree</a>.
When pulling from a known Firefox repository, this extension will add
a local-only Mercurial tag for that repository. For example,
when pulling mozilla-central, the <em>central</em> tag will be created.</p>
<p>Local-only tags are a Mercurial feature only available to
extensions. A local-only tag is effectively an overlay of tags
that don't get transferred as part of push and pull operations.
They behave like normal tags: you can <em>hg up</em> to them and reference
them elsewhere changeset identifiers are used. They are also read
only: if you update to a tag and then commit, the tag will not
move forward (contrast with branches or bookmarks).</p>
<h2>Example Usage</h2>
<p>Clone <em>https://hg.mozilla.org/hgcustom/version-control-tools</em> and add
the following to your <em>.hg/hgrc</em>:</p>
<pre><code>[extensions]
firefoxtree = /path/to/version-control-tools/hgext/firefoxtree
</code></pre>
<p>To use, simply pull from a Firefox repo:</p>
<div class="pygments_murphy"><pre>$ hg pull https://hg.mozilla.org/mozilla-central

$ hg up central

# Do your development work.

# Time to land.
$ hg pull https://hg.mozilla.org/integration/mozilla-inbound
$ hg rebase -d inbound
$ hg out -r . https://hg.mozilla.org/integration/mozilla-inbound
$ hg push -r .  https://hg.mozilla.org/integration/mozilla-inbound
</pre></div>

<p>Please note that <em>hg push</em> tries to push all local changes on all
heads to a remote by default. When operating a unified repo, you'll
need to use the <em>-r</em> argument to <em>hg push</em> and <em>hg out</em> to limit
what changesets are considered. I most frequently use <em>-r .</em> to limit
changes to the current checked out changeset.</p>
<p>Also note that this extension conflicts with my <em>mozext</em> extension.
I hope to update <em>mozext</em> to make it behave in the same manner. (It
was easier to write a new extension than to update mozext.)</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Please Stop Using MQ]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/06/23/please-stop-using-mq" />
    <id>http://gregoryszorc.com/blog/2014/06/23/please-stop-using-mq</id>
    <updated>2014-06-23T11:50:00Z</updated>
    <published>2014-06-23T11:50:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Please Stop Using MQ]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/06/23/please-stop-using-mq"><![CDATA[<p>Are you a <a href="http://mercurial.selenic.com/">Mercurial</a> user?</p>
<p>Do you use the <a href="http://mercurial.selenic.com/wiki/MqExtension">mq</a>
extension? If so, please don't.</p>
<p>Why, you ask? Good question. The short version is that mq is a
solution spawned from version control techniques that were popular
over a decade ago. We have better tools now. mq is technologically
obsolete.</p>
<p>But if you want to know the full answer, keep reading.</p>
<h2>A history of Mercurial and mq</h2>
<p>The mq extension is just that: an extension to Mercurial's core
capabilities. (Mercurial consists of a core/basic feature set
supplemented by
<a href="http://www.selenic.com/hg/help/extensions">built-in</a> and
<a href="http://mercurial.selenic.com/wiki/UsingExtensions">3rd party</a>
extensions that provide more advanced or lesser used, niche
features.) Modern versions of Mercurial (if you aren't
running version 3.0+, please upgrade ASAP) are significantly
different from the Mercurial that necessitated the existence and
usage of the mq extension.</p>
<p>In the early days of Mercurial (Mercurial was
<a href="http://lkml.iu.edu//hypermail/linux/kernel/0504.2/0670.html">announced</a>
in April 2005), your choices for <em>branching</em> were not spectacular.
Your option in the core of Mercurial was to use Mercurial <em>branches</em>.
Mercurial branches are very heavy beasts. Branches are permanent.
If you change the branch a changeset (Mercurial's term for a commit)
is assciated with, the SHA-1 of that changeset changes. The takeaway
is Mercurial branches aren't very user friendly. That's why modern
versions of Mercurial print a warning when you create one:</p>
<pre><code>$ hg branch my-new-feature
marked working directory as branch my-new-feature
(branches are permanent and global, did you want a bookmark?)
</code></pre>
<p>Branches were and still are a relatively poor user experience
inside Mercurial, especially when compared to Git branches
(comparing Git and Mercurial branches is an apples to oranges
comparison: Mercurial branches are more synonymous with CVS or
Subversion branches). In defense of branches, they are good for
some roles, such as tracking release branches.
(Mozilla's <a href="https://hg.mozilla.org/releases/mozilla-aurora/">aurora</a>,
<a href="https://hg.mozilla.org/releases/mozilla-beta/">beta</a>,
<a href="https://hg.mozilla.org/releases/mozilla-release/">release</a>, etc
Firefox repositories should arguably be modeled as branches
instead of separate repositories.)</p>
<p>Further complicating the usability of branches in early versions
of Mercurial was the lack of commands to rewrite history.
Concepts such as rebasing or reordering patches were not
always available in Mercurial (or if they were there were
significant limitations). Today, this seems like an obvious
shortcoming of a version control system. But keep in mind the
state of version control around 2005-2007. CVS and Subversion
were the big players. Perforce, SourceSafe, TFS, etc were popular
in corporate settings. While I'm sure there were version control
systems at the time that supported rewriting history,
my recollection is that rewriting history did not <em>become a
thing</em> until Git rose in popularity (which I think was around
2008 or 2009). At that time, the concept of mutating past commits
was alien, if not absurd. Why would you want to lose data on what
you've already done? Isn't that the antithesis of a version control
system?! Git - and many of its concepts, including history
rewriting - were perceived as radical. It doesn't matter if they
borrowed the ideas from other tools: Git's newfound popularity
made them common and a new necessity. If you went from Git to
Subversion (or even Mercurial), the superiority of Git's
flexibility was obvious (although the UI was not so great, but
people can - and do - still cope).</p>
<p>It was under this renaissance of modern version control tools
in the late 2000's where mq became popular. But its popularity
was not because of the strength of mq: it was because of its
necessity.</p>
<p>mq was added to Mercurial in February 2006 and released as part of
Mercurial 0.8.1 in April 2006. As far as I can tell, at the time of
mq's release, mq was the only tolerable way to perform history
rewriting in Mercurial (<em>hg qref</em> and <em>hg qpush --move</em> are a
very crude method of history rewriting). Now, you could leverage
multiple Mercurial commands to give the illusion of history
rewriting, but it was very cumbersome. No sane person wanted to
deal with that. So mq was used.</p>
<p>The introduction of the <em>transplant</em> extension in the
Mercurial 0.9.2 release in December 2006 added another history
rewriting facility to Mercurial. The <em>transplant</em> command
effectively copies changesets between branches or heads.</p>
<p>The Mercurial 0.9.5 release in September 2007 introduced the
<em>record</em> extension. The <em>record</em> command provides interactive
and incremental commit support, similar to <em>git add -i</em>.
While <em>record</em> isn't strictly history rewriting, it provides
a very useful functionality for helping to produce separate,
smaller commits from a larger ongoing change.</p>
<p>The release of Mercurial 1.1 in December 2008 was - on paper at
least - an milestone for Mercurial. This release added the
<em>rebase</em> extension.  This introduced the <em>rebase</em> command,
which moves changesets (as opposed to <em>transplant</em>, which merely
copies them). Rebasing allowed you to pull remote changes and
then easily move your local changesets on top of the new changes,
among other things.</p>
<p>An even bigger feature added in Mercurial 1.1 was the <em>bookmarks</em>
extension. <a href="http://mercurial.selenic.com/wiki/Bookmarks">Bookmarks</a>
are Mercurial's lightweigh branches. Instead of permanent
association with a changeset, a bookmark is a movable label
attached to a changeset. They are very similar to Git branches.</p>
<p>The initial bookmarks feature was far from robust. You couldn't
push bookmarks and share them with others until Mercurial 1.6
in June 2010. It's worth noting that bookmarks became part of the
Mercurial core (as opposed to existing in an extension that must
be enabled) in Mercurial 1.8, released in March 2011.</p>
<p>Bookmarks, record, and rebase provided a decent framework for
history editing in Mercurial. But there were still some rough
edges, notably around making it easier to edit history: mq
was still easier to use for doing tasks like reordering patches.</p>
<p>It wasn't until Mercurial 2.2 in May 2012 that Mercurial
gained the ability to easily reorder patches using something
other than mq. It came via the <em>histedit</em> extension, which
provides the <em>histedit</em> command. This command provides a mechanism
to interactively edit history. It is very similar to <em>git rebase
--interactive</em>.</p>
<p>With the introduction of the <em>histedit</em> extension, you could
(finally) perform most of the more advanced repository
interaction workflows that mq allowed without using mq. Continue
reading the next section to learn why not using mq is important.</p>
<p>For Mozillians reading, it's worth noting that the conversion of
the Firefox source repository from CVS to Mercurial
<a href="http://soberbuildengineer.com/blog/2007/04/version-control-system-shootout-redux-redux/">occurred in March 2007</a>.
At that time, Mercurial had <em>mq</em> and <em>transplant</em> for
performing history rewriting. mq was thus the most convenient
method for rewriting history and managing individual patches
(a process Firefox development largely maintains to this day).
Thus, mq effectively became a de facto requirement for developing
Firefox patches. Despite mq being arguably unnecessary since
Mercurial 2.2's release in May 2012, mq is still widely used within
Mozilla. My perception is that most developers continue to use
mq. Furthermore, even new developers are still picking it up
instead of utilizing Mercurial's other commands for managing
changesets. FWIW, I believe many are so turned off by mq or
don't want to learn Mercurial or mq that they do their
day-to-day development in Git and only involve Mercurial
when doing the final push to the canonical Firefox Mercurial
repository.</p>
<p>Now that we learned why mq is popular, let's talk about why it
shouldn't be used any more.</p>
<h2>The hack that is mq</h2>
<p>In terms of architecture, mq is a giant hack: a wart on top of
Mercurial. The goal of every version control system is to track
changes over time. mq actively works against that.</p>
<p>At the core of every Mercurial repository is a <em>store</em> that
contains the repository data. The changesets in the repository
are logically represented as a directed acyclic graph (DAG).
When you run <em>hg commit</em>, <em>hg pull</em>, <em>hg import</em>, or any
command that introduces new changesets, new data is added to
the DAG and written to the store.</p>
<p>One of the most important properties of the store is that it is
supposed to be append-only: once data is added, it is never
removed. This property allows Mercurial to fulfill the <em>contract</em>
of version control systems, which is to keep track of data without
losing anything.</p>
<p>This append-only property is important because it means Mercurial
can know about all of the history for all of time. If you need to
perform a merge, Mercurial knows exactly what came before and thus
the most effective way to perform that merge. (It's worth noting
that merging can be quite complicated. All this extra data helps
do the merge correctly the first time, which means you can spend
your time writing code instead of resolving merge conflicts.)</p>
<p>The <em>"mq is a hack"</em> statement derives from how mq interacts with
Mercurial's store. Your mq <em>patch queue</em> is effectively an overlay
over Mercurial's built-in store that is in an ever-changing state
of partial application. When you <em>hg qpush</em> to apply a patch from
the <em>patch queue</em>, you effectively do an <em>hg import</em> to <em>import</em>
a Mercurial changeset file into the core Mercurial store. That's
mostly fine. But when you <em>hg qpop</em> (unapply a patch from mq), you
are effectively asking Mercurial to delete a changeset and all
data associated with it from the core Mercurial store. In other
words, <em>qpop</em> breaks the ideal append-only property of the
Mercurial store: <em>qpop</em> forces Mercurial to delete data and lose
track of history. This makes Mercurial very sad.</p>
<p>Because you are throwing away repository data, merges become much
harder. This means you spend more of your time dealing with
resolving conflicts. To further complicate that, the mq code paths
for performing merges and conflict resolution aren't as robust as
those used by, say, <em>hg rebase</em> and <em>hg histedit</em>. So if you use mq,
you are pretty much guaranteed a poorer conflict resolution process.
This means you spend more of your time wrestling with tools instead
of, you know, actually doing something productive.</p>
<p>Deleting repository data by unapplying patches via mq also has
negative performance implications. Given a large enough repository
(such as Firefox's - it currently has ~200,000 changesets), these
performance issues can result in severely degraded performance.
An extreme example of this is Mozilla's
<a href="https://hg.mozilla.org/try/">Try repository</a>. The
<a href="http://bke.ro/?p=386">runaway process/CPU issues leading to outages</a>
is due to a
<a href="http://bz.selenic.com/show_bug.cgi?id=4255">known Mercurial issue</a>
dealing with inefficient handling of stores that aren't append-only.
When you use mq, you risk running into the same issues. Although the
performance implication should hopefully be a magnitude or two less
pronounced than what Mozilla's Try repository experiences.</p>
<p>In theory, mq could compensate for deletion of data from Mercurial's
core store by retaining that data itself. But it doesn't. This leads
to yet more reasons why you shouldn't use mq.</p>
<p>mq throws away perfectly fine history data. When you <em>hg qrefresh</em>,
your current patch is overwritten with the new one. The old version
is discared. This actively works against the goal of a version
control system to record history. Have you ever started down a path
and realized a few commits later that you need to throw it away and
backtrack to a few commits back? I do that all the time. If you
<em>qrefresh</em>, tough luck: you've lost your history. If only the
history store was append-only.</p>
<p>(In fairness to mq, the patch queue maintained by mq is itself a
Mercurial repository and can be committed to, preventing history
loss. The <a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/36eb33f9058d/hgext/mqext/README.txt">mqext extension</a>
even provides a mechanism for automatically committing the patch
queue repo during <em>qrefresh</em> and other mutation events. But as we
will see, even with this, mq is not perfect.)</p>
<p>mq also fails to adequately update patches when they are moved
around. Little known fact: mq patches have their parent changeset
encoded in them. If you run <em>hg qpush --exact</em>, Mercurial will apply
the patch against the parent changeset it was actually created
against, as opposed to the current work directory changeset. In
theory, you should never encounter conflicts when
applying patches this way. Because Mercurial's changeset SHA-1s
are dependent on content (like Git), if 23d165967da3 is the
child of d5741ada659d, then there should be absolutely no way
that 23d165967da3 should fail to apply directly to d5741ada659d.
The problem is that mq fails to update the parent changeset when
you push patches on top of a new parent! e.g.</p>
<div class="pygments_murphy"><pre># Let&#39;s create a root commit.
$ echo &#39;foo&#39; &gt; foo
$ hg commit -A -m &#39;initial commit&#39;
adding foo
$ hg log
changeset:   0:23d165967da3
user:        Gregory Szorc &lt;gps@mozilla.com&gt;
date:        Sun Jun 22 13:48:05 2014 -0700
summary:     initial commit
</pre></div>

<p>Notice the changeset of that commit. <em>023d165...</em>.</p>
<p>Now let's create a new mq patch.</p>
<div class="pygments_murphy"><pre>$ echo &#39;patch 1&#39; &gt; foo
$ hg qnew -m &#39;make mq patch 1&#39; p1

# Creating an mq patch creates a file in .hg/patches.
$ cat .hg/patches/p1
# HG changeset patch
# Parent 23d165967da39e5846976eb6ed967f1058827ffa
# User Gregory Szorc &lt;gps@mozilla.com&gt;
make p1

diff --git a/foo b/foo
--- a/foo
+++ b/foo
@@ -1,1 +1,1 @@
-foo
+patch 1
</pre></div>

<p>Notice how the parent is listed as the changeset in Mercurial's core
store.</p>
<p>Now let's pop that patch, create a new commit, and push the old mq
patch.</p>
<div class="pygments_murphy"><pre>$ hg qpop
popping p1
patch queue now empty

$ echo &#39;bar&#39; &gt; bar
$ hg commit -A -m &#39;second commit&#39;
adding bar

$ hg log
changeset:   1:d5741ada659d
tag:         tip
user:        Gregory Szorc &lt;gps@mozilla.com&gt;
date:        Sun Jun 22 13:48:37 2014 -0700
summary:     second commit

changeset:   0:23d165967da3
user:        Gregory Szorc &lt;gps@mozilla.com&gt;
date:        Sun Jun 22 13:48:05 2014 -0700
summary:     initial commit

$ hg qpush
applying p1
now at: p1

$ hg log --graph
@ changeset:   2:64851294d038
| tag:         p1
| tag:         qbase
| tag:         qtip
| tag:         tip
| user:        Gregory Szorc &lt;gps@mozilla.com&gt;
| date:        Sun Jun 22 14:27:55 2014 -0700
| summary:     make mq patch 1
|
o changeset:   1:d5741ada659d
| tag:         qparent
| user:        Gregory Szorc &lt;gps@mozilla.com&gt;
| date:        Sun Jun 22 13:48:37 2014 -0700
| summary:     second commit
|
o changeset:   0:23d165967da3
  user:        Gregory Szorc &lt;gps@mozilla.com&gt;
  date:        Sun Jun 22 13:48:05 2014 -0700
  summary:     initial commit
</pre></div>

<p>We see our mq patch is now applied on top of the second commit,
<em>d5741ada659d</em> because it was pushed while the working directory
was sitting at <em>d5741ada659d</em>.</p>
<p>But let's see what mq says:</p>
<div class="pygments_murphy"><pre>$ hg cat .hg/patches/p1
# HG changeset patch
# Parent 23d165967da39e5846976eb6ed967f1058827ffa
# User Gregory Szorc &lt;gps@mozilla.com&gt;
make p1

diff --git a/foo b/foo
--- a/foo
+++ b/foo
@@ -1,1 +1,1 @@
-foo
+patch 1
</pre></div>

<p>mq still says <em>23d165967da3</em> is the parent, even though we changed the
parent! mq is lying to us! Now, we
can rectify the situation by running <em>hg qrefresh</em>. That will cause mq
to regenerate the patch file, which will pick up the new parent. But
who does that? Unless you need to qrefresh to resolve conflicts or
other changes, nobody. This means that if you distribute the patch -
say you are uploading it for review - the parent changeset may not
be accurate and anyone applying that patch may apply it to the wrong
changeset and get unexpected results. That's no good.</p>
<p>For what it's worth, this behavior of not auto refreshing patches
is by design. We don't necessarily want application to be a mutating
operation, especially since mq repositories aren't automatically
versioned. This is partially because mq was effectively designed to be
<a href="https://savannah.nongnu.org/projects/quilt">quilt</a> built into
Mercurial. And <em>quilt</em> is a tool that was invented before the modern
version control tools era. mq's behavior is influenced more from
emulating <em>quilt</em> than from the desire to facilitate a sane
patch/stack/feature based workflow. If you ever wanted to know why
mq works the way it does and not like something more modern, that's
why.</p>
<p>Another huge reason to not use mq is because its concepts and
workflows are alien to modern and well-understood practices. While
I'm a huge fan of Mercurial and prefer it over Git (read my
<a href="/blog/2013/05/12/thoughts-on-mercurial-%28and-git%29/">thoughts on the topic</a>),
I don't pretend that Git isn't the most widely used version control
software right now (at least in the open source world).
It got that way despite its horrible
<a href="http://stevelosh.com/blog/2013/04/git-koans/">UI shortcomings</a>.
I argue its rise was because people enjoy workflows such
as lightweight branches and fast, often-simple merging.
(GitHub and its fairly good web UI certainly helped the cause.)
People today know Git. They know lightweight branches. I think
they largely understand the concept of repositories with multiple
heads and grok how a distributed version control system means you can
commit locally without affecting a remote (server). They grok
how can you push local commits to a remote (sometimes in the
form of a pull request). mq doesn't work this way - the way that
people have come to expect from Git. There are
<a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">cognitive biases</a>
that lead us to believe that because mq is different (from Git)
that it is inferior. Why should someone apply and unapply
individual patches on a temporary queue (or stack depending on how
you think about it) instead of working with <em>branches</em>? If someone
groks Git and multiple heads/branches/bookmarks, why should they
go through all the trouble of learning mq? The fact that mq
doesn't work as well as non-mq mechanisms is icing on the
figurative cake.</p>
<p>If the reasons I've listed are not enough, know this: mq users
will not able to fully utilize the game-changing
<a href="http://mercurial.selenic.com/wiki/ChangesetEvolution">Changeset Evolution</a>
feature of Mercurial. Remember in the late 2000's when people
thought Git was crazy for allowing you to mutate history - the
antithesis of version control because it threw away data? Changeset
Evolution and obsolescence markers - the mechanism used to enable
Changeset Evolution - are Mercurial's answer to that. They enable
Mercurial to retain metadata about previous changesets and how they
<em>evolved</em> into newer changesets. That criticism about history
rewriting deleting history: Changeset Evolution makes it largely
go away. A light version of the history of past commits is preserved
and propagated during push and pull operations.</p>
<p>Changeset Evolution changes the game much like Git changed the
landscape of version control in the late 2000's. So much of our
notions of how modern version control work are based on the
<em>current</em> behavior of tools. For example, any Git user will tell
you, <em>never git push --force</em>.
<a href="https://groups.google.com/forum/#!searchin/jenkinsci-dev/force$20push/jenkinsci-dev/-myjRIPcVwU/mrwn8VkyXagJ">Bad things will happen</a>.
Why do they say that? They say that because the user experience of
distributed history rewriting in Git can be horrible and error prone.
And it is like this because Git's implementation of history rewriting
burns the old books of history once they are translated to the
new world order. (OK, to be fair to Git it does have a reflog that
can kinda sorta be used to recover in disaster scenarios. But it's
far from robust and there are numerous caveats, notably that the
reflog is not part of data distributed with push/fetch and therefore
susceptible to single/few points of failure.) Mercurial's
obsolescence markers, by contrast, leave footnotes in our history
books and transfer these annotations as part of the distributed
repository data. Changeset Evolution uses these footnotes to
reconstruct the pages of history, even if they differ
from our own perspective. For example, you can force push rewritten
history and other clients can recover from that automagically. Want
to do complex history rewriting and force push?
Go right ahead: Mercurial and Changeset Evolution will
enable you to work without imposing as many (practical)
restrictions on your workflow as other tools. Good tools are flexible
and impose fewer restrictions. This is why Mercurial and Changeset
Evolution have the potential to change the world of version control
much like Git changed things half a decade ago.</p>
<p>Are you still not convinced mq is a bad idea? Know this: a
Mercurial core developer
<a href="http://www.selenic.com/pipermail/mercurial-devel/2014-June/059535.html">recently proposed marking mq as deprecated</a>.
That's right: there's very little love for mq within the Mercurial
Project. Maintainers generally think what I've stated in this post:
mq is yesterday's solution to yesterday's problem and it should
be cast aside.</p>
<p>If you are a mq user, I hope you are now convinced that mq is a bad
idea and you should transition away from it as soon as possible. In
the next section, I'll talk about moving off mq.</p>
<h2>Moving away from mq</h2>
<p>I completely abandonded mq in December 2013 and am never using it
again. In hindsight, I should have made the transition much sooner.</p>
<p>I could write an entire post about my workflow. Since this post is
already a bit long, I'm going to describe it with mostly command
line examples.</p>
<p>I use bookmarks for managing my <em>feature branches</em>. I use one
bookmark per logical feature. This workflow is very similar to
using Git branches.</p>
<div class="pygments_murphy"><pre># Create a new bookmark for the new feature I&#39;m developing.
$ hg bookmark gps/my-new-feature

# make changes to files
(gps/my-new-feature) $ hg commit
# make more changes)
(gps/my-new-feature) $ hg commit
# keep making small changes
(gps/my-new-features) $ hg commit

# I decide I want to reorder or merge a few commits. I look at the
# DAG to see which changeset to rewrite.
(gps/my-new-features) $ hg log --graph

(gps/my-new-feature) $ hg histedit 5e907ed10e22
# this opens an editor where I can say what changes to make)

# Let&#39;s start a new feature.
(gps/my-new-feature) $ hg up central
(leaving bookmark gps/my-new-feature)
$ hg bookmark gps/feature2
# Make some changes
(gps/feature2) $ hg commit

# I got review on my original feature. Let&#39;s push it.
(gps/feature2) $ hg up gps/my-new-feature
(activating bookmark gps/marionette-restart)

(gps/my-new-feature) $ hg pull gecko
pulling from http://hg.stage.mozaws.net/gecko
searching for changes
adding changesets
adding manifests
adding file changes
added 118 changesets with 543 changes to 328 files (+1 heads)
OBSEXC: pull obsolescence markers
OBSEXC: looking for common markers in 215590 nodes
OBSEXC: no unknown remote markers
OBSEXC: DONE
updating bookmark aurora
updating bookmark b2g28
updating bookmark b2ginbound
updating bookmark beta
updating bookmark central
updating bookmark esr24
updating bookmark fx-team
updating bookmark inbound
updating bookmark release
(run &#39;hg heads .&#39; to see heads, &#39;hg merge&#39; to merge)

(gps/my-new-feature) $ hg rebase -d fx-team

# Verify I&#39;m about to push what I want to push.
(gps/my-new-feature) $ hg out -r . fx-team

# And push the changes.
(gps/my-new-feature) $ hg push -r . fx-team

# And delete the bookmark that I don&#39;t need any more.
(gps/my-new-feature) $ hg bookmark -d gps/my-new-feature
</pre></div>

<p>That's how bookmarks work. If you upgrade to Mercurial 3.0 or newer,
Mercurial will print messages when you enter and leave bookmarks. This
is a great UI improvement!</p>
<p>I also have the
<a href="http://mercurial.selenic.com/wiki/PromptExtension">prompt extension</a>
installed and configured so my shell prompt contains the active
bookmark. This helps me keep track of what head I'm committing to.</p>
<p>I'm also a user of the experimental
<a href="http://mercurial.selenic.com/wiki/EvolveExtension">evolve extension</a>.
This is the extension that is implementing the <em>Changeset Evolution</em>
feature. Eventually the functionality will be merged into core
Mercurial. One such workflow with <em>evolve</em> is as follows.</p>
<div class="pygments_murphy"><pre># Create a bookmark for a new feature
$ hg bookmark gps/my-new-feature

# Make some changes.
(gps/my-new-feature) $ hg commit -m &#39;first commit&#39;

# Make some more changes.
(gps/my-new-feature) $ hg commit -m &#39;second commit&#39;

# Submit code for review. (Exact commands excluded.)

# Wait for review comments. There is a nit on the first commit.
$ hg previous
[204142] first commit

# Make changes
$ hg amend
1 new unstable changesets

# (amend is provided by evolve. It is equivalent to hg commit --amend)

# evolve is the command that looks at the history rewriting markers
# and knows how to rebase, etc other changesets in the face of
# rewriting.
$ hg evolve
move:[204143] second commit
atop:[204144] first commit
merging foo
warning: conflicts during merge.
merging foo incomplete! (edit conflicts, then use &#39;hg resolve --mark&#39;)
evolve failed!
fix conflict and run &quot;hg evolve --continue&quot;
abort: unresolved merge conflicts (see hg help resolve)

# Manually address conflict markers in file &quot;foo&quot;
$ hg resolve -m foo
no more unresolved files

$ hg evolve --continue
grafting revision 204143

# And I&#39;m ready to push.
</pre></div>

<p>If you really love the concept of mq and patch queues and absolutely
must do development that way (as opposed to bookmarks/branches), then
you should consider using the
<a href="http://mercurial.selenic.com/wiki/ShelveExtension">shelve extension</a>
instead of mq. While shelve is still a bit hacky in that it violates the
append-only goal of the Mercurial store, it does so in a way that
integrates much better than mq. For example, when you <em>unshelve</em>,
the changesets will only apply to the parent changeset they were
last attached to. You will get no merge conflicts during <em>unshelve</em>. If
you want to rebase, you will need to use the <em>rebase</em> command, which
will go through Mercurial's more robust merging code paths, leaving
conflict markers instead of <em>.rej</em> files
(assuming you are using the <em>internal</em>
<a href="http://mercurial.selenic.com/wiki/MergeToolConfiguration">merge tool</a>).
Shelve also groups multiple changesets together. Contrast with
mq's default behavior of a flat list of patches (my mq queue grew
to over 100 patches with patches belonging to dozens of bugs).
Shelve is all around a better mq and is a good compromise between
the stack/queue based development workflow of mq with the more modern
development workflow of bookmarks. If nothing else, shelve integrates
much better into the Mercurial core. As a quantitative measurement
of this, mq weighs in
at <a href="http://selenic.com/repo/hg/file/cd3c79392056/hgext/mq.py">3461</a>
lines. Shelve, by comparison, is a svelt
<a href="http://selenic.com/repo/hg/file/cd3c79392056/hgext/shelve.py">704 lines</a>.
Considering they do nearly the same thing (shelve offloads functionality
like folding and reordering to core Mercurial commands that didn't
exist at the time of mq's inception), I trust shelve with its reduced
surface area to be more robust and bug free.</p>
<p>But as good as shelve is, it's still not as integrated as bookmarks
or branches. If you can, try to stick to the Mercurial core
features and avoid shelve. But whatever you do, try to avoid mq!</p>
<h2>Conclusion</h2>
<p>I never used Mercurial before becoming an employee of Mozilla
and a contributor to Firefox. I was a mq user for my first two plus
years of Mercurial use. I blindly followed the Mozilla
documentation and advice of my fellow Mozillians to use mq.
It wasn't until I truly invested in learning Mercurial (as
opposed to learning merely the command line interface - the
minimum required for me to contribute to Firefox) that I
realized how wrong the common Mozilla mindset about Mercurial
and mq was. I was incorrectly associating mq with <em>"The Mercurial
Way"</em> and thought Mercurial was inherently lacking. I knew
about branches and bookmarks, but didn't realize I could use
them as an alternative to mq.</p>
<p>Only after learning Mercurial's internals, contributing patches to
the Mercurial core, and reading the changelog of the Mercurial
project itself did I realize the truth: <strong>mq's popularity is a
result of historical necessity that no longer exists; and, continued
usage of mq represents a general failure in user eduction about
mq's drawbacks and Mercurial's modern features.</strong> In other words,
the more informed I became, the more I learned what a bad idea
mq is and why it should be avoided.</p>
<p>At Mozilla, we happened to switch to Mercurial at a time (2007) when
mq was the only reasonable solution available to Mercurial. The
procedures and documentation developed in 2007 have persisted to
2014, largely ignoring advancements in Mercurial over that time.
To be fair to my fellow Mozillians and Mercurial users everywhere,
Mercurial wasn't truly ready to jettison mq until the <em>histedit</em>
extension came into existence a few years ago. But that was
<em>years</em> ago. We all should have had time to switch, but we haven't.
Or if we have, we've switched to Git. (And I can't blame anyone for
switching to Git - both its mind share and the network effect of
GitHub are <em>very</em> compelling reasons.)</p>
<p>I hope you now know why mq is a bad idea. Please join me in realizing
that mq was a solution for yesterday's problems. mq is a legacy tool
that loses data and makes your life harder. It's time to let go of
the past and embrace the future. Please join me in shaving the mq
neck beard that has been growing since CVS was a popular version
control system.</p>
<h2>Addendum on Code Review</h2>
<p>While I've wanted to write this post for a while, the trigger for me
finally writing it is my work on integrating Mercurial with the
<a href="http://www.reviewboard.org/">Review Board</a> code
review software. The Bugzilla Team at Mozilla is working on a project
to integrate Review Board into Bugzilla for code review, supplementing
the antiquated-by-comparison Splinter code review feature.
Instead of uploading patches to Bugzilla - how Mozilla and Firefox
development has done it for over a decade - you will push changesets
to a Mercurial repository and pushed
changesets will automatically turn into code reviews on Review
Board and get cross-posted to referenced Bugzilla bugs.</p>
<p>This is all part of a larger goal to make it easier for patches to be
submitted and landed consistently and centrally. This should lead to
various automation and tooling improvements, such as bots conducting
aspects of code review and automatically landing reviewed patches.</p>
<p>These things are very difficult to do in a Bugzilla-only and patch-based
world because it is difficult to first aggregate patches and second
process them in a unified manner. Patches come in many different
flavors. You have Mercurial style diffs.
You have plain patches, and patches with Git or Mercurial style
annotation.  You have different lines of context in the patch.
You have different handling of binary content. You have mq lying
about the parent changeset. All these contribute
to a massive impedance mismatch of sorts that makes it extremely
difficult to roll out any kind of automation. Any tools built on
top must first solve a very difficult data normalization and
distribution problem. These are problems that should not exist and
drastically raise the barrier to forward progress.</p>
<p>Contrast this with pushing to Mercurial (or Git) repositories. The
repository is the data, not the patch file. Clients are able to
extract variations of that data however they see fit. Commit
data is centralized, distributable, and unified. There are dozens
of existing tools and services that already know how to speak
with repositories. Our data problem not only goes away, but
many solutions have already been invented for us.</p>
<p>Back to Review Board.</p>
<p>I've written an <a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/default/hgext/reviewboard">extension</a>
that pushes review-specific metadata to the Mercurial server. This
effectively allows Mercurial to <em>speak</em> code review and interact
with the code review server. For Mercurial clients that are writing
obsolescence markers, we are able to <em>track</em> the changesets
undergoing review against their logical successors. For example,
if you pull and rebase, this will rewrite changeset X to changeset Y
(because the SHA-1 changes). Mercurial knows that a) changeset X was
under review and b) Y is the new version of X. So, when you push
Y for code review, the review associated with X is updated
automagically. You could accomplish this with heuristic-based
matching or user prompting, but these are error prone (you wouldn't
believe the number of corner cases) or require excessive user
time, especially when complex history rewriting is involved.
Mercurial's obsolescence markers allow the matching to <em>just work</em>
in most scenarios and for people to spend more time writing and
reviewing code as opposed to telling the code review tool what
and how to review.</p>
<p>As I was implementing this extension, I realized that mq users
(most Mercurial users at Mozilla I reckon) would be unable to reap the
benefits of all this magic because, well, they are using mq. I care
passionately about developer productivity. Good tools are the tools
that don't require constant massaging. I want everyone to get the
full benefits of Mozilla's new code review system when it launches.
And the only way that happens is if people stop using mq. And the
only way that happens is if people learn why mq is a bad idea. So
if nothing else has convinced you to stop using mq yet, maybe the
lure of an amazing and automagical code review and collaboration
experience will sway you.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Using Mercurial for Status Reports]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/04/01/using-mercurial-for-status-reports" />
    <id>http://gregoryszorc.com/blog/2014/04/01/using-mercurial-for-status-reports</id>
    <updated>2014-04-01T12:30:00Z</updated>
    <published>2014-04-01T12:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Using Mercurial for Status Reports]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/04/01/using-mercurial-for-status-reports"><![CDATA[<p>Mercurial has a pair of amazing features called
<a href="http://www.selenic.com/hg/help/revsets">Revisions Sets</a>
and <a href="http://www.selenic.com/hg/help/templates">Templates</a>. Combined,
they allow you to query Mercurial like a database and to generate custom
reports from obtained data.</p>
<p>As I've <a href="/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata/">demonstrated</a>,
you can write Mercurial extensions to provide custom revision set
queries and template functions and keywords. My
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/default/hgext/mozext">mozext</a>
extension aggregates Mozilla's <em>pushlog</em> data into a local SQLite
database and makes this data available to revision sets and templates.</p>
<p>My hack of the day is to use revision sets and templates to create a
weekly status report:</p>
<div class="pygments_murphy"><pre>hg log -r &#39;public() and me() and firstpushdate(&quot;-7&quot;)&#39; \
--template &#39;* {ifeq(reviewer, &quot;gps&quot;, &quot;Review: &quot;, &quot;Landing: &quot;)}{firstline(desc)}\n&#39;
</pre></div>

<p>When I run this, I get the output:</p>
<div class="pygments_murphy"><pre>* Review: Bug 957241 - Don&#39;t package the full sdk when we don&#39;t need it. r=gps
* Review: Bug 987146 - Represent SQL queries more efficiently. r=gps.
* Review: Bug 987984 - VirtualenvManager.call_setup() should use self.python_path instead of sys.executable, r=gps
* Landing: Bug 987398 - Part 1: Run mochitests from manifests with mach; r=ahal
* Landing: Bug 987398 - Part 2: Handle install-to-subdir in TestResolver; r=ahal
* Landing: Bug 987414 - Pass multiple test arguments to mach testing commands; r=ahal
* Review: Bug 988141 - Clean up config/recurse.mk after bug 969164. r=gps
* Landing: Bug 973992 - Support experiments add-ons; r=Unfocused
* Review: Bug 927672 - Force pymake to fall back to mozmake when run on build slaves. r=gps
* Review: Bug 989147 - Use new sccache for Linux and Android builds. r=gps
* Review: Bug 989147 - Add missing part of the patch from rebase conflict. r=gps
* Landing: Bug 975000 - Disable updating and compatibility checking for Experiments; r=Unfocused
* Landing: Bug 985084 - Experiment add-ons should be disabled by default; r=Unfocused
* Landing: Backed out changeset 4834a3833639 and c580afddd1cb (bug 985084 and bug 97500)
* Landing: Bug 975000 - Disable updating and compatibility checking for Experiments; r=Unfocused
* Landing: Bug 985084 - Experiment add-ons should be disabled by default; r=Unfocused
* Landing: Bug 989137 - Part 1: Uninstall unknown experiments; r=Unfocused
* Landing: Bug 989137 - Part 2: Don&#39;t use a global logger; r=gfritzsche
* Landing: Bug 989137 - Part 3: Log.jsm API to get a Logger that prefixes messages; r=bsmedberg
* Landing: Bug 989137 - Part 4: Use a prefixing logger for Experiments logging; r=gfritzsche
* Landing: Bug 989137 - Part 5: Prefix each log message with the instance of the object; r=gfritzsche
* Review: Bug 988849 - Add mach target for jit tests; r=gps
* Landing: Bug 989137 - Part 6: Create experiment XPIs during the build; r=bsmedberg
* Landing: Bug 989137 - Part 7: Remove unncessary content from test experiments; r=Unfocused
* Landing: Bug 985084 - Part 2: Properly report userDisabled in the API; r=Unfocused
</pre></div>

<p>Which I can then copy and paste directly into the
<a href="http://benjamin.smedbergs.us/weekly-updates.fcgi/">status tool</a> to
capture all my weekly code contributions! That takes a few seconds to
run and saves me a few minutes of typing.</p>
<p>For the curious, let's break that Mercurial command down.</p>
<ul>
<li>public() selects all <em>public</em> changesets. These are changesets in the
  repository that have been pushed to a publishing repository. In other
  words, patches that landed in Firefox.</li>
<li>me() is a custom revset from my <em>mozext</em> extension that parses the
  commit message and selects changesets that I authored or reviewed.</li>
<li>firstpushdate("-7") is a custom revset from my <em>mozext</em> extension. It
  selects changesets that were first pushed in the last 7 days (using
  pushlog data stored in a local SQLite database).</li>
</ul>
<p>The template piece should be easy to read. I have a simple branch
testing whether the changeset is a review or not, then output a label
followed by the first line of the commit message.</p>
<p>I have this command saved under the <em>[alias]</em> section of my <em>~/.hgrc</em>
file so I can just type <em>hg statusreport</em>.</p>
<p>While there is room to improve the tool (stripping <em>r=</em> lines from
commit messages for example), I think it's a pretty cool hack and shows
how Mercurial can grow to solve problems you don't think your version
control system knows how to solve.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[How Promises and Tasks are Improving Tests]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/03/30/how-promises-and-tasks-are-improving-tests" />
    <id>http://gregoryszorc.com/blog/2014/03/30/how-promises-and-tasks-are-improving-tests</id>
    <updated>2014-03-30T14:15:00Z</updated>
    <published>2014-03-30T14:15:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="JavaScript" />
    <summary type="html"><![CDATA[How Promises and Tasks are Improving Tests]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/03/30/how-promises-and-tasks-are-improving-tests"><![CDATA[<p>I was a very early adoptor of promises and
<a href="https://developer.mozilla.org/en-US/docs/Mozilla/JavaScript_code_modules/Task.jsm">Tasks</a>
in Firefox's JavaScript code base. To me, promises on their own are ok.
The ability to chain promises together and tack one error handler on
the end sure beats the
<a href="http://tritarget.org/blog/2012/11/28/the-pyramid-of-doom-a-javascript-style-trap/">Pyramid of Doom</a>
and having to pass errors into callbacks everywhere. But what really
lured me in were tasks: using generators (then a feature only available
in SpiderMonkey) to represent async code flow as nice, easy-to-read
procedural flow that nearly every programming can relate to. It made
code much easier to read and grok. I've been using tasks ever since.</p>
<p>When I started writing new APIs that returned promises instead of using
callbacks, I found myself writing a lot of tests consuming promises and
using tasks. So, I
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=819033">added an add_task</a>
API to our xpcshell test harness to make writing task-based unit tests
involve less boilerplate. That API is now used heavily for new xpcshell
tests.</p>
<p>While I initially added <em>add_task()</em> to cut down on the boilerplate for
writing tests, I only recently realized it has another benefit: it's
helped cut down on hung tests!</p>
<p>Before, with callback-based APIs, we'd code tests like so:</p>
<div class="pygments_murphy"><pre><span class="nx">add_test</span><span class="p">(</span><span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
  <span class="nx">do_something</span><span class="p">(</span><span class="kd">function</span> <span class="nx">onThatThing</span><span class="p">(</span><span class="nx">result</span><span class="p">)</span> <span class="p">{</span>
     <span class="nx">Assert</span><span class="p">.</span><span class="nx">ok</span><span class="p">(</span><span class="nx">result</span><span class="p">.</span><span class="nx">success</span><span class="p">);</span>
     <span class="nx">run_next_test</span><span class="p">();</span>
  <span class="p">});</span>
<span class="p">});</span>
</pre></div>

<p>Or another pattern:</p>
<div class="pygments_murphy"><pre><span class="nx">add_test</span><span class="p">(</span><span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
  <span class="nx">do_something</span><span class="p">(</span><span class="kd">function</span> <span class="nx">onThatThing</span><span class="p">(</span><span class="nx">result</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// The next line throws an Error by accident!</span>
    <span class="nx">result</span><span class="p">.</span><span class="nx">foo</span><span class="p">();</span>
    <span class="nx">run_next_test</span><span class="p">();</span>
  <span class="p">});</span>
<span class="p">});</span>
</pre></div>

<p>In the first example, the test will hang if the callback never gets
called. The test harness driver will eventually terminate
the test (after a multi-second delay with no output). Not good.</p>
<p>In the second example, we are still susceptible to the callback not
being called. But we have a different problem: an untrapped Error is
thrown from a callback! This results in the same behavior:
<em>run_next_test()</em> (the function that says to advance to the next test)
won't execute and the test will hang until it times out.</p>
<p>A more proper way to write this test is:</p>
<div class="pygments_murphy"><pre><span class="nx">add_test</span><span class="p">(</span><span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
  <span class="nx">do_something</span><span class="p">(</span><span class="kd">function</span> <span class="nx">onThatThing</span><span class="p">(</span><span class="nx">result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">try</span> <span class="p">{</span>
      <span class="nx">result</span><span class="p">.</span><span class="nx">foo</span><span class="p">();</span>
    <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="nx">ex</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">do_report_unexpected_exception</span><span class="p">(</span><span class="nx">ex</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nx">run_next_test</span><span class="p">();</span>
  <span class="p">});</span>
<span class="p">});</span>
</pre></div>

<p>In reality, few people surround all their callbacks with try..catch
blocks because, well, it's a lot of typing and people don't always think
it's necessary (the test passes most of the time, doesn't it?).</p>
<p>What promises and task-based tests are doing is enabling us to write
more robust tests without all of the extra work. Here is how you would
use task-based tests:</p>
<div class="pygments_murphy"><pre><span class="nx">add_task</span><span class="p">(</span><span class="kd">function</span><span class="o">*</span> <span class="p">()</span> <span class="p">{</span>
  <span class="kd">let</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">yield</span> <span class="nx">do_something</span><span class="p">();</span>
  <span class="c1">// The next line throws an Error by accident!</span>
  <span class="nx">result</span><span class="p">.</span><span class="nx">foo</span><span class="p">();</span>
<span class="p">});</span>
</pre></div>

<p>Here, the Error thrown by the test function is thrown within the context
of an executing Task. It is caught by the Task and converted into a
rejected promise. <strong>The test harness sees that failure immediately
and no timeout occurs!</strong> This can cut down on overhead when writing
tests, especially if you are trying to debug a hang.</p>
<p>Furthermore, the test is 4 lines versus 10. Less typing means you have
more time to write additional tests or you can focus on writing other
patches.</p>
<p>Finally, the task-based test functions are easier to understand. That 4
line, procedural test is much easier to grok than its callback-based
counterpart.</p>
<p>And before I conclude, I should mention that we can do more with
promises. For example, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=976205">bug 976205</a> is making uncaught promise errors turn into test failures!
There is also an awesome patch in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=867742">bug 867742</a> to
introduce a unified JavaScript test harness API for defining JavaScript
tests in our tree (currently the APIs for xpcshell tests and mochitests
are different, leading to cognitive dissonance and lower productivity).
<strong>If you want to be a hero to the Firefox developer community, help
finish that patch.</strong></p>
<p>Given that so much Firefox feature development time (at Mozilla) is
spent writing and debugging tests, I encourage everyone to consider
promises and tasks for his or her next feature so that you can cut
down on development time and complete projects faster.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[New Repository for Mozilla Version Control Tools]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/02/05/new-repository-for-mozilla-version-control-tools" />
    <id>http://gregoryszorc.com/blog/2014/02/05/new-repository-for-mozilla-version-control-tools</id>
    <updated>2014-02-05T19:15:00Z</updated>
    <published>2014-02-05T19:15:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Git" />
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[New Repository for Mozilla Version Control Tools]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/02/05/new-repository-for-mozilla-version-control-tools"><![CDATA[<p>Version control systems can be highly useful tools.</p>
<p>At Mozilla, we've made numerous improvements and customizations to our
version control tools. We have <a href="https://hg.mozilla.org/hgcustom/hghooks/">custom hooks</a>
that run on the server. We have a <a href="https://hg.mozilla.org/hgcustom/hg_templates/">custom skin</a>
for Mercurial's web interface. Mozillians have written a handful of
Mercurial extensions to aid with common developer tasks, such as
<a href="https://bitbucket.org/sfink/trychooser">pushing to try</a>,
<a href="https://hg.mozilla.org/users/tmielczarek_mozilla.com/bzexport">interacting with Bugzilla</a>,
<a href="https://bitbucket.org/sfink/mqext">making mq more useful</a>, and more.</p>
<p>These have all come into existence in an organic manner, one after the
other. Individuals have seen an itch and scratched it. Good for them.
Good for Mozilla.</p>
<p>Unfortunately, the collection of amassed tools has become quite large.
They have become difficult to discover and keep up to date. The
consistency in quality and style between the tools varies. Each tool has
separate processes for updating and changing.</p>
<p>I contacted the maintainers of the popular version control tools at
Mozilla with a simple proposal: let's maintain all our tools under one
repo. This would allow us to increase cohesion, share code, maintain a
high quality bar, share best practices, etc. There were no major
objections, so we now have a <a href="https://hg.mozilla.org/hgcustom/version-control-tools/">unified repository</a>
containing our version control tools!</p>
<p>Currently, we only have a few Mercurial extensions in there. A goal is
to accumulate as much of the existing Mercurial infrastructure into
that repository as possible. Client code. Server code. All of the code.
I want developers to be able to install the same hooks on their clients
as what's running on the server: why should your local repo let you
commit something that the server will reject? I want developers to be
able to reasonably reproduce Mozilla's canonical version control server
configuration locally. That way, you can test things locally with a high
confidence that your changes will work the same way on production. This
allows deployments to move faster and with less friction.</p>
<p>The immediate emphasis will be on moving extensions into this repo and
deprecating the old homes on user repositories. Over time, we'll move
into consolidating server code and getting hg.mozilla.org and
git.mozilla.org to use this repository. But that's a lower priority: the
most important goal right now is to make it easier and friendlier for
people to run productivity-enhancing tools.</p>
<p>So, if you see your Mercurial extensions alerting you that they've been
moved to a new repository, now you know what's going on.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[The Mercurial Revlog]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2014/02/05/the-mercurial-revlog" />
    <id>http://gregoryszorc.com/blog/2014/02/05/the-mercurial-revlog</id>
    <updated>2014-02-05T16:26:00Z</updated>
    <published>2014-02-05T16:26:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[The Mercurial Revlog]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2014/02/05/the-mercurial-revlog"><![CDATA[<p>Mercurial stores lots of its data in append-only,
intended-to-be-immutable data structures called <em>revlogs</em>. Each revlog is
backed by a file on the filesystem. The main component of a revlog
is a <em>revision</em>. When a new revision arrives, its content is compared
against the previous revision in the file and a zlib-compressed
delta/diff is generated. If the delta is smaller than the entry
itself, the delta is appended to the revlog. If the compressed delta
itself or the stream of deltas that must be applied to recreate the
original text is larger than the source text, the compressed full content
is appended to the revlog. In other words, Mercurial tries to maintain
a balance between file size/growth rate and read times in terms of
both I/O and CPU.</p>
<p>The <em>changelog</em> is a <em>revlog</em> that holds information about every
changeset/commit in the repository. The <em>manifest</em> is a <em>revlog</em> that
holds details about which files are present in every changeset. There
exist a separate <em>revlog</em> for each file/path ever present in the
repository. These are called <em>filelogs</em>.</p>
<p>When you commit a change touching a single file, Mercurial will append
a revision to the changelog describing the commit, a revision to the
manifest describing the set of files active in that specific commit,
and a new revision to a filelog.</p>
<p>You can poke around your repository's revlogs by running some debug
commands. For example:</p>
<pre><code># Show high-level information about the manifest revlog
$ hg debugrevlog -m

# Show details about each entry in the manifest revlog (this
# actually reads data from an index to the data revlog - pretend
# there aren't index files for now)
$ hg debugindex -m

# Dump the content of a single entry in the changelog.
$ hg debugdata -c 2
</code></pre>
<p>I'm generally a big fan of append-only data structures because I love
the beneficial caching properties and linear I/O performance.
Mercurial and the revlog can take advantage of these properties for
some performance wins under key scenarios, especially server
operation (pushing commits doesn't necessarily invalidate cached revlog
entries, allowing the page cache to service many reads).</p>
<h2>Edge cases and deficiencies</h2>
<p>As with any system trying to solve a complex problem, the revlog
storage format doesn't always work as well as intended.</p>
<p>Let's start by taking by looking at how revlogs do delta storage. I said
earlier that revlogs try to store a compressed delta against the
previous entry. Well, that previous entry is the previous physical
revision in the file/revlog, not the parent revision. You see,
entries/revisions in revlogs have a numeric index (0, 1, 2, 3, ...),
a SHA-1 hash of their content, and a link to the logical <em>parent</em> of
the entry. e.g. say you have two commits in your repo, one made after
the other:</p>
<pre><code>0:8ba995b74e18
1:9b2a99adc05e
</code></pre>
<p>The revlog has entries at indexes 0 and 1. They are also accessible
by their hash/node values of 8ba995b74e18 and 9b2a99adc05e. The parent
of 1 is 0. The entry for 0 is the full, compressed content of 0. The
entry for 1 is likely a compressed delta from 0 to 1. As we commit,
we keep appending new entries. These exist as compressed deltas until
the sizes of 0..n is greater than n by itself. At that time, a
compressed version of n is stored.</p>
<p>This model works great for linear histories, as changes from n to n+1
are usually small. Mercurial can store a very small delta for each
entry. The world is good.</p>
<p>This model works great when entries in revlogs are small. By having
small entries (and small changes), the number of deltas required to
eclipse the size of a single entry remains small, in effect keeping the length
of a <em>delta chain</em> in check. Limiting the length of delta chains is good
because it keeps the cost of looking up a single revision's content low.
If you have a delta chain of 1000, for example, Mercurial will need to read
1000 revlog entries and apply 1000 deltas to obtain the original value.
That can get expensive computationally. Since reads are linear, I/O
should remain in check. But you do need to scan a lot of bytes to read
in all the deltas and you need to perform a lot of the same computations
(such as zlib decompression).</p>
<p>Let's talk a little about where the revlog starts to break down.</p>
<p>First, there's the issue of multiple, interleaved branches in the
revlog. Say we have a repository with many branches/heads. We alternate
committing between all the heads. This can play havoc with the default
revlog delta compression. Since revlogs compress against the previous
<em>physical</em> entry in the revlog, if there is lots of alternating between
branches and the contents of those branches diverges significantly, the
deltas can grow quite large and full revisions will be stored with
higher frequency. This means more storage space and more CPU tasked
with resolving deltas (since deltas are larger). Although, CPU is kept
in check since delta chains tend to be smaller since full revisions are
stored with higher frequency.</p>
<p>Second, we have an issue with delta chain explosion of large entries
with small turnover. If your base content is large and it isn't changing
that much, it will take hundreds or even thousands of revisions before
the sum of the delta sizes outgrows that of an entry. This means delta
chains can be very long and Mercurial will have to spend a lot of CPU
to resolve a single entry.</p>
<p>Third, revlogs are using zlib for compression. As many
<a href="http://pokecraft.first-world.info/wiki/Quick_Benchmark:_Gzip_vs_Bzip2_vs_LZMA_vs_XZ_vs_LZ4_vs_LZO">benchmarks</a>
have shown, zlib isn't the fastest or most efficient compression
algorithm in the world. It's likely justified as a reasonable default.
But alternatives exist. The choice of zlib has implications, especially
when other factors (such as excessively long delta chains) come into
play.</p>
<p>Let's talk about mitigation strategies.</p>
<h2>True parent deltas</h2>
<p>While I wasn't around for the original design decisions of revlogs, I'm
guessing they were strongly influenced by the fact that sequential I/O
on magnetic disks is much, much faster than random I/O. With SSDs and
flash storage growing in popularity - a medium that offers random I/O
commonly over 100 MB/s - this buys us the luxury of asking <em>do revlogs
need to be optimized for sequential I/O</em> and <em>how can revlogs change to
take advantage of fast random I/O</em>.</p>
<p>One of the ways revlogs can adapt to fast random I/O is to store the
delta against the logical parent, not the physical. The delta chain will
thus <em>skip</em> revisions in the revlog. e.g. the chain could be 1, 2, 5, 6,
10, not n, n+1, n+2, .... This would keep deltas small and would reduce
the overall size of the revlog. Although, it would likely increase the
length of delta chains, especially when dealing with non-linear
histories.</p>
<p>It turns out Mercurial has a setting that enables this -
<strong>format.generaldelta</strong>. To create a repository with this enabled, run:</p>
<pre><code>$ hg --config format.generaldelta=true init path/to/repo
</code></pre>
<p>The revlogs in that repository with now have deltas computed against the
logical parent!</p>
<p>To verify you are using general delta, look for <strong>generaldelta</strong> in the
<em>.hg/requires</em> file. If it isn't there, you probably don't have
generaldelta enabled. <strong>Please note that cloning a generaldelta repo
won't necessarily give your repo generaldelta. You need to have the
custom config option set on the client or the client will likely use the
defaults.</strong></p>
<p>On repositories with lots of interleaved heads, this can make a huge
difference. As a pathalogical example, Mozilla's
<a href="https://hg.mozilla.org/try/">Try</a> repository (where people push heads
to trigger test/automation runs) has over 22,000 heads. The on-disk
size of the repository is 3117 MB with the standard settings and 2139 MB
with generaldelta! The bulk of this difference comes from the manifest
revlog, which is 954 MB smaller with generaldelta.</p>
<h2>Alternate compression format</h2>
<p>Mercurial uses zlib for revlog compression by default. This is a safe
choice. It's relatively fast and yields relatively good compression.</p>
<p>Since Mercurial is highly extensible, it's possible to plug in a custom
compression format for revlogs. Facebook's
<a href="https://bitbucket.org/facebook/lz4revlog/">lz4revlog extension</a> will
use lz4 for compression. lz4 is faster than zlib, but compression isn't
as good. Repositories with lz4 are commonly ~1.5x larger. But CPU bound
tasks can be significantly faster.</p>
<p>In theory, any compression format can be used. However, it's not
trivially selectable in Mercurial (yet), so someone will need to provide
an extension that implements your desired compression format.</p>
<h2>Alternate storage backends</h2>
<p>In theory, Mercurial revlogs can be backed by anything. This is the
extensibility of Mercurial at work. There's just a Mercurial extension
sitting between using SQL, S3, Cassandra, or any other storage backend
for revlogs.</p>
<p>It's also possible to write custom revlog implementations that change
the file layout for interesting scaling possibilities. For example,
modern filesystems like ZFS and btrfs support block-level deduplication
and transparent compression. If you had block-aligned revlog entries
with deduplication enabled, servers could in theory only store each
revision at most once. Another idea is to let the filesystem handle
the compression. This would cause compression to occur in kernel space
(rather than inside Python userspace). This may have beneficial
performance properties. It may not. It may depend on the repository.
These would be interesting experiments to conduct!</p>
<h2>Caveat with alternate revlog implementations</h2>
<p>Before you go experimenting with alternative revlog implementations,
be forewarned that wall time performance for push and pull operations
may suffer!</p>
<p>Currently, Mercurial isn't as smart as it could be when it comes to
transferring <em>bundles</em> of changeset data between repositories. Let me
explain.</p>
<p>When Mercurial transfers changeset data between repositories, it often
uses an encoding format called a <a href="http://mercurial.selenic.com/wiki/BundleFormat">bundle</a>.
A bundle is effectively a custom archive format for revlog data. If
you've ever used <em>hg bundle</em> or <em>hg unbundle</em> to transfer repository
data, you've explicitly interacted with bundles. But what's lesser known
is that the <em>hg push</em> and <em>hg pull</em> operations also transfer bundles.
The only major difference is that they are created on the fly and their
existence is hidden from view.</p>
<p>In theory, bundles can be encoded a number of different ways. The most
common tunable is the compression format. Over the wire, bundles are
zlib (or even uncompressed). If you run <em>hg bundle</em>, you'll likely
produce a bzip2 bundle. (This is why <em>hg unbundle</em> can be slower than
<em>hg clone</em> - the CPU time spent for bzip2 is much greater than for
zlib.) But a problem with bundles as they exist today is that the format
is rather static when it comes to what's transferred over the wire.
Unless you've mucked about with settings, the client and server will
send a zlib-compressed bundle using the physical revlog order. In other
words, the bundle format is the Mercurial defaults.</p>
<p>If Mercurial were completely dumb, transferring bundles would involve
1) determining the full text of a revlog entry 2) compressing that entry
into a bundle 3) sending that data to a peer 4) decompressing that entry
5) appending that entry to the appropriate revlog (which involves
recompression). Fortunately, Mercurial is a bit smarter than that:
Mercurial can detect when compressed bits in a bundle will match what
is on disk and will avoid the unncessary compression operations.</p>
<p>Anyway, the current bundle transfer mechanism falls apart when there is
a mismatch between client and server configurations or even when the
server or client is using non-defaults. You can think of this as a
revlog impedance mismatch. Essentially, when the client and server are
operating with different or uncommon types of revlogs, Mercurial tends
to default to the lowest common denominator, or zlib deltas against the
physical parent. If, for example, a client wants to use generaldelta
with a server employing defaults, the client will have to convert the
server's deltas into generaldelta deltas. This requires a non-trivial
amount of CPU and pull operations become slower. I believe the opposite
is also true: generaldelta clients will emit generaldelta bundles,
causing the server to recompute the deltas.</p>
<p><strong>When it comes to custom revlog formats today, essentially nobody
wins.</strong></p>
<p>The good news is this will be fixed. There is an
<a href="http://mercurial.selenic.com/wiki/BundleFormat2">effort</a> to improve the
bundle format and wire protocols to make matters better. A little
protocol negotiation can go a long way to make the situation a lot
better. That said, there is still the underlying problem that some
clients may want settings that differ from the server's. e.g. clients
with SSDs likely want generaldelta because they don't need sequential
I/O and SSD space is more expensive, so the smaller repository sizes
achieved with generaldelta are appreciated. But a server operator may
not want to force generaldelta on all clients because it would make
clients on mechanical hard drives slower! The point is revlog impedance
mismatch will occur and someone needs to spend the CPU cycles to rectify
the matter. I suspect this will be pushed to clients since distributed
CPU load is easier to deal with than centralized on the server. But, I
wouldn't be surprised if Mercurial allowed server operators to configure
the behavior. It's a hard problem. Time will tell.</p>
<p>In the mean time, just know that if you experiment with custom revlog
settings, push and pull operations will likely be slower. You may not
notice this on day-to-day operations. But on things like initial clone,
you could experience a massive slow-down.</p>
<p>Here's some timings with
<a href="https://hg.mozilla.org/mozilla-central">mozilla-central</a> with a
Mercurial 1.9 server and client on the same SSD-backed multi-core machine:</p>
<ul>
<li>clone default settings - 4:25</li>
<li>clone --uncompressed - 0:49</li>
<li>clone from generaldelta - 14:11</li>
<li>clone from generaldelta to generaldelta - 16:49</li>
<li>clone from generaldelta --uncompressed - 0:50</li>
<li>pull 2250 changesets, default from default - 6.7s</li>
<li>pull 2250 changesets, default from generaldelta - 17.9s</li>
<li>pull 2250 changesets, generaldelta from default - 28.5s</li>
<li>pull 2250 changesets, generaldelta from generaldelta - 20.0s</li>
</ul>
<p>As you can see, anything involving compression and generaldelta is
much slower. Once <em>bundle format 2</em> is fully implemented, I expect the
situation to improve.  Until then, know that you'll get a ~2.5-4x
slowdown from using generaldelta. You'll have to measure other
revlog formats for their impact.</p>
<p>In conclusion, Mercurial's revlog file format is an interesting and
tunable data structure. It works pretty well for most repositories. But
if you are the 1%, you might want to spend some time to investigate
changing its default configuration.</p>]]></content>
  </entry>
</feed>
