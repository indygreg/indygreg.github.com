<?xml version="1.0" encoding="UTF-8"?>
<feed
  xmlns="http://www.w3.org/2005/Atom"
  xmlns:thr="http://purl.org/syndication/thread/1.0"
  xml:lang="en"
   >
  <title type="text">Gregory Szorc's Digital Home</title>
  <subtitle type="text">Rambling on</subtitle>

  <updated>2015-10-22T10:17:03Z</updated>
  <generator uri="http://blogofile.com/">Blogofile</generator>

  <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog" />
  <id>http://gregoryszorc.com/blog/feed/atom/</id>
  <link rel="self" type="application/atom+xml" href="http://gregoryszorc.com/blog/feed/atom/" />
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Append I/O Performance on Windows]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/10/22/append-i/o-performance-on-windows" />
    <id>http://gregoryszorc.com/blog/2015/10/22/append-i/o-performance-on-windows</id>
    <updated>2015-10-22T02:15:00Z</updated>
    <published>2015-10-22T02:15:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Append I/O Performance on Windows]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/10/22/append-i/o-performance-on-windows"><![CDATA[<p>A few weeks ago, some coworkers were complaining about the relative
performance of Mercurial cloning on Windows. I investigated on my
brand new i7-6700K Windows 10 desktop machine and sure enough they were
correct: cloning times on Windows were several minutes slower than
Linux on the same hardware. What gives?</p>
<p>I performed a few clones with Python under a profiler. It pointed to a
potential slowdown in file I/O. I wanted more details so I fired up
<a href="https://technet.microsoft.com/en-us/library/bb896645.aspx">Sysinternals Process Monitor</a>
(strace for Windows) and captured data for a clone.</p>
<p>As I was looking at the raw system calls related to I/O, something
immediately popped out: <em>CloseFile()</em> operations were frequently
taking 1-5 <em>milliseconds</em> whereas other operations like opening, reading,
and writing files only took 1-5 <em>microseconds</em>. <strong>That's a 1000x
difference!</strong></p>
<p>I wrote a custom Python script to analyze an export of Process Monitor's
data. Sure enough, it said we were spending hundreds of seconds in
<em>CloseFile()</em> operations (it was being called a few hundred thousand
times). I posted the findings to some mailing lists.
<a href="https://groups.google.com/d/msg/mozilla.dev.platform/yupx2ToQ5T4/WAMC_Q-DCAAJ">Follow-ups</a>
in Mozilla's dev-platform list pointed me to
<a href="http://blogs.msdn.com/b/oldnewthing/archive/2011/09/23/10215586.aspx">an old MSDN blog post</a>
where it documents behavior similar to what I was seeing.</p>
<p>Long story short, <strong>closing file handles that have been appended to is
slow on Windows.</strong> This is apparently due to an implementation detail of
NTFS. Writing to a file in place is fine and only takes microseconds for
the open, write, and close. But if you append a file, closing the
associated file handle is going to take a few milliseconds. Even if you
are using Overlapped I/O (async I/O on Windows), the <em>CloseHandle()</em>
call to close the file handle blocks the calling thread! Seriously.</p>
<p>This behavior is in stark contrast to Linux and OS X, where system I/O
functions take microseconds (assuming your I/O subsystem can keep up).</p>
<p>There are two ways to work around this issue:</p>
<ol>
<li>Reduce the amount of file closing operations on appended files.</li>
<li>Use multiple threads for I/O on Windows.</li>
</ol>
<p>Armed with this knowledge, I dug into the guts of Mercurial and
proceeded to write a
<a href="https://selenic.com/repo/hg/rev/836291420d53">number</a>
<a href="https://selenic.com/repo/hg/rev/39d643252b9f">of</a>
<a href="https://selenic.com/repo/hg/rev/56a640b0f656">patches</a>
that drastically reduced the amount of file I/O system calls during
clone and pull operations. While I intend to write a blog post with the
full details, <strong>cloning the Firefox repository with Mercurial 3.6 on
Windows is now several minutes faster.</strong> Pretty much all of this is due
to reducing the number of file close operations by aggressively reusing
file handles.</p>
<p>I also
<a href="https://selenic.com/pipermail/mercurial-devel/2015-September/073788.html">experimented</a>
with moving file close operations to a separate thread on Windows. While
this change didn't make it into Mercurial 3.6, the results were very
promising. Even on Python (which doesn't have real asynchronous threads
due to the GIL), moving file closing to a background thread freed up the
main thread to do the CPU heavy work of processing data. This made clones
several minutes faster. (Python does release the GIL when performing an
I/O system call.) Furthermore, <strong>simply creating a dedicated thread for
closing file handles made Mercurial faster than 7-zip at writing tens of
thousands of files from an uncompressed tar archive</strong>. (I'm not going to
post the time for <em>tar</em> on Windows because it is embarassing.) That's a
Python process on Windows faster than a native executable that is lauded
for its speed (7-zip). Just by offloading file closing to a single
separate thread. Crazy.</p>
<p>I can optimize file closing in Mercurial all I want. However,
Mercurial's storage model relies on several files. For the Firefox
repository, we have to write ~225,000 files during clone. Assuming
1ms per file close (which is generous), that's 225s (or 3:45) wall
time performing file closes. That's not going to scale. I've already
started experimenting with alternative storage modes that initially use
1-6 files. This should enable Mercurial clones to run at over 100 MB/s
(yes, Python and Windows can do I/O that quickly if you are smart about
things).</p>
<p>My primary takeaway is that creating/appending to thousands of files
is slow on Windows and should be addressed at the architecture level
by not requiring thousands of files and at the implementation level
by minimizing the number of file close operations after write.
If you absolutely must create/append to thousands of files, use multiple
threads for at least closing file handles.</p>
<p>My secondary takeaway is that Sysinternals Process Monitor is amazing.
I used it against Firefox and immediately found
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1211090">performance concerns</a>.
It can be extremely eye opening to see how your higher-level code
is translated into function calls into your operating system and where
the performance hot spots are or aren't at the OS level.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Lowering the Barrier to Pushing to MozReview]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/10/14/lowering-the-barrier-to-pushing-to-mozreview" />
    <id>http://gregoryszorc.com/blog/2015/10/14/lowering-the-barrier-to-pushing-to-mozreview</id>
    <updated>2015-10-14T12:30:00Z</updated>
    <published>2015-10-14T12:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="MozReview" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Lowering the Barrier to Pushing to MozReview]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/10/14/lowering-the-barrier-to-pushing-to-mozreview"><![CDATA[<p>Starting today, a Mozilla LDAP account with Mercurial SSH access is no
longer required to <em>hg push</em> into
<a href="https://reviewboard.mozilla.org">MozReview</a> to initiate code review
with Mozilla projects.</p>
<p>The <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/mozreview/install.html">instructions for configuring your client to use MozReview</a>
have been updated to reflect how you can now push to MozReview over HTTP
using a Bugzilla API Key for authentication.</p>
<p>This change effectively enables first-time contributors to use MozReview
for code review. Before, you had to obtain an LDAP account and configure
your SSH client, both of which could be time consuming processes and
therefore discourage people from contributing. (Or you could just use
Bugzilla/Splinter and not get the benefits of MozReview, which many
did.)</p>
<p><strong>I encourage others to update contribution docs to start nudging people
towards MozReview over Bugzilla/patch-based workflows</strong> (such as
bzexport).</p>
<p><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1195856">Bug 1195856</a>
tracked this feature.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Serving Mercurial Clones from a CDN]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/09/01/serving-mercurial-clones-from-a-cdn" />
    <id>http://gregoryszorc.com/blog/2015/09/01/serving-mercurial-clones-from-a-cdn</id>
    <updated>2015-09-01T15:00:00Z</updated>
    <published>2015-09-01T15:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Serving Mercurial Clones from a CDN]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/09/01/serving-mercurial-clones-from-a-cdn"><![CDATA[<p>For the past few months, Mozilla has been
<a href="http://gregoryszorc.com/blog/2015/07/08/cloning-from-s3/">serving Mercurial clones from Amazon S3</a>.
We upload snapshots (called <em>bundles</em>) of large and/or high-traffic
repositories to S3. We have a custom Mercurial extension on the
client and server that knows how to exchange the URLs for these
snapshots and to transparently use them to bootstrap a clone. The
end result is drastically reduced Mercurial server load and faster
clone times. The benefits are seriously ridiculous when you operate
version control at scale.</p>
<p><a href="https://aws.amazon.com/cloudfront/">Amazon CloudFront</a> is a CDN.
You can easily configure it up to be backed by an S3 bucket. So
we did.</p>
<p><a href="https://hg.cdn.mozilla.net/">https://hg.cdn.mozilla.net/</a> is
Mozilla's CDN for hosting Mercurial data. Currently it's just bundles to
be used for cloning.</p>
<p>As of today, if you
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/bundleclone.html">install the bundleclone Mercurial extension</a>
and <em>hg clone</em> a repository on
<a href="https://hg.mozilla.org/">hg.mozilla.org</a> such as
<a href="https://hg.mozilla.org/mozilla-central">mozilla-central</a>
(<em>hg clone https://hg.mozilla.org/mozilla-central</em>), the CDN
URLs will be preferred by default. (Previously we preferred S3 URLs
that hit servers in Oregon, USA.)</p>
<p><strong>This should result in clone time reductions for Mozillians not
close to Oregon, USA</strong>, as the CloudFront CDN has servers all across
the globe and your Mercurial clone should be bootstrapped from the
closest and hopefully therefore fastest server to you.</p>
<p>Unfortunately, you do need the the aforementioned <em>bundleclone</em>
extension installed for this to work. But, this should only be
temporary: I've
<a href="https://mercurial.selenic.com/wiki/StaticBundlePlan">proposed</a>
integrating this feature into the core of Mercurial so if a client
talks to a server advertising pre-generated bundles the clone
offload <em>just works</em>. I already have tentative buy-in from one
Mercurial maintainer. So hopefully I can land this feature in
Mercurial 3.6, which will be released November 1. After that,
I imagine some high-traffic Mercurial servers (such as Bitbucket)
will be very keen to deploy this so CPU load on their servers
is drastically reduced.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[JSON APIs on hg.mozilla.org]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/08/18/json-apis-on-hg.mozilla.org" />
    <id>http://gregoryszorc.com/blog/2015/08/18/json-apis-on-hg.mozilla.org</id>
    <updated>2015-08-18T16:00:00Z</updated>
    <published>2015-08-18T16:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[JSON APIs on hg.mozilla.org]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/08/18/json-apis-on-hg.mozilla.org"><![CDATA[<p>I added a feature to Mercurial 3.4 that exposes JSON from Mercurial's
various <a href="https://hg.mozilla.org/mozilla-central/help/hgweb">web APIs</a>.
Unfortunately, due to the presence of legacy code on hg.mozilla.org
providing similar functionality, we weren't able to deploy this
feature to hg.mozilla.org when we deployed Mercurial 3.4 several weeks
ago.</p>
<p>I'm pleased to announce that as of today, JSON is now exposed from
hg.mozilla.org!</p>
<p>To access JSON output, simply add <strong>json-</strong> to the <em>command</em> name
in URLs. e.g. instead of
<a href="https://hg.mozilla.org/mozilla-central/rev/de7aa6b08234">https://hg.mozilla.org/mozilla-central/rev/de7aa6b08234</a>
use <a href="https://hg.mozilla.org/mozilla-central/json-rev/de7aa6b08234">https://hg.mozilla.org/mozilla-central/json-rev/de7aa6b08234</a>.
The full list of web commands, URL patterns, and their parameters are
<a href="https://hg.mozilla.org/mozilla-central/help/hgweb">documented</a> in
the <em>hgweb</em> help topic.</p>
<p>Not all web commands support JSON output yet. Not all web commands
expose all data available to them. If there is data you need but isn't
exposed, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Developer%20Services&amp;component=Mercurial%3A%20hg.mozilla.org">file a bug</a>
and I'll see what I can do.</p>
<p>Thanks go to Steven MacLeod for
<a href="https://reviewboard.mozilla.org/r/15617/">reviewing</a> the rather large
series it took to make this happen.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[moz.build metadata on hg.mozilla.org]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/08/04/moz.build-metadata-on-hg.mozilla.org" />
    <id>http://gregoryszorc.com/blog/2015/08/04/moz.build-metadata-on-hg.mozilla.org</id>
    <updated>2015-08-04T19:55:00Z</updated>
    <published>2015-08-04T19:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[moz.build metadata on hg.mozilla.org]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/08/04/moz.build-metadata-on-hg.mozilla.org"><![CDATA[<p>Sometime last week we enabled a new API on hg.mozilla.org:
<em>json-mozbuildinfo</em>. This endpoint will return JSON describing
moz.build-derived metadata about the files that changed in a commit.</p>
<p><a href="https://hg.mozilla.org/mozilla-central/json-mozbuildinfo/1164ec236273">Example</a>.
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/mozbuildinfo.html">Docs</a>.</p>
<p>We plan to eventually leverage this API to do cool things like
have MozReview automatically file bugs in the appropriate component and
assign appropriate reviewers given the set of changed files in a commit.</p>
<p>The API is currently only available on mozilla-central. And, we have
very conservative resource limits in place. So large commits may cause
it to error out. As such, the API is considered experimental. Also,
performance is not as optimal as it could be. You have to start
somewhere.</p>
<p>I'd like to thank Guillaume Destuynder (kang) for his help with the
security side of things. When I started on this project, I didn't think
I'd be writing
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/02e353037996/testing/docker/builder-hgweb-chroot/mozbuild-eval.c">C code for spawning secure processes</a>,
but here we are. In the not so distant future, I'll likely be adding
<a href="http://man7.org/linux/man-pages/man2/seccomp.2.html">seccomp(2)</a>
into the mix, which will make the execution environment as
or more secure than the Firefox content process sandbox, depending
on how it is implemented. The rabbit holes we find ourselves in to
implement proper security...</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[hg.mozilla.org Operational Workings Now Open Sourced]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/08/04/hg.mozilla.org-operational-workings-now-open-sourced" />
    <id>http://gregoryszorc.com/blog/2015/08/04/hg.mozilla.org-operational-workings-now-open-sourced</id>
    <updated>2015-08-04T14:30:00Z</updated>
    <published>2015-08-04T14:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[hg.mozilla.org Operational Workings Now Open Sourced]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/08/04/hg.mozilla.org-operational-workings-now-open-sourced"><![CDATA[<p>Just a few minutes ago, hg.mozilla.org reached an important milestone:
deployments are now performed via Ansible from our open source
<a href="https://hg.mozilla.org/hgcustom/version-control-tools">version-control-tools</a>
repository instead of via Puppet from Mozilla's private <em>sysadmins</em>
repository. This is important for a few reasons.</p>
<p>First, the code behind the operation of hg.mozilla.org is now open source
and available for the public to see and change. I strive for my work at
Mozilla to be open by default. With hg.mozilla.org's private Puppet
repository, people weren't able to see what was going on under the
covers. Nor were they empowered to change anything. This may come as a
shock, but even I don't have commit privileges to the internal Puppet
repository that was previously powering hg.mozilla.org! I did have read
access. But any change I wanted to make involved me proxying it through
one of two people. It was tedious, made me feel uncomfortable for having to
nag people to do my work, and slowed everyone down. We no longer have this
problem, thankfully.</p>
<p>Second, having the Ansible code in version-control-tools enables us to
use the same operational configuration in production as we do in our
Docker test environment. I can now spin up a cluster of Docker
containers that behave very similarly to the production servers (which
aren't running Docker). This enables us to write end-to-end tests of
complex systems running across multiple Docker containers and have
relatively high confidence that our production and testing environments
behave very similarly. In other words, I can test complex interactions
between multiple systems all from my local machine - even from a plane!
For example, we can and do test that SSH connections to a simulated
production environment running in Docker behave as expected, complete
with an OpenSSH server speaking to an OpenLDAP server for SSH public
key lookup. While we still have many tests to write, we had no such
tests a year ago and every production deployment was a
cross-your-fingers type moment. Having comprehensive tests gives us
confidence to move fast and not break things.</p>
<p>One year ago, hg.mozilla.org's infrastructure was opaque, didn't have
automated tests, and was deployed too seldomly. There was the often
correct perception that changing this critical-to-Mozilla service was
difficult and slow. Today, things couldn't be more different. <strong>The
hg.mozilla.org infrastructure is open, we have tests, and we can and
do deploy multiple times per day without forward notice and without
breaking things.</strong> I love this brave new world of open infrastructure
and moving fast.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Mercurial 3.5 Released]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/31/mercurial-3.5-released" />
    <id>http://gregoryszorc.com/blog/2015/07/31/mercurial-3.5-released</id>
    <updated>2015-07-31T13:15:00Z</updated>
    <published>2015-07-31T13:15:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Mercurial 3.5 Released]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/31/mercurial-3.5-released"><![CDATA[<p>Mercurial 3.5 was released today (following Mercurial's time-based
schedule of releasing a new version every 3 months).</p>
<p>There were roughly 1000 commits between 3.4 and 3.5, making this a
busy version. Although, 1000 commits per release has become the new
norm, as development on Mercurial has accelerated in the past few
years.</p>
<p>In my mind, the major highlight of Mercurial 3.5 is that the new
<em>bundle2</em> wire protocol for transferring data during <em>hg push</em>
and <em>hg pull</em> is now enabled by default on the client. Previously,
it was enabled by default only on the server.
<a href="https://hg.mozilla.org/">hg.mozilla.org</a> is running Mercurial 3.4,
so clients that upgrade to 3.5 today will be speaking to it using
the new wire protocol.</p>
<p>The <em>bundle2</em> wire protocol succeeds the existing protocol
(which has been in place for years) and corrects many of its
deficiencies. Before bundle2, pull and push operations were not
atomic because Mercurial was performing a separate API call for
each piece of data. It would start by transferring changeset data
and then have subsequent transfers of metadata like bookmarks
and phases. As you can imagine, there were race conditions and
scenarios where pushes could be incomplete (not atomic). bundle2
transfers all this data in one large chunk, so there are much
stronger guarantees for data consistency and for atomic operations.</p>
<p>Another benefit of bundle2 is it is a fully extensible data exchange
format. Peers can add additional <em>parts</em> to the payload. For
extensions that wish to transfer additional metadata (like
Mozilla's <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/pushlog.html">pushlog</a>
data), they can simply add this directly into the data
stream without requiring additional requests over the wire protocol.
This translates to fewer network round trips and faster push and pull
operations.</p>
<p>The <em>progress</em> extension has been merged into Mercurial's core and
is enabled by default. It is now safe to remove the
<em>extensions.progress</em> config option from your hgrc.</p>
<p>Mercurial 3.5 also (finally) drops support for Python 2.4 and 2.5.
Hopefully nobody reading this is still running these ancient and
unsupported versions of Python. This is a win for Mercurial developers,
as we were constantly having to work around deficiencies with these old
Python releases. There were dozens of commits removing hacks and
workarounds for Python 2.4 and 2.5. Dropping 2.4 and 2.5 also
means Python 3 porting can begin in earnest. However, this isn't a high
priority for anyone, so don't hold your breath.</p>
<p>There were a number of performance improvements in 3.5:</p>
<ul>
<li>operations involving obsolescence markers are faster (for users of
  changeset evolution)</li>
<li>various revsets were optimized</li>
<li>parts of phases calculation are now performed in C. The <em>not public()</em>
  revset should be much faster.</li>
<li><em>hg status</em> and things walking the filesystem are faster (Mozillians
  should be using <em>hgwatchman</em> to make <em>hg status</em> insanely fast)</li>
</ul>
<p>A <em>ui.allowemptycommit</em> config option was introduced to control whether
empty commits are allowed. Mozillians manually creating <em>trychooser</em>
commits may run into problems creating empty commits without this
option (a better solution is to use <em>mach push-to-try</em>).</p>
<p>Work is progressing on per-directory manifests. Currently, Mercurial
stores the mapping of files to content in a giant list called the
manifest. For repositories with tens or hundreds of thousands of
files, decoding and reading large manifests is very CPU intensive.
Work is being done to enable Mercurial to split manifests by directory.
So instead of a single manifest, there are several. This is a prequisite
to <em>narrow clone</em>, which is the ability to clone history for a subset
of files (like how Subversion works). This work will eventually enable
repositories with millions of files to exist without significant
performance loss. It will also allow
<a href="/blog/2014/09/09/on-monolithic-repositories/">monolithic repositories</a>
to exist without the common critique that they are too unwieldy to
use because they are so large.</p>
<p><em>hgignore</em> files now have an <em>include:</em> and <em>subinclude:</em> syntax that
can be used to include other files containing ignore rules. This
feature is useful for a number of reasons. First, it makes sense for
ignore rules to live in the directory hierarchy next to paths they
impact. Second, for people working with monolithic repositories, it
means you can <em>export</em> a sub-directory of your monorepo (to e.g. a
Git repository) and its ignore rules - being defined in local
directories - can still work. (I'm pretty sure Facebook is using this
approach to make its syncing of directories/projects from its Mercurial
monorepo to GitHub easier to manage.)</p>
<p>Significant work has been done on the template parser. If you have
written custom templates, you may find that Mercurial 3.5 is more
strict about parsing certain syntax.</p>
<p>Revsets with chained <em>or</em> no longer result in stack exhaustion. Before,
programmatically generated revsets like <em>1 or 2 or 3 or 4 or 5 or 6...</em>
would likely fail.</p>
<p>Interactions with servers over SSH should now display server output in
real time. Before, server output was buffered and only displayed at the
end of the operation. (You may not see this on hg.mozilla.org until
the server is upgraded to 3.5, which is planned for early September.)</p>
<p>There are now static analysis checks in place to ensure that Mercurial
config options have corresponding documentation in <em>hg help config</em>.
As a result, a lot of formerly undocumented options are now documented.</p>
<p>I contributed
<a href="/blog/2015/07/31/my-contributions-to-mercurial-3.5/">various improvements</a>.
These include:</p>
<ul>
<li>auto sharing repository data during clone</li>
<li>clone and pull performance improvements</li>
<li><em>hg help scripting</em></li>
</ul>
<p>There were tons of other changes, of course. See the
<a href="https://mercurial.selenic.com/wiki/WhatsNew#Mercurial_3.5_.282015-07-31.29">official release notes</a>
and the
<a href="https://mercurial.selenic.com/wiki/UpgradeNotes#A3.5:_no_more_support_for_Python_2.4_or_2.5">upgrade notes</a>
for more.</p>
<p>The <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/installing.html">Mercurial for Mozillians Installing Mercurial</a>
article provides a Mozilla tailored yet generally applicable guide for
installing or upgrading Mercurial to 3.5. As always, conservative
software users may want to wait until September 1 for the 3.5.1 point
release to fix any issues or regressions from 3.5.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[My Contributions to Mercurial 3.5]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/31/my-contributions-to-mercurial-3.5" />
    <id>http://gregoryszorc.com/blog/2015/07/31/my-contributions-to-mercurial-3.5</id>
    <updated>2015-07-31T10:55:00Z</updated>
    <published>2015-07-31T10:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[My Contributions to Mercurial 3.5]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/31/my-contributions-to-mercurial-3.5"><![CDATA[<p>Mercurial 3.5 was released today. I contributed some small
improvements to this version that I thought I'd share with the world.</p>
<p>The feature I'm most proud of adding to Mercurial 3.5 is what I'm
referring to as <em>auto share</em>. The existing <em>hg share</em> extension/command
enables multiple checkouts of a repository to share the same backing
repository store. Essentially the <em>.hg/store</em> directory is a symlink
to shared directory. This feature has existed in Mercurial for years
and is essentially identical to the <em>git worktree</em> feature just
recently added in Git 2.5.</p>
<p>My addition to the <em>share</em> extension is the ability for Mercurial to
automatically perform an <em>hg clone</em> + <em>hg share</em> in the same operation.
If the <em>share.pool</em> config option is defined, <em>hg clone</em>
will automatically clone or pull the repository data somewhere inside
the directory pointed to by <em>share.pool</em> then create a new working copy
from that shared location. But here's the magic: <strong>Mercurial can
automatically deduce that different remotes are the same logical
repository (by looking at the root changeset) and automatically have
them share storage</strong>. So if you first <em>hg clone</em> the <em>canonical</em>
repository then later do a <em>hg clone</em> of a <em>fork</em>, Mercurial will
pull down the changesets unique to the fork into the previously
created shared directory and perform a checkout from that. Contrast
with performing a full clone of the fork. <strong>If you are cloning multiple
repositories that are logically derived from the same original one,
this can result in a significant reduction of disk space and network
usage.</strong> I wrote this feature with automated consumers in mind,
particularly continuous integration systems. However, there is also
mode more suitable for humans where repositories are pooled not by their
root changeset but by their URL. For more info, see <em>hg help -e share</em>.</p>
<p>For Mercurial 3.4, I contributed changes that refactored how Mercurial's
tags cache works. This cache was a source of performance problems at
Mozilla's scale for many years. Since upgrading to Mercurial 3.4,
Mozilla has not encountered any significant performance problems with
the cache on either client or server as far as I know.</p>
<p>Building on this work, Mercurial 3.5 supports transferring tags cache
entries from server to client when clients clone/pull. Before, clients
would have to recompute tags cache entries for pulled changesets. On
repositories that are very large in terms of number of files (over 50,000)
or heads (hudreds or more), this could take several dozen seconds or
even minutes. This would manifest as a delay either during or after
initial clone. In Mercurial 3.5 - assuming both client and server
support the new <em>bundle2</em> wire protocol - the cache entries are
transferred from server to client and no extra computation needs to
occur. The client does pay a very small price for transferring this
additional data over the wire, but the payout is almost always worth it.
<strong>For large repositories, this feature means clones are usable sooner.</strong></p>
<p>A few weeks ago, a coworker told me that connections to a Mercurial
server were timing out mid clone. We investigated and discovered a
potential for a long CPU-intensive pause during clones where Mercurial
would not touch the network. On this person's under-powered EC2
instance, the pause was so long that the server's inactivity timeout
was triggered and it dropped the client's TCP connection. I refactored
Mercurial's cloning code so there is no longer a pause. There should
be no overall change in clone time, but there is no longer a perceivable
delay between applying changesets and manifests where the network could
remain idle. This investigation also revealed some potential follow-up
work for Mercurial to be a bit smarter about how it interacts with
networks.</p>
<p>Finally, I contributed <em>hg help scripting</em> to Mercurial's help database.
This help topic covers how to use Mercurial from scripting and other
automated environments. It reflects knowledge I've learned from seeing
Mercurial used in automation at Mozilla.</p>
<p>Of course, there are plenty of other changes in Mercurial 3.5. Stay
tuned for another blog post.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Prompting to Run mach mercurial-setup]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/17/prompting-to-run-mach-mercurial-setup" />
    <id>http://gregoryszorc.com/blog/2015/07/17/prompting-to-run-mach-mercurial-setup</id>
    <updated>2015-07-17T11:35:00Z</updated>
    <published>2015-07-17T11:35:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Prompting to Run mach mercurial-setup]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/17/prompting-to-run-mach-mercurial-setup"><![CDATA[<p>Earlier this week, I landed some changes to the Firefox development
environment that aggressively make <em>mach</em> prompt to run <em>mach
mercurial-setup</em>. Full details in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1182677">bug 1182677</a>.</p>
<p>As expected, the change resulted in a fair amount of whining and
bemoaning among various Firefox developers. I wanted to take some time
to explain why we moved forward, even though we knew not everyone would
like the feature.</p>
<p>My official job title at Mozilla is <em>Developer Productivity Engineer</em>.
My job is to make you do your job better.</p>
<p>I've been an employee at Mozilla for four years and in that time I've
witnessed a surprising lack of understanding around version control
tools. (I don't think Mozilla is significantly different from most
other companies here.) I find that a significant number of people
are practicing sub-optimal version control workflows because they don't
know any better (common) or because they are unwilling to change from
learned habits.</p>
<p>Furthermore, Mercurial is a highly customizable tool. A lot of
Mozillians have spent a lot of time developing useful extensions to
Mercurial that enable Mozillians to use Mercurial more effectively and
to thus become more productive. The latest epic time-saving hack
is <a href="http://www.ncalexander.net/blog/2015/07/02/build-fennec-frontend-fast-with-mach-artifact/">Nick Alexander's work to make Fennec build 80% faster by
having deep integration with version control</a>.</p>
<p><em>mach mercurial-setup</em> is almost
<a href="/blog/2013/07/29/mercurial-setup-wizard-for-firefox-development/">two years old</a>.
Yet, when assisting my fellow Mozillians with Mercurial issues, my
"have you run mach mercurial-setup?" question is still often met with
blank stares followed by "wait, there's a mach mercurial-setup?!" What's
even more frustrating is people wrongly believing that Mercurial can't
do things like rebasing and then spreading misinformation about the
lackings of Mercurial. (Mercurial has many advanced features disabled
out of the box so new users don't footgun themselves.)</p>
<p>Just like Firefox would be irrelevant if it didn't have millions of users,
your awesome tool is mostly irrelevant if you are its only user. That's
why when I hear of someone say they created an amazing tool for
themselves or modified a third party tool without sending the improvements
upstream, my blood pressure rises a little. It rises because here this
person did something awesome and they or some limited subset of people
who happened to be following the person on Twitter or reading their blog
at that point in time managed to a) know about the tool b) take the
effort to install it. The uptake rate is insanely low and return on
investment for that tool is low. It results in duplication of effort.
I find this painfully frustrating because I want everyone to have easy
access to the best tools available. This requires that tools are well
advertised and easy to install and use.</p>
<p>The primary goal of <em>mach mercurial-setup</em> is to make it super easy for
anyone to have an optimal Mercurial experience. It was apparent to me that
despite <em>mach mercurial-setup</em> existing, numerous people didn't know it
existed or weren't using it. Your awesome tool isn't very awesome unless
people are using it. And a lot of the awesome tools people have built
around Mercurial at Mozilla weren't being utilized and lots of
productivity wins were thus being unrealized. Forcefully pushing <em>mach
mercurial-setup</em> onto people is thus an attempt to unlock unrealized
productivity wins and to make people happier about the state of their
tools.</p>
<p>I'm not thrilled that mach's prompting to run <em>mach mercurial-setup</em> is
as disruptive as it is. It's bad user experience. I know better. But,
(and this is explained somewhat in the bug), other solutions are more
complicated and have other gotchas. The current, invasive implementation
was the easiest to implement and has the biggest bang for the buck in
terms of adoption. We knew people would complain about it. But from
my perspective, it was do this or do nothing. And nothing hadn't been
very effective. So we did something.</p>
<p>There has been lots of feedback about the change this week. Most
surprising to me is the general sentiment of "I don't want something
automatically changing my hgrc file." I find this surprising because
<em>mach mercurial-setup</em> puts the user firmly in control by prompting
before doing anything, thus respecting user choice and avoiding gotchas
and unwanted changes. It's clear this property needs to be advertised a
bit more so people aren't scared to run <em>mach mercurial-setup</em> and don't
spread fear, uncertainty, and doubt about the tool to others. (I also
find it somewhat surprising people would think this in the first place:
I'd like to think we'd implicitly trust most Mozillians to implement
tools that respect user choice and don't do <em>malicious</em> things.)</p>
<p>Like all software, things can and will change. The user experience of
this new feature isn't terrific. We'll iterate on it. If you want to
help enact change, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=mach">file a bug in Core :: mach</a>
(for now) and we'll go from there.</p>
<p>Thank you for your patience and your understanding.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[MozReview Statistics July 2015]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/16/mozreview-statistics-july-2015" />
    <id>http://gregoryszorc.com/blog/2015/07/16/mozreview-statistics-july-2015</id>
    <updated>2015-07-16T14:00:00Z</updated>
    <published>2015-07-16T14:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="MozReview" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[MozReview Statistics July 2015]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/16/mozreview-statistics-july-2015"><![CDATA[<p>As of today, ~15.6% of commits landing in Firefox in July have gone
through <a href="https://reviewboard.mozilla.org/">MozReview</a> or have been produced
on machines that have used MozReview. This is still a small percentage
of overall commits. But, signs are that the percentage is going up. Last
month, about half as many commits exhibited the same signature. It's
only July 16 and we've already passed the total from June.</p>
<p>What I find interesting is the differences between commits that have
gone through MozReview versus the rest. When you look at the diff
statistics (a quick proxy of change size), we find that MozReview
commits tend to be smaller. The median <em>adds</em> as reported by diff stat
(basically lines that were changed) is 12 for MozReview versus 17
elsewhere. The average is 58 for MozReview versus 100 elsewhere. For
number of files modified, MozReview averages 2.59 versus elsewhere's
2.71. (These numbers exclude some specific large commits that appeared to
be bulk imports of external projects and drove up the non-MozReview
figures.)</p>
<p>It's entirely possible the root cause behind the discrepancy is a
side-effect of the population of MozReview users: perhaps MozReview
users just write smaller commits. However, I'd like to think it's because
MozReview makes it easier to manage multiple commits and people are taking
advantage of that (this is an explicit design goal of MozReview). Whatever
the root cause, I'm glad diffs are smaller.
As I've <a href="/blog/2014/10/27/implications-of-using-bugzilla-for-firefox-patch-development/">written about before</a>,
smaller commits are easier to review and land, thus enabling projects to
move faster.</p>
<p>I have a quarterly goal to remove the requirement for a Mozilla LDAP
account to push to MozReview. That will allow first time contributors to
use MozReview. This will be a huge win, as we can do much more magic in
the MozReview world than we can from vanilla Bugzilla (automatic bug
filing, automatic reviewer assignment, etc). Unofficially, I'd like to
have more than 50% of Firefox commits go through MozReview by the end of
the year.</p>]]></content>
  </entry>
</feed>
