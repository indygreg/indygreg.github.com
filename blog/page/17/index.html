


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Pollinating  
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20101114

-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>Gregory Szorc's Digital Home
</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom" />
<link rel="stylesheet" href="/style/style.css" type="text/css" />
<link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />


  </head>
  <body>
    <div id="wrapper">
      
  <div id="menu">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/notes">Notes</a></li>
    <li><a href="/work.html">Work</a></li>
    <li><a href="/skills.html">Skills</a></li>
    <li><a href="/thoughts.html">Thoughts</a></li>
    <li><a href="/resume.pdf">Resume</a></li>
  </ul>
</div>


      <div id="page">
        <div id="page-bgtop">
          <div id="page-bgbtm">
              <div id="content">
                
  
<div class="blog_post">
  <a name="importance-of-hosting-your-version-control-server"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/11/13/importance-of-hosting-your-version-control-server" rel="bookmark" title="Permanent Link to Importance of Hosting Your Version Control Server">Importance of Hosting Your Version Control Server</a></h2>
  <small>November 13, 2013 at 09:25 AM | categories: 

<a href='/blog/category/git'>Git</a>, <a href='/blog/category/mercurial'>Mercurial</a>, <a href='/blog/category/mozilla'>Mozilla</a>
 | <a href="http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>The subject of where to host version control repositories comes up a lot
at Mozilla. It takes many forms:</p>
<ul>
<li>We should move the Firefox repository to GitHub</li>
<li>I should be allowed to commit to GitHub</li>
<li>I want the canonical repository to be hosted by Bitbucket</li>
</ul>
<p>When Firefox development is concerned, Release Engineerings puts down
their foot and insists the canonical repository be hosted by Mozilla,
under a Mozilla hostname. When that's not possible, they set up a mirror
on Mozilla infrastructure.</p>
<p>I think a
<a href="https://groups.google.com/d/topic/jenkinsci-dev/-myjRIPcVwU/discussion">recent issue with the Jenkins project</a>
demonstrates why hosting your own version control server is important.
The gist is someone force pushed to a bunch of repos hosted on GitHub.
They needed to involve GitHub support to recover from the issue. While
it appears they largely recovered (and GitHub support deserves kudos - I
don't want to take away from their excellence), this problem would have
been avoided or the response time significantly decreased if the Jenkins
people had direct control over the Git server: they either could have
installed a custom hook that would have prevented the pushes or had
access to the reflog so they could have easily seen the last pushed
revision and easily forced pushed back to it. GitHub doesn't have a
mechanism for defining pre-* hooks, doesn't allow defining custom
hooks (a security and performance issue for them), and doesn't
expose the reflog data.</p>
<p>Until repository hosting services expose full repository data (such as
reflogs) and allow you to define custom hooks, accidents like these will
happen and the recovery time will be longer than if you hosted the repo
yourself.</p>
<p>It's possible repository hosting services like GitHub and Bitbucket will
expose these features or provide a means to quickly recover. If so,
kudos to them. But larger, more advanced projects will likely employ
custom hooks and considering custom hooks are a massive security and
performance issue for any hosted service provider, I'm not going to
hold my breath this particular feature is rolled out any time soon.
This is unfortunate, as it makes projects seemingly choose between
low risk/low convenience and GitHub's vibrant developer community.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/11/13/importance-of-hosting-your-version-control-server#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="mercurial-2.8-released"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/11/08/mercurial-2.8-released" rel="bookmark" title="Permanent Link to Mercurial 2.8 released">Mercurial 2.8 released</a></h2>
  <small>November 08, 2013 at 02:30 PM | categories: 

<a href='/blog/category/mercurial'>Mercurial</a>, <a href='/blog/category/mozilla'>Mozilla</a>
 | <a href="http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p><a href="http://mercurial.selenic.com/">Mercurial</a> 2.8 has been released.</p>
<p>The <a href="http://mercurial.selenic.com/wiki/WhatsNew#Mercurial_2.8_.282013-11-1.29">changes</a>
aren't as sexy as previous releases. But there are a handful of bug
fixes that seem useful to pull in. People may also find the new <em>shelve</em>
extension useful.</p>
<p>I encourage Mozillians to keep their Mercurial up to date. I once went
around the San Francisco office and stood behind people as they
upgraded to a modern Mercurial. For the next few weeks I was hearing a
lot of "OMG Mercurial is so much better now." Don't handicap yourself by
running an older, buggy Mercurial.</p>
<p>If you don't yet feel comfortable running 2.8, 2.7 should be safe.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/11/08/mercurial-2.8-released#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="using-mercurial-to-query-mozilla-metadata"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata" rel="bookmark" title="Permanent Link to Using Mercurial to query Mozilla metadata">Using Mercurial to query Mozilla metadata</a></h2>
  <small>November 08, 2013 at 09:42 AM | categories: 

<a href='/blog/category/mercurial'>Mercurial</a>, <a href='/blog/category/mozilla'>Mozilla</a>
 | <a href="http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>I have updated my
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/default/hgext/mozext">Mercurial extension tailored for Gecko/Firefox development</a>
with features that support rich querying of Mozilla/Gecko-development
specific metadata!</p>
<p>The extension now comes with a bug full of
<a href="http://www.selenic.com/hg/help/revsets">revision set</a> selectors and
<a href="http://www.selenic.com/hg/help/templates">template keywords</a>. You can
use them to query and format Mozilla-central metadata from the
repository.</p>
<h2>Revision set selectors</h2>
<p>You can now select changesets referencing a specific bug number:</p>
<pre><code>hg log -r 'bug(931383)'
</code></pre>
<p>Or that were reviewed by a specific person:</p>
<pre><code>hg log -r 'reviewer(gps)'
</code></pre>
<p>Or were reviewed or not reviewed:</p>
<pre><code>hg log -r 'reviewed()'
hg log -r 'not reviewed()'
</code></pre>
<p>You can now select changesets that are present in a specific tree:</p>
<pre><code>hg log -r 'tree(central)'
</code></pre>
<p>I've also introduced support to query changesets <em>you</em> influenced:</p>
<pre><code>hg log -r 'me()'
</code></pre>
<p>(This finds changesets you authored or reviewed.)</p>
<p>You can select changesets that initially landed on a specific tree:</p>
<pre><code>hg log -r 'firstpushtree(central)'
</code></pre>
<p>You can select changesets marked as <em>DONTBUILD</em>:</p>
<pre><code>hg log -r 'dontbuild()'
</code></pre>
<p>You can select changesets that don't reference a bug:</p>
<pre><code>hg log -r 'nobug()'
</code></pre>
<p>You can select changesets that were <em>push heads</em> for a tree:</p>
<pre><code>hg log -r 'pushhead(central)'
</code></pre>
<p>(This would form the basis of a push-aware bisection tool - an excellent
idea for a future feature in this extension.)</p>
<p>You can combine these revset selector functions with other revset
selectors to do some pretty powerful things.</p>
<p>To select all changesets on inbound but not central:</p>
<pre><code>hg log -r 'tree(inbound) - tree(central)'
</code></pre>
<p>To find all your contributions on beta but not release:</p>
<pre><code>hg log -r 'me() &amp; (tree(beta) - tree(release))'
</code></pre>
<p>To find all changesets referencing a specific bug that have landed in
Aurora:</p>
<pre><code>hg log -r 'bug(931383) and tree(aurora)'
</code></pre>
<p>To find all changesets marked <em>DONTBUILD</em> that landed directly on central:</p>
<pre><code>hg log -r 'dontbuild() and firstpushtree(central)'
</code></pre>
<p>To find all non-merge changesets that don't reference a bug:</p>
<pre><code>hg log -r 'not merge() and nobug()'
</code></pre>
<p>Neato!</p>
<h2>Template keywords</h2>
<p>You can also now print some Mozilla information when using templates.</p>
<p>To print the main bug of a changeset, use:</p>
<pre><code>{bug}
</code></pre>
<p>To retrieve all referenced bugs:</p>
<pre><code>{bugs} {join(bugs, ', ')}
</code></pre>
<p>To print the reviewers:</p>
<pre><code>{reviewer} {join(reviewers, ', ')}
</code></pre>
<p>To print the first version a changeset appeared in a specific channel:</p>
<pre><code>{firstrelease} {firstbeta} {firstaurora} {firstnightly}
</code></pre>
<p>To print the <strong>estimated</strong> first Aurora and Nightly date for a
changeset, use:</p>
<pre><code>{auroradate} {nightlydate}
</code></pre>
<p>(Getting the exact first Aurora and Nightly dates requires consulting
3rd party services, which we don't currently do. I'd like to
eventually integrate these into the extension. For now, it just
estimates dates from the pushlog data.)</p>
<p>You can also print who and where pushed a changeset:</p>
<pre><code>{firstpushuser} {firstpushtree}
</code></pre>
<p>You can also print the TBPL URL with the results of the first push:</p>
<pre><code>{firstpushtbpl}
</code></pre>
<p>Here is an example that prints channel versions and dates for each
changesets:</p>
<pre><code>hg log --template '{rev} Nightly: {firstnightly} {nightlydate}; Aurora {firstaurora} {auroradate}; Beta: {firstbeta}; Release: {firstrelease}\n'
</code></pre>
<h2>Putting it all together</h2>
<p>Of course, you can combine selectors and templates to create some
mighty powerful queries.</p>
<p>To look at your impact on Mozilla, do something like:</p>
<pre><code>hg log --template '{rev} Bug {bug}; Release {firstrelease}\n' -r 'me()'
</code></pre>
<p>You can easily forumate a status report for your activity in the past
week:</p>
<pre><code>hg log --template '{firstline(desc)}\n' -r 'firstpushdate(-7) and me()'
</code></pre>
<p>You can also query Mercurial to see where changesets have been landing
in the past 30 days:</p>
<pre><code>hg log --template '{firstpushtree}\n' -r 'firstpushdate(-30)' | sort | uniq -c
</code></pre>
<p>You can see who has been reviewing lots of patches lately:</p>
<pre><code>hg log --template '{join(reviewers, "\n")}\n' -r 'firstpushdate(-30)' | sort | uniq -c | sort -n
</code></pre>
<p>(smaug currently has the top score, edging out my 116 reviews with 137.)</p>
<p>If you want to reuse templates (instead of having to type them on the
command line), you can save them as <em>style files</em>. Search
<a href="https://www.google.com/search?q=mercurial+style+files">the Internets</a>
to learn how to use them. You can even change your default style so
the default output from <em>hg log</em> contains everything you'd ever want to
know about a changeset!</p>
<h2>Keeping it running</h2>
<p>Many of the queries rely on data derived from multiple repositories and
pushlog data that is external to the repository.</p>
<p>To get best results, you'll need to be running a monolithic/unified
Mercurial repository. You can either assemble one locally with this
extension by periodically pulling from the separate repos:</p>
<pre><code>hg pull releases
hg pull integration
</code></pre>
<p>Or, you can pull from
<a href="http://hg.gregoryszorc.com/gecko">my personal unified repo</a>.</p>
<p>You will also need to ensure the pushlog data is current. If you pull
directly from the official repos, this will happen automatically. To be
sure, run:</p>
<pre><code>hg pushlogsync
</code></pre>
<p>Finally, you can force a repopulation of cached bug data by running:</p>
<pre><code>hg buginfo --reset
</code></pre>
<p>Over time, I want all this to automagically work. Stay tuned.</p>
<h2>Comments and future improvements</h2>
<p>I implemented this feature to save myself from having to go troving
through Bugzilla and repository history to answer questions and to
obtain metrics. I can now answer many questions via simple Mercurial
one-liners.</p>
<p>Custom revision set selectors and template keywords are a pretty nifty
feature of Mercurial. They demonstrate how you can extend Mercurial to
be aware of more than just tracking commits and files. As I've
<a href="/blog/2013/05/12/thoughts-on-mercurial-%28and-git%29/">said before</a>
and will continue to say, the extensibility of Mercurial is
really its killer feature, especially for organizations with
well-defined processes (like Mozilla). The kind of extensibility I
achieved with this extension with custom queries and formatting
functions is just not possible with Git (at least not with the reference
C implementation that the overwhelming majority of Git users use).</p>
<p>There are numerous improvements that can be made to the extension.
Obviously more revision set selectors and template keywords can be
added. The parsing routine to extract bugs and reviewers isn't the most
robust in the world. I copied some existing Mozilla code. It does well
at detecting string patters but doesn't cope well with extracting lists.</p>
<p>I'd also love to better integrate Mercurial with automation
results so you can do things like expose a <em>greenpush()</em> selector and do
things like <em>hg up -r 'last(tree(inbound)) and greenpush()'</em> (which
of course could be exposed as <em>lastgreen(inbound)</em>. Wouldn't
that be cool! (This would be possible if we had better APIs for querying
individual push results.) It would also be possible to have the
Mercurial server expose this data as repository data so clients pull it
automatically. That would prevent clients from all needing to query the
same 3rd party services. Just a crazy thought.</p>
<p>Speed can be an issue. Calculating the release information
(<em>{firstnightly}</em> etc) is currently slower than I'd like. This is mostly
due to me using inefficient algorithms and not caching things where I
should. Speed issues should be fixed in due time.</p>
<p>Please let me know if you run into any problems or have suggestions for
improvements. If you want to implement your own revision set selectors
or template keywords, it's <a href="https://hg.mozilla.org/users/gszorc_mozilla.com/hgext-gecko-dev/file/35bb3c96d786/__init__.py#l705">easier</a>
than you think! I will happily accept patches. Keep in mind that
Mercurial can integrate with 3rd party services. So if you want to
supplement repository data with data from a HTTP+JSON web service,
that's very doable. The sky is the limit.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/11/08/using-mercurial-to-query-mozilla-metadata#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="macbook-pro-firefox-build-times-comparison"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/11/05/macbook-pro-firefox-build-times-comparison" rel="bookmark" title="Permanent Link to MacBook Pro Firefox Build Times Comparison">MacBook Pro Firefox Build Times Comparison</a></h2>
  <small>November 05, 2013 at 10:00 AM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>Many developers use MacBook Pros for day-to-day Firefox development.
So, I thought it would be worthwhile to perform a comparison of
Firefox build times for various models of MacBook Pros.</p>
<h2>Test setup</h2>
<p>The numbers in this post are obtained from 3 generations of MacBook
Pros:</p>
<ol>
<li>
<p>A 2011 Sandy Bridge 4 core x 2.3 GHz with 8 GB RAM and an aftermarket
   SSD.</p>
</li>
<li>
<p>A 2012 Ivy Bridge retina with 4 core x 2.6 GHz, 16 GB RAM, and a
   factory SSD (or possibly flash storage).</p>
</li>
<li>
<p>A 2013 Haswell retina with 4 core x 2.6 GHz, 16 GB RAM, and flash
   storage.</p>
</li>
</ol>
<p>All machines were running OS X 10.9 Mavericks and were using the
Xcode 5.0.1 toolchain (<em>Xcode 5 clang: Apple LLVM version 5.0
(clang-500.2.79) (based on LLVM 3.3svn)</em>) to build.</p>
<p>The power settings prevented machine sleep and machines were plugged
into A/C power during measuring. I did not use the machines while
obtaining measurements.</p>
<p>The 2012 and 2013 machines were very vanilla OS installs. However,
the 2011 machine was my primary work computer and may have had a
few background services running and may have been slower due to
normal wear and tear. The 2012 machine was a loaner machine from
IT and has an unknown history.</p>
<p>All data was obtained from mozilla-central revision d4a27d8eda28.</p>
<p>The mozconfig used contained:</p>
<p>export MOZ_PSEUDO_DERECURSE=1
  mk_add_options MOZ_OBJDIR=@TOPSRCDIR@/obj-firefox.noindex</p>
<p>Please note that the objdir name ends with <em>.noindex</em> to prevent Finder
from indexing build files.</p>
<p>I performed all tests multiple times and used the fastest time. I used
<em>time</em> command for obtaining measurements of wall, user, and system
time.</p>
<h2>Results</h2>
<h3>Configure Times</h3>
<p>The result of <em>mach configure</em> is as follows:</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>29.748</td>
    <td>17.921</td>
    <td>11.644</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>26.765</td>
    <td>15.942</td>
    <td>10.501</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>21.581</td>
    <td>12.597</td>
    <td>8.595</td>
  </tr>
</table>

<h3>Clobber build no ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
not enabled.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>22:29 (1349)</td>
    <td>145:35 (8735)</td>
    <td>12:03 (723)</td>
    <td>157:38 (9458)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>15:00 (900)</td>
    <td>94:18 (5658)</td>
    <td>8:14 (494)</td>
    <td>102:32 (6152)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>11:13 (673)</td>
    <td>69:55 (4195)</td>
    <td>6:04 (364)</td>
    <td>75:59 (4559)</td>
  </tr>
</table>

<h3>Clobber build with empty ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
enabled. The ccache ccache was cleared before running <em>mach configure</em>.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>25:57 (1557)</td>
    <td>161:30 (9690)</td>
    <td>18:21 (1101)</td>
    <td>179:51 (10791)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>16:58 (1018)</td>
    <td>104:50 (6290)</td>
    <td>12:32 (752)</td>
    <td>117:22 (7042)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>12:59 (779)</td>
    <td>79:51 (4791)</td>
    <td>9:24 (564)</td>
    <td>89:15 (5355)</td>
  </tr>
</table>

<h3>Clobber build with populated ccache</h3>
<p><em>mach build</em> was performed after running <em>mach configure</em>. ccache was
enabled and the ccache was populated with the results of a prior build.
In theory, all compiler invocations should be serviced by ccache
entries.</p>
<p>This measure is a very crude way to measure how fast clobber builds
would be if compiler invocations were nearly instantaneous.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>3:59 (239)</td>
    <td>8:04 (484)</td>
    <td>3:21 (201)(</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3:11 (191)</td>
    <td>6:45 (405)</td>
    <td>2:53 (173)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2:31 (151)</td>
    <td>5:22 (322)</td>
    <td>2:12 (132)</td>
  </tr>
</table>

<h3>No-op builds</h3>
<p><em>mach build</em> was performed on a tree that was already built.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>1:58 (118)</td>
    <td>2:25 (145)</td>
    <td>0:41 (41)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>1:42 (102)</td>
    <td>2:02 (122)</td>
    <td>0:37 (37)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>1:20 (80)</td>
    <td>1:39 (99)</td>
    <td>0:28 (28)</td>
  </tr>
</table>

<h3>binaries no-op</h3>
<p><em>mach build binaries</em> was performed on a fully built tree. This results
in nothing being executed. It's a way to test the overhead of the
<em>binaries</em> make target.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>4.21</td>
    <td>4.38</td>
    <td>0.92</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3.17</td>
    <td>3.37</td>
    <td>0.71</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2.67</td>
    <td>2.75</td>
    <td>0.56</td>
  </tr>
</table>

<h3>binaries touch single .cpp</h3>
<p><em>mach build binaries</em> was performed on a fully built tree after touching
the file <em>netwerk/dns/nsHostResolver.cpp</em>. ccache was enabled but
cleared before running this test. This test simulates common C++
developer workflow of changing C++ and recompiling.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>12.89</td>
    <td>13.88</td>
    <td>1.96</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>10.82</td>
    <td>11.63</td>
    <td>1.78</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>8.57</td>
    <td>9.29</td>
    <td>1.23</td>
  </tr>
</table>

<h3>Tier times</h3>
<p>The times of each build system <em>tier</em> were measured on the 2013 Haswell
MacBook Pro. These timings were obtained out of curiosity to help
isolate the impact of different parts of the build. ccache was not
enabled for these tests.</p>
<table border="1">
  <tr>
    <th>Action</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>export clobber</td>
    <td>15.75</td>
    <td>66.11</td>
    <td>11.33</td>
    <td>77.44</td>
  </tr>
  <tr>
    <td>compile clobber</td>
    <td>9:01 (541)</td>
    <td>64:58 (3898)</td>
    <td>5:08 (308)</td>
    <td>70:06 (4206)</td>
  </tr>
  <tr>
    <td>libs clobber</td>
    <td>1:34 (94)</td>
    <td>2:15 (135)</td>
    <td>0:39 (39)</td>
    <td>2:54 (174)</td>
  </tr>
  <tr>
    <td>tools clobber</td>
    <td>9.33</td>
    <td>13.41</td>
    <td>2.48</td>
    <td>15.89</td>
  </tr>
  <tr>
    <td>export no-op</td>
    <td>3.01</td>
    <td>9.72</td>
    <td>3.47</td>
    <td>13.19</td>
  </tr>
  <tr>
    <td>compile no-op</td>
    <td>3.18</td>
    <td>18.02</td>
    <td>2.64</td>
    <td>20.66</td>
  </tr>
  <tr>
    <td>libs no-op</td>
    <td>58.2</td>
    <td>46.9</td>
    <td>13.4</td>
    <td>60.3</td>
  </tr>
  <tr>
    <td>tools no-op</td>
    <td>8.82</td>
    <td>12.68</td>
    <td>1.72</td>
    <td>14.40</td>
  </tr>
</table>

<h2>Observations and conclusions</h2>
<p>The data speaks for itself: <strong>the 2013 Haswell MacBook Pro is
significantly faster than its predecessors.</strong> It clocks in at 2x faster
than the benchmarked 2011 Sandy Bridge model (keep in mind the 300 MHz
base clock difference) and is ~34% faster than the 2012 Ivy Bridge (at
similar clock speed). Personally, I was surprised by this. I was
expecting speed improvements over Ivy Bridge, but not 34%.</p>
<p>It should go without saying: <strong>if you have the opportunity to upgrade
to a new, Haswell-based machine: do it.</strong> If possible, purchase
the upgrade to a 2.6 GHz CPU, as it contains ~13% more MHz than the
base 2.3 GHz model: this will make a measurable difference in build
times.</p>
<p>It's worth noting the increased efficiency of Haswell over its
predecessors. The total CPU time required to build decreased from ~158
minutes to ~103 minutes to 76 minutes! That 76 minute number is worth
highlighting because it means if we get 100% CPU saturation during
builds, we'll be able to build the tree in under 10 wall time minutes!</p>
<p>I hadn't performed crude benchmarks of high-level build system actions
since the <em>MOZ_PSEUDO_DERECURSE</em> work landed and I wanted to use the
opportunity of this hardware comparison to grab some numbers.</p>
<p>The overhead of ccache continues to surprise me. On the 2013
machine, enabling ccache increased the wall time of a clobber build by
1:46 and added 13:16 of CPU time. This is an increase of 16% and 17%,
respectively.</p>
<p>It's worth highlighting just how much time is spent compiling C/C++. In
our artificial tier measuring results, our clobber build time was ~660
wall time seconds (11 minutes) and used ~4473s CPU time (74:33). Of
this, 9:01 wall time and 70:06 CPU time was spent compiling C/C++. This
represents ~82% wall time and ~94% CPU time! Please note this does not
include linking. <strong>Anything we can do to decrease the CPU time used by
the compiler will make the build faster.</strong></p>
<p>I also found it interesting to note variances in obtained times. Even on
my brand new 2013 Haswell MacBook Pro where I know there aren't many
background processes running, wall times could vary significantly. I
<em>think</em> I isolated it to CPU bursting and heat issues. If I wait a few
minutes between CPU intensive tests, results are pretty consistent. But
if I perform CPU intensive tests back-to-back, the run times often vary.
The only other thing coming into play could be page caching or
filesystem indexing. I accounted for the latter by disabling Finder
on the object directory. And, I'd like to think that flash storage is
fast enough to remove I/O latency from the equation. Who knows. At the
end of the day, laptops aren't servers and OS X is a consumer OS, so I
don't expect ultra consistency.</p>
<p>Finally, I want to restate just how fast Haswell is. If you have the
opportunity to upgrade, do it.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="distributed-compiling-and-firefox"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/10/31/distributed-compiling-and-firefox" rel="bookmark" title="Permanent Link to Distributed Compiling and Firefox">Distributed Compiling and Firefox</a></h2>
  <small>October 31, 2013 at 11:35 AM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>If you had infinite CPU cores available and the Firefox build system
could distribute them all for concurrent compilation, Firefox
clobber build times would likely be 3-5 minutes instead of ~15
minutes on modern machines. This is a massive win. It therefore
should come as no surprise that distributed compiling is very
interesting to us.</p>
<p>Up until recently, the benefits of distributed compiling in the Firefox
build system couldn't be fully realized. This was because the build
system was performing recursive make traversal and make only <em>knew</em>
about a tiny subset of the tree's total C++ files at one time. For
example, when visiting <em>/layout/base</em> it only knew about 35 of the
close to 6000 files that get compiled as part of building Firefox. This
meant there was a hard ceiling to the max concurrency the build system
could achieve. This ceiling was often higher than the number of cores in
an individual machine, so it wasn't a huge issue for single machine
builds. But it did significantly limit the benefits of distributed
compiling. This all changed recently.</p>
<p><strong>As of a few weeks ago, the build system no longer encounters a low
ceiling preventing distributed compilation from reaping massive
benefits.</strong> If you have build with <em>make -j128</em>, make will spawn
128 compiler processes when processing the <em>compile</em> tier (which
is where most compilation occurs). If your compiler is set to a
distributed compiler, you will win.</p>
<p>So, what should you do about it?</p>
<p>I encourage people to set up distributed compilation <em>networks</em>
to reap the benefits of distributed compilation. Here are some tools you
should know about and some things to keep in mind.</p>
<p><a href="https://code.google.com/p/distcc/">distcc</a> is the tried and proven tool
for performing distributed compilation. It's heavily used and gets the
job done. It even works on Windows and can perform remote processing,
which is a huge win for our tree, where preprocessing can be
computationally expensive because of excessive includes. But, it has
a few significant drawbacks. Read the next paragraph.</p>
<p>I'm personally more excited about
<a href="https://github.com/icecc/icecream">icecream</a>. It has some very
compelling advantages to distcc. It has a scheduler that can
intelligently distribute load between machines. It uses network
broadcast to discover the scheduler. So, you just start the client
daemon and if there is a scheduler on the local network, it's all
set up. Icecream transfers the compiler toolchain between nodes
so you are guaranteed to have consistent output. (With distcc,
output may not be idempotent if the nodes aren't homogenous since distcc
relies on the system-local toolchain. If different versions are
installed on different nodes, you are out of luck). Icecream also
supports cross-compiling. In theory, you can have Linux machines
building for OS X, 32-bit machines building for 64-bit, etc. This
is all very difficult (if not impossible) to do with distcc.
Unfortunately, icecream doesn't work on Windows and doesn't appear
to support server-side preprocessing. Although, I imagine
both could be made to work if someone put in the effort.</p>
<p>Distributed compilation is very network intensive. I haven't measured,
but I suspect Wi-Fi bandwidth and latency constraints might make it
prohibitive there. It certainly won't be good for Wi-Fi saturation!
<strong>If you are in a Mozilla office, please do not attempt to perform
distributed compilation over Wi-Fi!</strong> For the same reasons, distributed
compilation will likely not benefit you if you are attempting to compile
on network-distant nodes.</p>
<p>I have set up an icecream server in the Mozilla San Francisco office. If
you install the icecream client daemon (iceccd) on your machine, it
should just work. I'm not sure what broadcast nets are configured as,
but I've successfully had machines on the 7th floor discover it
automatically. I guarantee no SLA for this server. Ping me privately
if you have difficulty connecting.</p>
<p>I've started very preliminary talks with Mozilla IT about setting up
dedicated <em>compiler farms</em> in Mozilla offices. I'm not saying this is
coming any time soon. I feel this will have a major impact on developer
productivity and I wanted to get the ball rolling months in advance
so nobody can claim this is a fire drill.</p>
<p>For distributed compilation to work well, the build system really needs
to be aware of distributed compilation. For example, to yield the
benefits of distributed compilation with make, you need to pass -j64 or
some other large value for concurrency. However, this value would be
universal for <em>every</em> task in the build. There are still thousands of
processes that must run locally. Using -j64 on these local tasks could
cause memory exhaustion, I/O saturation, excessive context switching,
etc. But if you decrease the concurrency ceiling, you lose the benefits
of distributed compilation! The build system thus needs to be taught
when distributed compilation is available and what tasks can be made
concurrent so it can intelligently adjust the -j concurrency limit at
run-time. This is why we have a higher-level build wrapper tool: <em>mach
build</em>. (This is another reason why people should be building through
mach instead of invoking make directly.)</p>
<p>No matter what technical solution we employ, I would like the build
system to automatically discover and use distributed compilation if
it is available. If we need to hardcode Mozilla IP addresses or
hostnames into the build system, I'm fine with that. I just don't want
developers not achieving much-faster build times because they are
ignorant. If you are in a physical location with distributed compilation
support, you should get that automatically: fast builds should not be
hard.</p>
<p>We can and should investigate distributed compilation as part of release
automation. Icecream should mitigate the concerns about build
reproducibility since the toolchain is transferred at build time.</p>
<p>I have had success getting Icecream to work with Linux builds. However,
OS X is problematic. Specifically, Icecream is unable to create the
build environment for distribution (likely modern OS X/Xcode
compatibility issue). Details are in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=927952">bug 927952</a>.</p>
<p>Build peers have a lot on our plate this quarter and making distributed
compilation work well is not in our official goals. <strong>I would love, love,
love if someone could step up and be a hero to make distributed
compilation work better with the build system.</strong> If you are interested,
pop into #build on irc.mozilla.org.</p>
<p>In summary, there are massive developer productivity wins waiting to be
realized through distributed compiling. There is nobody tasked to work
on this officially. Although, I'd love it if there were. If you find
yourself setting up ad-hoc networks in offices, I'd <em>really</em> like to see
some kind of discovery in <em>mach</em>. If not, there will be people left
behind and that really stinks for those individuals. If you do any
work around distributed compiling, please have it tracked under
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=485559">bug 485559</a>.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="../16">« Previous Page</a>
  --  
 <a href="../18">Next Page »</a>

              </div>
              
          <div id="sidebar">
          <ul>
            <li>
              <h2>Categories</h2>
              <ul>
                <li><a href="/blog/category/bugzilla">Bugzilla</a></li>
                <li><a href="/blog/category/clang">Clang</a></li>
                <li><a href="/blog/category/docker">Docker</a></li>
                <li><a href="/blog/category/firefox">Firefox</a></li>
                <li><a href="/blog/category/git">Git</a></li>
                <li><a href="/blog/category/javascript">JavaScript</a></li>
                <li><a href="/blog/category/mercurial">Mercurial</a></li>
                <li><a href="/blog/category/mozreview">MozReview</a></li>
                <li><a href="/blog/category/mozilla">Mozilla</a></li>
                <li><a href="/blog/category/puppet">Puppet</a></li>
                <li><a href="/blog/category/python">Python</a></li>
                <li><a href="/blog/category/review-board">Review Board</a></li>
                <li><a href="/blog/category/sync">Sync</a></li>
                <li><a href="/blog/category/browsers">browsers</a></li>
                <li><a href="/blog/category/build-system">build system</a></li>
                <li><a href="/blog/category/code-review">code review</a></li>
                <li><a href="/blog/category/compilers">compilers</a></li>
                <li><a href="/blog/category/internet">internet</a></li>
                <li><a href="/blog/category/logging">logging</a></li>
                <li><a href="/blog/category/mach">mach</a></li>
                <li><a href="/blog/category/make">make</a></li>
                <li><a href="/blog/category/misc">misc</a></li>
                <li><a href="/blog/category/movies">movies</a></li>
                <li><a href="/blog/category/pymake">pymake</a></li>
                <li><a href="/blog/category/security">security</a></li>
                <li><a href="/blog/category/sysadmin">sysadmin</a></li>
                <li><a href="/blog/category/testing">testing</a></li>
              </ul>
            </li>
          </ul>
        </div>



              <div style="clear: both;">&nbsp;</div>
          </div>
        </div>
      </div>
      <div id="footer">
        
  <hr/>
  <p>Copyright (c) 2015 Gregory Szorc. All rights reserved. Design by <a href="http://www.freecsstemplates.org/"> CSS Templates</a>.</p>


      </div>
    </div>
  </body>
</html>





