


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Pollinating  
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20101114

-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>Gregory Szorc's Digital Home
</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom" />
<link rel="stylesheet" href="/style/style.css" type="text/css" />
<link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />


  </head>
  <body>
    <div id="wrapper">
      
  <div id="menu">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/notes">Notes</a></li>
    <li><a href="/work.html">Work</a></li>
    <li><a href="/skills.html">Skills</a></li>
    <li><a href="/thoughts.html">Thoughts</a></li>
    <li><a href="/resume.pdf">Resume</a></li>
  </ul>
</div>


      <div id="page">
        <div id="page-bgtop">
          <div id="page-bgbtm">
              <div id="content">
                
  
<div class="blog_post">
  <a name="mach-has-landed"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/09/26/mach-has-landed" rel="bookmark" title="Permanent Link to Mach Has Landed">Mach Has Landed</a></h2>
  <small>September 26, 2012 at 05:30 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>
 | <a href="http://gregoryszorc.com/blog/2012/09/26/mach-has-landed#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>Hacking on Firefox is <em>hard</em>. Compiling the source tree for the first
time is a daunting experience. If you manage to do that, you still need
to figure out how to submit patches, write and run tests, etc. There is
no shortage of points where people can get confused, make mistakes, or
just give up because the barrier is too high.</p>
<p>I have strong convictions about making the overall developer experience
better (developers are users too, after all). The easier you make the
developer experience, the greater the chances of retaining developers.
And retaining developers means more contributions: more features and
fewer bugs. This translates to a better state for the Mozilla Project.
This makes the world a better place.</p>
<p>Since practically my first day working at Mozilla, I've been
experimenting with ways to make contributing to Firefox easier by
improving the build system or interaction with it.</p>
<p>With a lot of help, I've finally succeeded in landing something into the
Firefox source tree that I think will ultimately lead to a much better
developer experience.</p>
<p>It's called <strong>mach</strong> (German for <em>do</em>) and if you pull the latest
version of <a href="https://hg.mozilla.org/mozilla-central">mozilla-central</a>
(Firefox's main source code repository), you can run mach today.</p>
<h2>Running Mach</h2>
<p>You can run Mach by simply executing it from the root directory in the
repository:</p>
<pre><code>$ ./mach
</code></pre>
<p>Ideally, I shouldn't have to tell you anything else: mach's output
should provide you all the instruction you need to use it. If it
doesn't, that is a bug and it should be fixed.</p>
<p>Realistically, mach is still in early development and its user
experience still leaves a lot to be desired.</p>
<p>Because technical usage docs belong in a medium that is easily
discoverable and where the community can improve on them (not a
post on a personal blog), you can find additional usage information in
the
<a href="https://developer.mozilla.org/En/Developer_Guide/mach">mach article</a> on
MDN. The
<a href="https://hg.mozilla.org/mozilla-central/file/default/python/mach/README.rst">mach README</a>
holds more technical information for people wanting to poke at the inner
workings.</p>
<p>Mach does require Python 2.7. The build system will likely soon require
Python 2.7 as well. So, if you don't have Python 2.7, you should upgrade
now before you lose the ability to build the tree. Conveniently, the
tree now has a
<a href="http://gregoryszorc.com/blog/2012/09/18/bootstrap-your-system-to-build-firefox">bootstrap script</a>
which covers the installation of Python. So, Python 2.7 should just be a
simple command away.</p>
<h2>Features</h2>
<p>Why would you use mach? Good question! Compared to the existing
out-of-the-box experience, mach adds:</p>
<ul>
<li>Ability to run xpcshell and mochitest tests from the source directory.
  This means you can tab-complete test filenames in your shell and it
  <em>just works</em>.</li>
<li>Parsing of compiler warnings (currently supports Clang 3.1 and MSVC
  formats) into a unified warnings database (actually a JSON file).
  After builds you can run <em>./mach warnings-list</em> or <em>./mach
  warnings-summary</em> to get a concise list without having to look at
  build logs.</li>
<li>A single command-line interface where you can easily discover new
  functionality. Just run <em>./mach help</em> (try doing that with make!).</li>
</ul>
<p>Naysayers will say this is a paltry list. They are correct. I have
bigger plans. But, you have to start somewhere.</p>
<h2>Goals and Future Ideas</h2>
<p>The overall goal of mach is to improve the developer experience of
developing Firefox and other Gecko applications. It does this by
providing a convenient, central command in the root directory of
the repository that acts as both an oracle to discover new commands
and functionality (<em>./mach help</em>) as well as a proxy to execute them.
You don't need to worry about environment variables, working directories,
or finding some random script hidden in the bowells of the source tree.
You just run a single command and the world is brought to you. No build
documentation. No outdated wikis. No copying commands into your shell.
No having to scour random blogs for useful tools. You just clone the
repository, run a command, see what you can do, and get stuff done. Your
shell-literate grandmother could do it.</p>
<p>Mach should be your springboard to in-tree developer tools and increased
productivity. You shouldn't need anything except a copy of the source
tree and mach.</p>
<p>Like Git and Mercurial, mach is powered by the concept of
sub-commands/actions. So, one simply needs to register a new sub-command
with the mach driver. This involves writing a Python class. Once you do
that, people can discover and use that functionality. All batteries are
included with a copy of mozilla-central.</p>
<p>As stated above, the current set of commands is rather small. But, the
sky is the limit. Here are some of my ideas:</p>
<ul>
<li>Ability to upload, download, and apply patches from Bugzilla (Burak
  YiÄŸit Kaya, Jeff Hammel, Clint Talbert and I have already talked about
  this -- progress tracked in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774141">bug 774141</a>).</li>
<li>Automatically configure Mercurial with optimal settings (ensure user
  info is set, proper lines of diff context, enable mqext, etc). Tracked
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=794580">bug 794580</a>.</li>
<li>Submit Try builds. The <a href="https://github.com/pbiggar/trychooser">trychooser</a>
  Mercurial extension could easily live as a mach subcommand! Tracked in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774137">bug 774137</a>.</li>
<li>Identify Bugzilla components and/or reviewers from files touched by
  patch. It's all in the history of the touched files and the history of
  the old bugs referenced by those commits!
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774145">Bug 774145</a>.</li>
<li>Interaction with the <em>self-serve</em> build API. That thing on TBPL to
  control individual builds - we could make a CLI interface for it.
  (Steve Fink and/or Jeff Hammel already have
  <a href="https://hg.mozilla.org/users/josh_joshmatthews.net/self-serve-tools">code</a>
  for this - it just needs to be integrated).
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774147">Bug 774147</a>.</li>
</ul>
<p>If you have an idea for a feature, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=mach">file a bug</a>.
Please note there are many features on file already. However, some
obvious ones such as integration with missing test suites have yet to be
filed (at least at the time I wrote this post).</p>
<p>If you wrote an awesome developer tool and would like others to use it
(without having to rely on people discovering it by reading a corner of the
Internet), add it to mach! Use mach as a wedge to get more exposure and
users. File a bug. I will happily r+ patches that add useful developer
functionality to the tree.</p>
<h2>What this Means / Longer Term Future</h2>
<p>While there is no timetable, mach will eventually replace <em>client.mk</em>.
client.mk, like mach, is essentially a CLI driver for the build
system. Having the driver implemented in Python rather than make has many
compelling advantages. I could probably write a whole post on it, but
I'll spare the world from my ranting.</p>
<p>Anyway, this all means that you may want to start re-training your
muscle memory now. Stop typing <em>make</em> and start typing <em>mach</em>. If you
need to type <em>make</em> because mach does not provide a feature, this is a
missing feature from mach.
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=mach">File a bug</a>
and request a new mach feature!</p>
<p>I want to condition people to stop typing <em>make</em>, especially in the object
directory. There are drastic changes to the build system in the works
(<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=784841">bug 784841</a> is
the tip of the iceburg). These changes will require the build system to
be treated as a black box. So, things like invoking make from the object
directory will eventually break. You'll need to go through an
intelligent tool to invoke the build system. Mach will be that tool.</p>
<h2>Thanks</h2>
<p>I would like to single out the following individuals for helping to land
mach:</p>
<ul>
<li>Jeff Hammel for doing the bulk of the reviewing. He shares my vision
  for mach and how it will make the overall developer experience much
  more pleasant and how this will translate to better things for The
  Project. In my mind, Jeff deserves as much credit for landing mach as
  I do.</li>
<li>Mike Hommey and Ms2ger for review help. Mike Hommey helped identify a
  lot of issues with build system integration. Ms2ger provided lots of
  general feedback on Python issues and API design.</li>
<li>Mike Connor (my manager) for allowing me to work on this. It's not
  related to my job description in any way so he <em>could</em> say I shouldn't
  be spending time on this. But, he realizes the positive impact this can
  have and has been supportive of it.</li>
</ul>
<p>I hope you find mach useful!</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/09/26/mach-has-landed#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="bootstrap-your-system-to-build-firefox"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/09/18/bootstrap-your-system-to-build-firefox" rel="bookmark" title="Permanent Link to Bootstrap Your System to Build Firefox">Bootstrap Your System to Build Firefox</a></h2>
  <small>September 18, 2012 at 05:00 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>
 | <a href="http://gregoryszorc.com/blog/2012/09/18/bootstrap-your-system-to-build-firefox#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>If you've looked at the
<a href="https://developer.mozilla.org/en-US/docs/Simple_Firefox_build">build instructions</a>
for Firefox lately, you may have noticed something new: support for
system bootstrapping!</p>
<p>Now checked in to mozilla-central is a
<a href="https://hg.mozilla.org/mozilla-central/file/default/python/mozboot/">framework</a>
for ensuring your system is capable of building mozilla-central and
Firefox. You just need to download and run a single Python script and it
performs magic.</p>
<p>Kudos go out to a community contributor, kmm (name wasn't revealed) for
doing the legwork for tracking down and verifying things worked on all
the Linux distros. Richard Newman and Jeff Hammel also helped with code
reviews. Just hours after it landed, Landry Breuil contributed support
for OpenBSD!</p>
<p>Currently, bootstrapping works for the following:</p>
<ul>
<li>Ubuntu Linux</li>
<li>Mint</li>
<li>CentOS 6.x</li>
<li>Fedora</li>
<li>OS X 10.6, 10.7, and 10.8</li>
<li>OpenBSD</li>
</ul>
<p>If you want to add support for an additional OS, please file a
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=Build%20Config">Core : Build Config</a>
bug. Likewise, if you encounter an issue, please file a bug so others
don't get tripped up by it!</p>
<p>Bootstrap support is definitely in its infancy. It still needs features
like better prompting and opportunities for user choice (e.g. support
MacPorts on OS X - currently it only works with Homebrew). But, I think
it is much better than what existed previously, especially on OS X.</p>
<p>I consider this bootstrapping component just one piece in a larger
mission to make developing and building Firefox (and other Gecko
applications) easier. This should (hopefully) lead to more development
involvement. The next component to land will likely be
<a href="http://gregoryszorc.com/blog/2012/07/25/mozilla-build-system-plan-of-attack">mach</a>.
It's (finally) been getting some review love (thanks Jeff Hammel!), so
I'm optimistic it will land in the next few weeks.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/09/18/bootstrap-your-system-to-build-firefox#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="visual-studio-project-generation-for-mozilla-central"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central" rel="bookmark" title="Permanent Link to Visual Studio Project Generation for mozilla-central">Visual Studio Project Generation for mozilla-central</a></h2>
  <small>August 28, 2012 at 12:00 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>I have very alpha support for Visual Studio project generation for
mozilla-central that daring people can dogfood.</p>
<p>I want to emphasize that this is extremely alpha. Normally, I wouldn't
release things as fragile as they are. But, I know Windows developers
sorely miss Visual Studio, especially IntelliSense. The current Visual
Studio projects support IntelliSense, so I want to get this in the hands
of Windows developers ASAP.</p>
<p>The current directions for making this all work are a bit hacky. Things
will change once things have matured. For now, please excuse the mess.</p>
<p>First, you will need to grab the code. If you use Git, set up a remote
to my repository:</p>
<pre><code>git remote add indygreg git://github.com/indygreg/mozilla-central.git
git fetch indygreg
</code></pre>
<p>The branch of interest is <em>build-splendid</em>. I periodically rebase this
branch on top of master. You have been warned.</p>
<p>You can switch to this branch:</p>
<pre><code>git checkout -b build-splendid indygreg/build-splendid
</code></pre>
<p>Alternatively, you can squash it down to a single commit and merge it
into your local branch. Once you've done that, you can record the SHA-1
of the commit and cherry-pick that wherever you like!</p>
<pre><code>git merge --squash indygreg/build-splendid
git commit
</code></pre>
<p>In the current state, you need to build the tree or the Visual Studio
projects will complain about missing files. It doesn't matter if you
build the tree before or after Visual Studio projects are generated.
But, we might as well get it out of the way. From your MozillaBuild
environment, run:</p>
<pre><code>./mach build
</code></pre>
<p>That should <em>just work</em>. If it doesn't, you may need to configure
mach.ini. See my <a href="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid/">previous post</a>
on how to configure mach.ini. As a reference, my Windows config is:</p>
<pre><code>[build]

configure_extra = --disable-webgl

[compiler]

[paths]
source_directory = c:\dev\src\mozilla-central-git
object_directory = c:\dev\src\mozilla-central-git\objdir
</code></pre>
<p>Now, to generate Visual Studio project files:</p>
<pre><code>./mach backendconfig visualstudio
</code></pre>
<p>That should take about a minute to finish. When it's done, it should
have created <em>objdir/msvc/mozilla.sln</em>. You should be able to load that
in Visual Studio!</p>
<p>You will need to regenerate Visual Studio project files when the build
config changes. As a rule of thumb, do this every time you pull source.
You don't need to perform a full build before you generate Visual Studio
files (you do need to perform configure, however). However, if you have
not performed a full build, Visual Studio may not be able to find some
files, like headers generated from IDLs.</p>
<p><strong>Please close the solution before regenerating the project files.</strong> If
you don't, Visual Studio puts up a modal dialog for each project file
that changed and you have to click through over a hundred of these. It's
extremely frustrating. I'm investigating workarounds.</p>
<h2>Current State</h2>
<p>Currently, it only generates projects for C/C++ compilation (libraries).
I still need to add support for IDL, headers, etc. However, each
project has proper compiler flags, header search paths, etc. So,
IntelliSense is happy and some things do manage to compile!</p>
<p>Many parts are broken and sub-par.</p>
<p>I've only tested on Visual Studio 2008. If you are running Visual Studio
\2010, you can try to upgrade the solution. This <em>may</em> work. The backend
supports generating solutions for different versions. But, I haven't
tested things work on non-2008 and I don't want to expose untested behavior.</p>
<p>Compiling within Visual Studio works for some things. On my system, I
get a lot of <em>nullptr not defined</em> errors. I'm not sure why. This will
hopefully be worked out soon.</p>
<p>If you do manager to compile within Visual Studio, the output files
don't go in the right places. So, if you do a build from the
command-line, it will have to re-compile to pick up changes.</p>
<p>Project names are based on the name of the library they produce. I'm not
sure if this is the best solution.</p>
<p>Project dependencies are not set up. They will be added later.</p>
<p>Projects for linking libxul or building firefox.exe are not yet
provided. Along the same vein, debugging support is not built-in. I'm
working on it.</p>
<p>Basically, IntelliSense works. You can now use Visual Studio as a rich
editor. Hopefully this is a step in the right direction.</p>
<p>I'm anxious to hear if this works for other people. Please leave
comments!</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="build-firefox-faster-with-build-splendid"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/08/15/build-firefox-faster-with-build-splendid" rel="bookmark" title="Permanent Link to Build Firefox Faster with Build Splendid">Build Firefox Faster with Build Splendid</a></h2>
  <small>August 15, 2012 at 02:30 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>Would you like to build Firefox faster? If so, do the following:</p>
<pre><code>hg qimport http://people.mozilla.org/~gszorc/build-splendid.patch
hg qpush
rm .mozconfig* (you may want to create a backup first)
./mach build
</code></pre>
<p>This should <em>just work</em> on OS X, Linux, and other Unix-style systems.
<strong>Windows support is currently broken, sorry.</strong></p>
<p><em>mach</em> can do much more than build. Run the following to see what:</p>
<pre><code>./mach --help
</code></pre>
<h2>Important Info</h2>
<p><em>mach</em> replaces client.mk. <em>mach</em> has its own configuration file. The
first time you run <em>mach</em>, it will create the file <em>mach.ini</em> in the
same directory as the <em>mach</em> script. This is your new <em>mozconfig</em> file.</p>
<p>The default <em>mach.ini</em> places the object directory into the directory
<em>objdir</em> under the top source directory. It also builds an optimized
binary without debug info.</p>
<p>Run the following to see which config settings you can add to
<em>mach.ini</em>:</p>
<pre><code>./mach settings-create
./mach settings-list
</code></pre>
<p>This <em>may</em> fail because I'm still working out the kinks with <em>gettext</em>.
If it doesn't work, open <em>python/mozbuild-bs/mozbuild/base.py</em> and search
for <em>_register_settings</em>. Open
<em>python/mozbuild-bs/mozbuild/locale/en-US/LC_MESSAGES/mozbuild.po</em> for
the help messages.</p>
<p>As a point of reference, my <em>mach.ini</em> looks like the following:</p>
<pre><code>[build]
application = browser

configure_extra = --enable-dtrace --enable-tests

[compiler]
cc = /usr/local/llvm/bin/clang
cxx = /usr/local/llvm/bin/clang++

cflags = -fcolor-diagnostics
cxxflags = -fcolor-diagnostics

[paths]
source_directory = /Users/gps/src/mozilla-central-git
object_directory = /Users/gps/src/mozilla-central-git/objdir
</code></pre>
<p>I am on OS X and am using a locally-built version of LLVM/Clang, which I
have installed to <em>/usr/local/llvm</em>.</p>
<p>You'll notice there are no options to configure make. The patch
automatically selects optimal settings for your platform!</p>
<h2>Known Issues and Caveats</h2>
<p>This is alpha. It works in scenarios in which I have tested it, mainly
building the <em>browser</em> application on OS X and Linux. There are many
features missing and likely many bugs.</p>
<p>I have been using this as part of my day-to-day development for weeks.
However, your mileage may vary.</p>
<p>As stated above, Windows support is lacking. It will appear to work, but
things will blow up during building. Don't even try to use it on
Windows.</p>
<p>There are likely many bugs. Please don't file Bugzilla bugs, as this
isn't part of the build system just yet.</p>
<p><strong>This patch takes over the build system. Do not attempt to use
client.mk or run make directly with this patch applied.</strong></p>
<p>If you encounter an issue, your methods of recourse are:</p>
<ol>
<li>Post a comment on this blog post</li>
<li>Ping me on irc.mozilla.org. My nick is <em>gps</em>. Try the #buildfaster
   channel.</li>
<li>Send an email to gps@mozilla.com</li>
</ol>
<p>I am particularly interested in exceptions and build failures.</p>
<p>If you encounter an issue building with this, just reverse the patch and
build like you have always done (don't forget to restore your mozconfig
file).</p>
<p>If <em>mach.ini</em> does not support everything you were doing in your
mozconfig, please send me a copy of your mozconfig so I can implement
whatever you need.</p>
<h2>Other Info</h2>
<p>I will likely write a follow-up post detailing what's going on. If you
are curious, the code lives in <em>python/mozbuild-bs</em>. The <em>backend</em> and
<em>frontend</em> sub-packages are where the magic is at. Once the backend has
been configured, check out <em>hybridmake.mk</em> and all of the <em>splendid.mk</em>
files in the object directory.</p>
<p>I am particularly interested in the real-world impact of this patch on
people's build times. In this early version of the patch, you likely
won't see drastic speed increases. On my MacBook Pro with an SSD, I see
end-to-end clobber build times decrease by over a minute. With a little
more work, I should be able to shave another minute or two off of that.</p>
<p>I will try to keep the patch up-to-date as I improve the build system.
Refresh early and often.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="mozilla-central-build-times"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/07/29/mozilla-central-build-times" rel="bookmark" title="Permanent Link to mozilla-central Build Times">mozilla-central Build Times</a></h2>
  <small>July 29, 2012 at 01:20 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-central-build-times#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>In my previous post, I
<a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview/">explained how Mozilla's build system works</a>.
In this post, I want to give people a feel for where time is spent and to
identify obvious areas that need improvement.</p>
<p>To my knowledge, nobody has provided such a comprehensive collection of
measurements before. Thus, most of our thoughts on where build time goes
have been largely lacking scientific rigor. I hope this post changes
matters and injects some much-needed quantitative figures into the
discussion.</p>
<h2>Methodology</h2>
<p>All the times reported in this post were obtained from my 2011
generation MacBook Pro. It has 8 GB of RAM and a magnetic hard drive. It
is not an ultimate build rig by any stretch of the imagination. However,
it's no slouch either. The machine has 1 physical Core i7 processor with
4 cores, each clocked at 2.3GHz. Each core has hyperthreading, so to the
OS there appears to be 8 cores. For the remainder of this post, I'll
simply state that my machine has 8 cores.</p>
<p>When I obtained measurements, I tried to limit the number of processes
running elsewhere on the machine. I also performed multiple runs and
reported the best timings. This means that the results are likely
synthetic and highly influenced by the page cache. More on that later.</p>
<p>I configured make to use up to 8 parallel processes (adding -j8 to the
make flags). I also used silent builds (the -s flag to make). Silent
builds are important because terminal rendering can add many seconds of
wall time to builds, especially on slow terminals (like Windows). I
measured results with make output being written to the terminal. In
hindsight, I wish I hadn't done this. Next time.</p>
<p>To obtain the times, I used the ubiquitous <em>time</em> utility. Wall times
are the <em>real</em> times from <em>time</em>. CPU time is the sum of the <em>user</em> and
<em>sys</em> times.</p>
<p>CPU utilization is the percentage of CPU cores busy during the wall time
of execution. In other words, I divided the CPU time by 8 times the wall
time (8 for the number of cores in my machine). 100% is impossible to
obtain, as obviously the CPU on my machine is doing other things during
measurement. But, I tried to limit the number of background processes
running, so there shouldn't have been that much noise.</p>
<p>I built a debug version of Firefox (the <em>browser</em> app in
mozilla-central) using r160922 of the Clang compiler (pulled and built
the day I did this measurement). The revision of mozilla-central being
built was <a href="https://hg.mozilla.org/mozilla-central/rev/08428deb1e89">08428edb1e89</a>.
I also had <em>--enable-tests</em>, which adds a significant amount of extra
work to builds.</p>
<h2>Configure</h2>
<p><em>time</em> reported the following for running <em>configure</em>:</p>
<pre><code>real 0m25.927s
user 0m9.595s
sys  0m8.729s
</code></pre>
<p>This is a one-time cost. Unless you are hacking on the build system or
pull down a tree change that modified the build system, you typically
don't need to worry about this.</p>
<h2>Clobber Builds with Empty ccache</h2>
<p>I built each tier separately with an empty ccache on a
recently-configured object directory. This measures the optimal worst
case time for building mozilla-central. In other words, we have nothing
cached in the object directory, so the maximum amount of work needs to
be performed. Since I measured multiple times and used the best results,
this is what I mean by <em>optimal</em>.</p>
<p>The table below contains the measurements. I omitted CPU utilization
calculation for small time values because I don't feel it is relevant.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Utilization</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.714</td>
    <td>0.774</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>5.081</td>
    <td>8.620</td>
    <td>21%</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.453</td>
    <td>0.444</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>base (total)</td>
    <td>6.248</td>
    <td>9.838</td>
    <td>19.7%</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>9.309</td>
    <td>8.404</td>
    <td>11.3%</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>1.030</td>
    <td>1.877</td>
    <td>22.8%</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>71.450</td>
    <td>416.718</td>
    <td>52%</td>
  </tr>
  <tr>
    <td>js tools</td>
    <td>0.324</td>
    <td>0.246</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>js (total)</td>
    <td>72.804</td>
    <td>418.841</td>
    <td>71.9%</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>40.487</td>
    <td>141.704</td>
    <td>43.7%</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>1211</td>
    <td>4896</td>
    <td>50.5%</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>70.416</td>
    <td>90.917</td>
    <td>16.1%</td>
  </tr>
  <tr>
    <td>platform (total)</td>
    <td>1312</td>
    <td>5129</td>
    <td>48.9%</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>4.383</td>
    <td>3.059</td>
    <td>8.7%</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>18.727</td>
    <td>18.976</td>
    <td>12.7%</td>
  </tr>
  <tr>
    <td>app tools (no-op)</td>
    <td>0.519s</td>
    <td>0.968</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>app (total)</td>
    <td>23.629</td>
    <td>23.003</td>
    <td>12.2%</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>1424 (23:44)</td>
    <td>5589 (93:15)</td>
    <td>49.1%</td>
  </tr>
</table>

<p>It's worth mentioning that linking libxul is part of the platform libs
tier. libxul linking should be called out because it is unlike other
parts of the build in that it is more I/O bound and can't use multiple
cores. On my machine, libxul linking (not using gold) takes ~61s. During
this time, only 1 CPU core is in use. The ~61s wall time corresponds to
roughly 5% of platform libs' wall time. Yet, even if we subtract this ~61s
from the effective CPU calculation, the percentage doesn't change much.</p>
<h2>Clobber with Populated ccache</h2>
<p>Using the ccache from a recently built tree to make C/C++ compilation
faster, I measured how long it took each tier to build on a clobber
build.</p>
<p>This measurement can be used to estimate the overhead of C/C++ compilation
during builds. In theory, the difference between CPU times between this
and the former measurement will be the amount of CPU time spent in the
C/C++ compiler.</p>
<p>This will also isolate how much time we spend <em>not</em> in the C/C++
compiler. It will arguably be very difficult to
make the C/C++ compiler faster (although things like reducing the abuse
of templates can have a measureable impact). However, we do have control
over many of the other things we do. If we find that CPU time spent
outside the C/C++ compiler is large, we can look for pieces to optimize.</p>
<p>Tiers not containing compiled files are omitted from the data.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
    <th>ccache savings (s) (Time in Compiler)</th>
  </tr>
  <tr>
    <td>base libs</td>
    <td>1.075</td>
    <td>1.525</td>
    <td>7.095</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>1.957</td>
    <td>0.933</td>
    <td>1.522</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>5.582</td>
    <td>1.688</td>
    <td>6.716</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>22.829</td>
    <td>9.529</td>
    <td>407.189</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>431</td>
    <td>328</td>
    <td>4568</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>14.498</td>
    <td>25.744</td>
    <td>65.173</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>10.193</td>
    <td>15.809</td>
    <td>3.167</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>487.134 (6:07)</td>
    <td>383.229 (6:23)</td>
    <td>5059 (84:19)</td>
  </tr>
</table>

<h2>No-op Build</h2>
<p>A <em>no-op</em> build is a build performed in an object directory that was
just built. Nothing changed in the source repository nor object
directory, so theoretically the build should do nothing. And, it should
be fast.</p>
<p>In reality, our build system isn't smart and performs some redundant
work. One part of redundant work is because one of the first things the
main Makefile does before invoking the tiers is delete a large chunk of
the <em>dist/</em> directory and the entirety of the <em>_tests/</em> directory from
the object directory.</p>
<p>In these measurements, I bypassed the deletion of these directories. In
other words, I measure what <em>no-op</em> builds are if we eliminate the
clown shoes around blowing away large parts of the object directory.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.524</td>
    <td>0.537</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.625</td>
    <td>0.599</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.447</td>
    <td>0.437</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.809</td>
    <td>0.752</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.334</td>
    <td>0.324</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.375</td>
    <td>0.361</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>10.904</td>
    <td>13.136</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>30.969</td>
    <td>44.25</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>8.213</td>
    <td>10.737</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.524</td>
    <td>1.006</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>6.090</td>
    <td>13.753</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>59.814</td>
    <td>85.892</td>
  </tr>
</table>

<p>So, no-op builds use ~60s of wall time and only make use of 17.9% of
available CPU resources.</p>
<h2>No-op Build With Directory Removal Silliness</h2>
<p>As mentioned above, before the tiers are iterated, the top-level
Makefile blows away large parts of <em>dist/</em> and the entirety of
<em>_tests/</em>. What impact does this have?</p>
<p>In this section, I try to isolate how much time was thrown away by doing
this.</p>
<p>First, we have to account for the deletion of these directories. On my
test build, deleting 15,005 files in these directories took ~3 seconds.</p>
<p>The table below contains my results. This is a more accurate reading
than the above on how long no-op builds takes because this is actually
what we do during normal builds. The time delta column contains the
difference between this build and a build without the removal silliness.
Positive times can be attributes to overhead associated with
repopulating <em>dist/</em> and <em>_tests/</em>.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>Wall Time Delta (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Time Delta (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.544</td>
    <td>Negligible</td>
    <td>0.559</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.616</td>
    <td>Negligible</td>
    <td>0.594</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.447</td>
    <td>Negligible</td>
    <td>0.436</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.803</td>
    <td>Negligible</td>
    <td>0.743</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.338</td>
    <td>Negligible</td>
    <td>0.329</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.378</td>
    <td>Negligible</td>
    <td>0.363</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>13.140</td>
    <td>2.236</td>
    <td>13.314</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>35.290</td>
    <td>4.329</td>
    <td>43.059</td>
    <td>-1.191 (normal variance?)</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>8.819</td>
    <td>0.606</td>
    <td>10.983</td>
    <td>0.246</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.525</td>
    <td>Negligible</td>
    <td>1.012</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>8.876</td>
    <td>2.786</td>
    <td>13.527</td>
    <td>-0.226</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>69.776</td>
    <td>9.962</td>
    <td>84.919</td>
    <td>-0.973 (normal variance)</td>
  </tr>
</table>

<p>If a delta is listed as negligible, it was within 100ms of the original
value and I figured this was either due to expected variance between
runs or below our threshold for caring. In the case of base, nspr, and
js tiers, the delta was actually much smaller than 100ms, often less
then 10ms.</p>
<p>It certainly appears that the penalty for deleting large parts of
<em>dist/</em> and the entirety of <em>_tests/</em> is about 10 seconds.</p>
<h2>The Overhead of Make</h2>
<p>We've measured supposed no-op build times. As I stated above, our no-op
builds actually aren't no-op builds. Even if we bypass the deletion of
<em>dist/</em> and <em>_tests/</em> we always evaluate some make rules. Can we measure how
much work it takes to just load the make files without actually doing
anything? This would allow us to get a rough estimate of how much we are
wasting by doing redundant work. It will also help us establish a
baseline for make overhead.</p>
<p>Turns out we can! Make has a <em>--dry-run</em> argument which evaluates the make
file but doesn't actually do anything. It simply prints what would have
been done.</p>
<p>Using <em>--dry-run</em>, I timed the different tiers. The difference from a no-op
build should roughly be the overhead associated with make itself. It is
possible that <em>--dry-run</em> adds a little overhead because it prints the
commands that would have been executed. (Previous timings were using
<em>-s</em>, which suppresses this.)</p>
<p>The delta times in the following table are the difference in times
between the true no-op build from above (the one where we don't delete
<em>dist/</em> and <em>_tests/</em>) and the times measured here. It roughly isolates
the amount of time spent outside of make, doing redundant work.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>Wall Time Delta (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Time Delta (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.369</td>
    <td>0.155</td>
    <td>0.365</td>
    <td>0.172</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.441</td>
    <td>0.184</td>
    <td>0.431</td>
    <td>0.168</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.368</td>
    <td>0.079</td>
    <td>0.364</td>
    <td>0.073</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.636</td>
    <td>0.173</td>
    <td>0.591</td>
    <td>0.161</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.225</td>
    <td>0.109</td>
    <td>0.225</td>
    <td>0.099</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.278</td>
    <td>0.097</td>
    <td>0.273</td>
    <td>0.088</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>3.841</td>
    <td>7.063</td>
    <td>6.108</td>
    <td>7.028</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>8.938</td>
    <td>22.031</td>
    <td>14.723</td>
    <td>29.527</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>3.962</td>
    <td>4.251</td>
    <td>6.185</td>
    <td>4.552</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.422</td>
    <td>0.102</td>
    <td>0.865</td>
    <td>0.141</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>0.536</td>
    <td>5.554</td>
    <td>1.148</td>
    <td>12.605</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>20.016</td>
    <td>39.798</td>
    <td>31.278</td>
    <td>54.614</td>
  </tr>
</table>

<h2>Observations</h2>
<p>The numbers say a lot. I'll get to key takeaways in a bit.</p>
<p>First, what the numbers don't show is the variance between runs.
Subsequent runs are almost always <em>significantly</em> faster than the
initial, even on no-op builds. I suspect this is due mostly to
I/O wait. In the initial tier run, files are loaded into the page cache.
Then, in subsequent runs, all I/O comes from physical memory rather than
waiting on a magnetic hard drive.</p>
<p>Because of the suspected I/O related variance, I fear that the numbers I
obtained are highly synthetic, at least for my machine. It is unlikely
I'll ever see all these numbers in one mozilla-central build. Instead,
it requires a specific sequence of events to obtain the best times
possible. And, this sequence of events is not likely to correspond with
real-world usage.</p>
<p>That being said, I think these numbers are important. If you remove I/O
from the equation - say you have an SSD with near 0 service times or
have enough memory so you don't need a hard drive - these numbers will
tell what limits you are brushing up against. And, as computers get more
powerful, I think more and more people will cross this threshold and
will be more limited by the build system than the capabilities of their
hardware. (A few months ago, I
<a href="https://groups.google.com/forum/#!topic/mozilla.dev.builds/FJclsTA_OBQ/discussion">measured resource usage</a>
when compiling mozilla-central on Linux and concluded you need roughly
9GB of dedicated memory to compile and link mozilla-central without page
cache eviction. In other words, if building on a machine with only 8GB
of RAM, your hard drive will play a role.)</p>
<p>Anyway, to the numbers.</p>
<p>I think the most important number in the above tables is <strong>49.1%</strong>. That
is the effective CPU utilization during a clobber build. This means that
<strong>during a build, on average half of the available CPU cores are
unused.</strong> Now, I could be generous and bump this number to 50.7%. That's
what the effective CPU utilization is if you remove the ~60s of libxul
linking from the calculation.</p>
<p>The 49.1% has me reaching the following conclusions:</p>
<ol>
<li>I/O wait really matters.</li>
<li>Our recursive use of make is incapable of executing more than 4 items
   at a time on average (assuming 8 cores).</li>
<li>My test machine had more CPU wait than I think.</li>
</ol>
<p>I/O wait is easy to prove: compare times on an SSD or with a similar I/O
bus with near zero service times (e.g. a filled page cache with no
eviction - like a machine with 16+ GB of memory that has built
mozilla-central recently).</p>
<p>A derived time not captured in any table is 11:39. This is the total
CPU time of a clobber build (93:15) divided by the number of cores (8).
<strong>If we had 100% CPU utilization across all cores during builds, we should
be able to build mozilla-central in 11:39.</strong> This is an ideal figure and
won't be reached. As mentioned above, libxul linking takes ~60s itself! I
think 13:00 is a more realistic optimal compilation time for a modern 8
core machine. This points out a startling number: <strong>we are wasting
~12 minutes of wall time due to not fully utilizing CPU cores during
clobber builds.</strong></p>
<p>Another important number is 5059 out of 5589, or 90.5%. That is the CPU
time in a clobber build spent in the C/C++ compiler, as measured by the
speedup of using ccache. It's unlikely we are going to make the C/C++
compiler go much faster (short of not compiling things). So, this is a
big fat block of time we will never be able to optimize. On my machine
<strong>compiling mozilla-central will always take at least ~10:30 wall time,
just in compiling C/C++.</strong></p>
<p>A clobber build with a saturated ccache took 487s wall time but only 383s
CPU time. That's only about 10% total CPU utilization. And, this
represents only 6.8% of total CPU time from the original clobber build.
Although, it is 34.2% of total wall time.</p>
<p>The above means that everything not the C/C++ compiler is horribly
inefficient. These are clown shoes of epic proportions. We're not even
using 1 full core doing build actions outside of the C/C++ compiler!</p>
<p>Because we are inefficient when it comes to core usage, I
think a key takeaway is that throwing more cores at the existing build
system will have diminishing returns. Sure, some parts of the build system
today could benefit from it (mainly js, layout, and dom, as they have
Makefile's with large numbers of source files). But, most of the build
system won't take advantage of many cores. <strong>If you want to throw money
at a build machine, I think your first choice should be an SSD. If you
can't do that, have as much memory as you can so most of your filesystem
I/O is serviced by the page cache, not your disk drive.</strong></p>
<p>In the final table, we isolated how much time <em>make</em> is spending to
just to figure out what to do. That amounts to ~20 seconds wall
time and ~31s CPU time. That leaves ~40s wall and ~55s CPU for non-make
work during no-op builds. Translation: we are doing 40s of wall time work
during no-op builds. Nothing changed. <strong>We are throwing 40s of wall time
away because the build system isn't using proper dependencies and is
doing redundant work.</strong></p>
<p>I've long been a critic of us blowing away parts of <em>dist/</em> and
<em>_tests/</em> at the top of builds. Well, after measuring it, I have mixed
reactions. It only amounts to about ~10s of added time to builds. This
doesn't seem like a lot in the grand scheme of things. However, this is
~10s on top of the ~60s it actually takes to iterate through the tiers.
So, in terms of percentages for no-op builds, it is actually quite
significant.</p>
<p>No-op builds with the existing build system take ~70s under ideal
conditions. In order of time, the breakdown is roughly:</p>
<ul>
<li>~40s for doing redundant work in Makefiles</li>
<li>~20s for make traversal and loading overhead</li>
<li>~10s for repopulating deleted content from <em>dist/</em> and <em>_tests/</em></li>
</ul>
<p>In other words, <strong>~50s of ~70s no-op build times are spent doing work
we have already done.</strong> This is almost purely clown shoes. Assuming we
can't make make traversal and loading faster, the shortest possible
no-op build time will be ~20s.</p>
<p>Splitting things up a bit more:</p>
<ul>
<li>~22s - platform libs make evaluation</li>
<li>~20s - make file traversal and loading (readying for evaluation)</li>
<li>~10s - repopulating deleted content from <em>dist/</em> and <em>_tests/</em></li>
<li>~7s - platform export make evaluation</li>
<li>~5.5 - app libs make evaluation</li>
<li>~4s - platform tools</li>
</ul>
<p>The ~20s for make file traversal and loading is interesting. I suspect
(although I haven't yet measured) that a lot of this is due to the sheer
size of rules.mk. As I
<a href="http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times/">measured</a>
on Friday, the overhead of rules.mk with pymake is significant. I
hypothesized that it would have a similar impact on GNU make. I think a
good amount of this ~20s is similar overhead. I need to isolate,
however. I am tempted to say that if we truly did no-op builds and make
Makefile's load into make faster, we could attain no-op build times in
the ~10s range. I think this is pretty damn good! Even ~20s isn't too
bad. As surprising as it is for me to say it, <strong>recursive make is not
(a significant) part of our no-op build problem</strong>.</p>
<h2>Why is the Build System Slow?</h2>
<p>People often ask the question above. As the data has told me, the
answer, like many to complicated problems, is nuanced.</p>
<p>If you are doing a clobber build on a fresh machine, the build system is
slow because 1) compiling all the C/C++ takes a lot of time (84:19 CPU
time actually) 2) we don't make efficient use of all available cores
when building. Half of the CPU horsepower during a fresh build is
unharnessed.</p>
<p>If you are doing a no-op build, the build system is slow mainly because
it is performing a lot of needless and redundant work. A significant
contributor is the overhead of make, probably due to rules.mk being
large.</p>
<p>If you are doing an incremental build, you will fall somewhere between
either extreme. You will likely get nipped by both inefficient core
usage as well as redundant work. Which one hurts the most depends on the
scope of the incremental change.</p>
<p>If you are building on a machine with a magnetic hard drive (not an
SSD), your builds are slow because you are waiting on I/O. You can
combat this by putting 8+GB of memory in your system and doing your best
to ensure that building mozilla-central can use as much of it as
possible. I highly recommend 12GB, if not 16GB.</p>
<h2>Follow-ups</h2>
<p>The measurements reported in this post are only the tip of the iceberg.
If I had infinite time, I would:</p>
<ul>
<li>Measure other applications, not just browser/Firefox. I've heard that
  mobile/Fennec's build config is far from optimal, for example. I would
  love to quantify that.</li>
<li>Set up buildbot to record and post measurements so we have a dashboard
  of build times. We have some of this today, but the granularity isn't
  as fine as what I captured.</li>
<li>Record per-directory times.</li>
<li>Isolate time spent in different processes (DTrace could be used here).</li>
<li>Capture I/O numbers.</li>
<li>Correlate the impact of I/O service times on build times.</li>
<li>Isolate the overhead of ccache (mainly in terms of I/O).</li>
<li>Obtain numbers on other platforms and systems. Ensure results can be
  reproduced.</li>
</ul>
<h2>Next Steps</h2>
<p>If we want to make our existing recursive make build backend faster, I
recommend the following actions (in no particular order):</p>
<ol>
<li>Factor pieces out of rules.mk into separate .mk files and
   conditionally load based on presence of specific variables. In other
   words, finish what we have started. This definitely cuts down on the
   overhead with pymake (as measured on Friday) and <em>likely</em> makes GNU
   make faster as well.</li>
<li>Don't blow away parts of <em>dist/</em> and <em>_tests/</em> at the top of builds.
   I know this introduces a problem where we could leave orphaned files
   in the object directory. We should solve this problem by having
   proper manifests for everything so we can detect and delete orphans.
   The cheap man's solution is to periodically clobber these
   directories.</li>
<li>Don't perform unnecessary work during no-op builds. I suspect a lot
   of redundant work is due to rules in Makefile's not the rules in
   rules.mk. As we eliminate rules from Makefile's, this problem should
   gradually go away since rules.mk is generally intelligent about these
   things.</li>
<li>More parallelism. I'm not sure how we're going to solve this with
   recursive make short of using PARALLEL_DIRS more and/or consolidating
   Makefile's together.</li>
</ol>
<p>Again, these steps apply to our current recursive make build backend.</p>
<p>Because the most significant losses are due to ungained parallelism, <strong>our
focus should be on increasing parallelism.</strong> We can only do this so much
with recursive make. It is clear now more than ever that recursive make
needs to be replaced with something that can fully realize the potential
of multiple CPU cores. That could be non-recursive make or a separate
build backend altogether.</p>
<p>We will likely not have an official alternate build backend soon. Until
then, there are no shortage of clown shoes that can be looked at.</p>
<p>The redundant work during no-op builds is definitely tempting to
address, as I think that has significant impact to most developers.
Eliminating the absurdly long no-op build times removes the needs for
hacks like <em>smart-make</em> and instills a culture of <em>trust the build
system.</em></p>
<p>I suspect a lot of the redundant work during no-op builds is due to
poorly implemented rules in individual Makefiles rather than on
silliness in rules.mk. Therefore,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">removing rules from Makefile's</a>
again seems to be one of the most important things we can do to make the
build system faster. It also prepares us for implementing newer build
backends, so it is a win-win!</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-central-build-times#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="../13">Â« Previous Page</a>
  --  
 <a href="../15">Next Page Â»</a>

              </div>
              
          <div id="sidebar">
          <ul>
            <li>
              <h2>Categories</h2>
              <ul>
                <li><a href="/blog/category/bugzilla">Bugzilla</a></li>
                <li><a href="/blog/category/clang">Clang</a></li>
                <li><a href="/blog/category/docker">Docker</a></li>
                <li><a href="/blog/category/firefox">Firefox</a></li>
                <li><a href="/blog/category/git">Git</a></li>
                <li><a href="/blog/category/javascript">JavaScript</a></li>
                <li><a href="/blog/category/mercurial">Mercurial</a></li>
                <li><a href="/blog/category/mozilla">Mozilla</a></li>
                <li><a href="/blog/category/puppet">Puppet</a></li>
                <li><a href="/blog/category/python">Python</a></li>
                <li><a href="/blog/category/review-board">Review Board</a></li>
                <li><a href="/blog/category/sync">Sync</a></li>
                <li><a href="/blog/category/browsers">browsers</a></li>
                <li><a href="/blog/category/build-system">build system</a></li>
                <li><a href="/blog/category/code-review">code review</a></li>
                <li><a href="/blog/category/compilers">compilers</a></li>
                <li><a href="/blog/category/internet">internet</a></li>
                <li><a href="/blog/category/logging">logging</a></li>
                <li><a href="/blog/category/mach">mach</a></li>
                <li><a href="/blog/category/make">make</a></li>
                <li><a href="/blog/category/misc">misc</a></li>
                <li><a href="/blog/category/movies">movies</a></li>
                <li><a href="/blog/category/pymake">pymake</a></li>
                <li><a href="/blog/category/security">security</a></li>
                <li><a href="/blog/category/sysadmin">sysadmin</a></li>
                <li><a href="/blog/category/testing">testing</a></li>
              </ul>
            </li>
          </ul>
        </div>



              <div style="clear: both;">&nbsp;</div>
          </div>
        </div>
      </div>
      <div id="footer">
        
  <hr/>
  <p>Copyright (c) 2012 Gregory Szorc. All rights reserved. Design by <a href="http://www.freecsstemplates.org/"> CSS Templates</a>.</p>


      </div>
    </div>
  </body>
</html>





