


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Pollinating  
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20101114

-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>Gregory Szorc's Digital Home</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom" />
<link rel="stylesheet" href="/style/style.css" type="text/css" />
<link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />


  </head>
  <body>
    <div id="wrapper">
      
  <div id="menu">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/notes">Notes</a></li>
    <li><a href="/work.html">Work</a></li>
    <li><a href="/skills.html">Skills</a></li>
    <li><a href="/thoughts.html">Thoughts</a></li>
    <li><a href="/resume.pdf">Resume</a></li>
  </ul>
</div>


      <div id="page">
        <div id="page-bgtop">
          <div id="page-bgbtm">
              <div id="content">
                
  
<div class="blog_post">
  <a name="mozilla-central-build-times"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/07/29/mozilla-central-build-times" rel="bookmark" title="Permanent Link to mozilla-central Build Times">mozilla-central Build Times</a></h2>
  <small>July 29, 2012 at 01:20 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-central-build-times#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>In my previous post, I
<a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview/">explained how Mozilla's build system works</a>.
In this post, I want to give people a feel for where time is spent and to
identify obvious areas that need improvement.</p>
<p>To my knowledge, nobody has provided such a comprehensive collection of
measurements before. Thus, most of our thoughts on where build time goes
have been largely lacking scientific rigor. I hope this post changes
matters and injects some much-needed quantitative figures into the
discussion.</p>
<h2>Methodology</h2>
<p>All the times reported in this post were obtained from my 2011
generation MacBook Pro. It has 8 GB of RAM and a magnetic hard drive. It
is not an ultimate build rig by any stretch of the imagination. However,
it's no slouch either. The machine has 1 physical Core i7 processor with
4 cores, each clocked at 2.3GHz. Each core has hyperthreading, so to the
OS there appears to be 8 cores. For the remainder of this post, I'll
simply state that my machine has 8 cores.</p>
<p>When I obtained measurements, I tried to limit the number of processes
running elsewhere on the machine. I also performed multiple runs and
reported the best timings. This means that the results are likely
synthetic and highly influenced by the page cache. More on that later.</p>
<p>I configured make to use up to 8 parallel processes (adding -j8 to the
make flags). I also used silent builds (the -s flag to make). Silent
builds are important because terminal rendering can add many seconds of
wall time to builds, especially on slow terminals (like Windows). I
measured results with make output being written to the terminal. In
hindsight, I wish I hadn't done this. Next time.</p>
<p>To obtain the times, I used the ubiquitous <em>time</em> utility. Wall times
are the <em>real</em> times from <em>time</em>. CPU time is the sum of the <em>user</em> and
<em>sys</em> times.</p>
<p>CPU utilization is the percentage of CPU cores busy during the wall time
of execution. In other words, I divided the CPU time by 8 times the wall
time (8 for the number of cores in my machine). 100% is impossible to
obtain, as obviously the CPU on my machine is doing other things during
measurement. But, I tried to limit the number of background processes
running, so there shouldn't have been that much noise.</p>
<p>I built a debug version of Firefox (the <em>browser</em> app in
mozilla-central) using r160922 of the Clang compiler (pulled and built
the day I did this measurement). The revision of mozilla-central being
built was <a href="https://hg.mozilla.org/mozilla-central/rev/08428deb1e89">08428edb1e89</a>.
I also had <em>--enable-tests</em>, which adds a significant amount of extra
work to builds.</p>
<h2>Configure</h2>
<p><em>time</em> reported the following for running <em>configure</em>:</p>
<pre><code>real 0m25.927s
user 0m9.595s
sys  0m8.729s
</code></pre>
<p>This is a one-time cost. Unless you are hacking on the build system or
pull down a tree change that modified the build system, you typically
don't need to worry about this.</p>
<h2>Clobber Builds with Empty ccache</h2>
<p>I built each tier separately with an empty ccache on a
recently-configured object directory. This measures the optimal worst
case time for building mozilla-central. In other words, we have nothing
cached in the object directory, so the maximum amount of work needs to
be performed. Since I measured multiple times and used the best results,
this is what I mean by <em>optimal</em>.</p>
<p>The table below contains the measurements. I omitted CPU utilization
calculation for small time values because I don't feel it is relevant.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Utilization</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.714</td>
    <td>0.774</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>5.081</td>
    <td>8.620</td>
    <td>21%</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.453</td>
    <td>0.444</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>base (total)</td>
    <td>6.248</td>
    <td>9.838</td>
    <td>19.7%</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>9.309</td>
    <td>8.404</td>
    <td>11.3%</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>1.030</td>
    <td>1.877</td>
    <td>22.8%</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>71.450</td>
    <td>416.718</td>
    <td>52%</td>
  </tr>
  <tr>
    <td>js tools</td>
    <td>0.324</td>
    <td>0.246</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>js (total)</td>
    <td>72.804</td>
    <td>418.841</td>
    <td>71.9%</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>40.487</td>
    <td>141.704</td>
    <td>43.7%</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>1211</td>
    <td>4896</td>
    <td>50.5%</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>70.416</td>
    <td>90.917</td>
    <td>16.1%</td>
  </tr>
  <tr>
    <td>platform (total)</td>
    <td>1312</td>
    <td>5129</td>
    <td>48.9%</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>4.383</td>
    <td>3.059</td>
    <td>8.7%</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>18.727</td>
    <td>18.976</td>
    <td>12.7%</td>
  </tr>
  <tr>
    <td>app tools (no-op)</td>
    <td>0.519s</td>
    <td>0.968</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>app (total)</td>
    <td>23.629</td>
    <td>23.003</td>
    <td>12.2%</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>1424 (23:44)</td>
    <td>5589 (93:15)</td>
    <td>49.1%</td>
  </tr>
</table>

<p>It's worth mentioning that linking libxul is part of the platform libs
tier. libxul linking should be called out because it is unlike other
parts of the build in that it is more I/O bound and can't use multiple
cores. On my machine, libxul linking (not using gold) takes ~61s. During
this time, only 1 CPU core is in use. The ~61s wall time corresponds to
roughly 5% of platform libs' wall time. Yet, even if we subtract this ~61s
from the effective CPU calculation, the percentage doesn't change much.</p>
<h2>Clobber with Populated ccache</h2>
<p>Using the ccache from a recently built tree to make C/C++ compilation
faster, I measured how long it took each tier to build on a clobber
build.</p>
<p>This measurement can be used to estimate the overhead of C/C++ compilation
during builds. In theory, the difference between CPU times between this
and the former measurement will be the amount of CPU time spent in the
C/C++ compiler.</p>
<p>This will also isolate how much time we spend <em>not</em> in the C/C++
compiler. It will arguably be very difficult to
make the C/C++ compiler faster (although things like reducing the abuse
of templates can have a measureable impact). However, we do have control
over many of the other things we do. If we find that CPU time spent
outside the C/C++ compiler is large, we can look for pieces to optimize.</p>
<p>Tiers not containing compiled files are omitted from the data.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
    <th>ccache savings (s) (Time in Compiler)</th>
  </tr>
  <tr>
    <td>base libs</td>
    <td>1.075</td>
    <td>1.525</td>
    <td>7.095</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>1.957</td>
    <td>0.933</td>
    <td>1.522</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>5.582</td>
    <td>1.688</td>
    <td>6.716</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>22.829</td>
    <td>9.529</td>
    <td>407.189</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>431</td>
    <td>328</td>
    <td>4568</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>14.498</td>
    <td>25.744</td>
    <td>65.173</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>10.193</td>
    <td>15.809</td>
    <td>3.167</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>487.134 (6:07)</td>
    <td>383.229 (6:23)</td>
    <td>5059 (84:19)</td>
  </tr>
</table>

<h2>No-op Build</h2>
<p>A <em>no-op</em> build is a build performed in an object directory that was
just built. Nothing changed in the source repository nor object
directory, so theoretically the build should do nothing. And, it should
be fast.</p>
<p>In reality, our build system isn't smart and performs some redundant
work. One part of redundant work is because one of the first things the
main Makefile does before invoking the tiers is delete a large chunk of
the <em>dist/</em> directory and the entirety of the <em>_tests/</em> directory from
the object directory.</p>
<p>In these measurements, I bypassed the deletion of these directories. In
other words, I measure what <em>no-op</em> builds are if we eliminate the
clown shoes around blowing away large parts of the object directory.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.524</td>
    <td>0.537</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.625</td>
    <td>0.599</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.447</td>
    <td>0.437</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.809</td>
    <td>0.752</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.334</td>
    <td>0.324</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.375</td>
    <td>0.361</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>10.904</td>
    <td>13.136</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>30.969</td>
    <td>44.25</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>8.213</td>
    <td>10.737</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.524</td>
    <td>1.006</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>6.090</td>
    <td>13.753</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>59.814</td>
    <td>85.892</td>
  </tr>
</table>

<p>So, no-op builds use ~60s of wall time and only make use of 17.9% of
available CPU resources.</p>
<h2>No-op Build With Directory Removal Silliness</h2>
<p>As mentioned above, before the tiers are iterated, the top-level
Makefile blows away large parts of <em>dist/</em> and the entirety of
<em>_tests/</em>. What impact does this have?</p>
<p>In this section, I try to isolate how much time was thrown away by doing
this.</p>
<p>First, we have to account for the deletion of these directories. On my
test build, deleting 15,005 files in these directories took ~3 seconds.</p>
<p>The table below contains my results. This is a more accurate reading
than the above on how long no-op builds takes because this is actually
what we do during normal builds. The time delta column contains the
difference between this build and a build without the removal silliness.
Positive times can be attributes to overhead associated with
repopulating <em>dist/</em> and <em>_tests/</em>.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>Wall Time Delta (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Time Delta (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.544</td>
    <td>Negligible</td>
    <td>0.559</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.616</td>
    <td>Negligible</td>
    <td>0.594</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.447</td>
    <td>Negligible</td>
    <td>0.436</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.803</td>
    <td>Negligible</td>
    <td>0.743</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.338</td>
    <td>Negligible</td>
    <td>0.329</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.378</td>
    <td>Negligible</td>
    <td>0.363</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>13.140</td>
    <td>2.236</td>
    <td>13.314</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>35.290</td>
    <td>4.329</td>
    <td>43.059</td>
    <td>-1.191 (normal variance?)</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>8.819</td>
    <td>0.606</td>
    <td>10.983</td>
    <td>0.246</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.525</td>
    <td>Negligible</td>
    <td>1.012</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>8.876</td>
    <td>2.786</td>
    <td>13.527</td>
    <td>-0.226</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>69.776</td>
    <td>9.962</td>
    <td>84.919</td>
    <td>-0.973 (normal variance)</td>
  </tr>
</table>

<p>If a delta is listed as negligible, it was within 100ms of the original
value and I figured this was either due to expected variance between
runs or below our threshold for caring. In the case of base, nspr, and
js tiers, the delta was actually much smaller than 100ms, often less
then 10ms.</p>
<p>It certainly appears that the penalty for deleting large parts of
<em>dist/</em> and the entirety of <em>_tests/</em> is about 10 seconds.</p>
<h2>The Overhead of Make</h2>
<p>We've measured supposed no-op build times. As I stated above, our no-op
builds actually aren't no-op builds. Even if we bypass the deletion of
<em>dist/</em> and <em>_tests/</em> we always evaluate some make rules. Can we measure how
much work it takes to just load the make files without actually doing
anything? This would allow us to get a rough estimate of how much we are
wasting by doing redundant work. It will also help us establish a
baseline for make overhead.</p>
<p>Turns out we can! Make has a <em>--dry-run</em> argument which evaluates the make
file but doesn't actually do anything. It simply prints what would have
been done.</p>
<p>Using <em>--dry-run</em>, I timed the different tiers. The difference from a no-op
build should roughly be the overhead associated with make itself. It is
possible that <em>--dry-run</em> adds a little overhead because it prints the
commands that would have been executed. (Previous timings were using
<em>-s</em>, which suppresses this.)</p>
<p>The delta times in the following table are the difference in times
between the true no-op build from above (the one where we don't delete
<em>dist/</em> and <em>_tests/</em>) and the times measured here. It roughly isolates
the amount of time spent outside of make, doing redundant work.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>Wall Time Delta (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Time Delta (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.369</td>
    <td>0.155</td>
    <td>0.365</td>
    <td>0.172</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.441</td>
    <td>0.184</td>
    <td>0.431</td>
    <td>0.168</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.368</td>
    <td>0.079</td>
    <td>0.364</td>
    <td>0.073</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.636</td>
    <td>0.173</td>
    <td>0.591</td>
    <td>0.161</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.225</td>
    <td>0.109</td>
    <td>0.225</td>
    <td>0.099</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.278</td>
    <td>0.097</td>
    <td>0.273</td>
    <td>0.088</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>3.841</td>
    <td>7.063</td>
    <td>6.108</td>
    <td>7.028</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>8.938</td>
    <td>22.031</td>
    <td>14.723</td>
    <td>29.527</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>3.962</td>
    <td>4.251</td>
    <td>6.185</td>
    <td>4.552</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.422</td>
    <td>0.102</td>
    <td>0.865</td>
    <td>0.141</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>0.536</td>
    <td>5.554</td>
    <td>1.148</td>
    <td>12.605</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>20.016</td>
    <td>39.798</td>
    <td>31.278</td>
    <td>54.614</td>
  </tr>
</table>

<h2>Observations</h2>
<p>The numbers say a lot. I'll get to key takeaways in a bit.</p>
<p>First, what the numbers don't show is the variance between runs.
Subsequent runs are almost always <em>significantly</em> faster than the
initial, even on no-op builds. I suspect this is due mostly to
I/O wait. In the initial tier run, files are loaded into the page cache.
Then, in subsequent runs, all I/O comes from physical memory rather than
waiting on a magnetic hard drive.</p>
<p>Because of the suspected I/O related variance, I fear that the numbers I
obtained are highly synthetic, at least for my machine. It is unlikely
I'll ever see all these numbers in one mozilla-central build. Instead,
it requires a specific sequence of events to obtain the best times
possible. And, this sequence of events is not likely to correspond with
real-world usage.</p>
<p>That being said, I think these numbers are important. If you remove I/O
from the equation - say you have an SSD with near 0 service times or
have enough memory so you don't need a hard drive - these numbers will
tell what limits you are brushing up against. And, as computers get more
powerful, I think more and more people will cross this threshold and
will be more limited by the build system than the capabilities of their
hardware. (A few months ago, I
<a href="https://groups.google.com/forum/#!topic/mozilla.dev.builds/FJclsTA_OBQ/discussion">measured resource usage</a>
when compiling mozilla-central on Linux and concluded you need roughly
9GB of dedicated memory to compile and link mozilla-central without page
cache eviction. In other words, if building on a machine with only 8GB
of RAM, your hard drive will play a role.)</p>
<p>Anyway, to the numbers.</p>
<p>I think the most important number in the above tables is <strong>49.1%</strong>. That
is the effective CPU utilization during a clobber build. This means that
<strong>during a build, on average half of the available CPU cores are
unused.</strong> Now, I could be generous and bump this number to 50.7%. That's
what the effective CPU utilization is if you remove the ~60s of libxul
linking from the calculation.</p>
<p>The 49.1% has me reaching the following conclusions:</p>
<ol>
<li>I/O wait really matters.</li>
<li>Our recursive use of make is incapable of executing more than 4 items
   at a time on average (assuming 8 cores).</li>
<li>My test machine had more CPU wait than I think.</li>
</ol>
<p>I/O wait is easy to prove: compare times on an SSD or with a similar I/O
bus with near zero service times (e.g. a filled page cache with no
eviction - like a machine with 16+ GB of memory that has built
mozilla-central recently).</p>
<p>A derived time not captured in any table is 11:39. This is the total
CPU time of a clobber build (93:15) divided by the number of cores (8).
<strong>If we had 100% CPU utilization across all cores during builds, we should
be able to build mozilla-central in 11:39.</strong> This is an ideal figure and
won't be reached. As mentioned above, libxul linking takes ~60s itself! I
think 13:00 is a more realistic optimal compilation time for a modern 8
core machine. This points out a startling number: <strong>we are wasting
~12 minutes of wall time due to not fully utilizing CPU cores during
clobber builds.</strong></p>
<p>Another important number is 5059 out of 5589, or 90.5%. That is the CPU
time in a clobber build spent in the C/C++ compiler, as measured by the
speedup of using ccache. It's unlikely we are going to make the C/C++
compiler go much faster (short of not compiling things). So, this is a
big fat block of time we will never be able to optimize. On my machine
<strong>compiling mozilla-central will always take at least ~10:30 wall time,
just in compiling C/C++.</strong></p>
<p>A clobber build with a saturated ccache took 487s wall time but only 383s
CPU time. That's only about 10% total CPU utilization. And, this
represents only 6.8% of total CPU time from the original clobber build.
Although, it is 34.2% of total wall time.</p>
<p>The above means that everything not the C/C++ compiler is horribly
inefficient. These are clown shoes of epic proportions. We're not even
using 1 full core doing build actions outside of the C/C++ compiler!</p>
<p>Because we are inefficient when it comes to core usage, I
think a key takeaway is that throwing more cores at the existing build
system will have diminishing returns. Sure, some parts of the build system
today could benefit from it (mainly js, layout, and dom, as they have
Makefile's with large numbers of source files). But, most of the build
system won't take advantage of many cores. <strong>If you want to throw money
at a build machine, I think your first choice should be an SSD. If you
can't do that, have as much memory as you can so most of your filesystem
I/O is serviced by the page cache, not your disk drive.</strong></p>
<p>In the final table, we isolated how much time <em>make</em> is spending to
just to figure out what to do. That amounts to ~20 seconds wall
time and ~31s CPU time. That leaves ~40s wall and ~55s CPU for non-make
work during no-op builds. Translation: we are doing 40s of wall time work
during no-op builds. Nothing changed. <strong>We are throwing 40s of wall time
away because the build system isn't using proper dependencies and is
doing redundant work.</strong></p>
<p>I've long been a critic of us blowing away parts of <em>dist/</em> and
<em>_tests/</em> at the top of builds. Well, after measuring it, I have mixed
reactions. It only amounts to about ~10s of added time to builds. This
doesn't seem like a lot in the grand scheme of things. However, this is
~10s on top of the ~60s it actually takes to iterate through the tiers.
So, in terms of percentages for no-op builds, it is actually quite
significant.</p>
<p>No-op builds with the existing build system take ~70s under ideal
conditions. In order of time, the breakdown is roughly:</p>
<ul>
<li>~40s for doing redundant work in Makefiles</li>
<li>~20s for make traversal and loading overhead</li>
<li>~10s for repopulating deleted content from <em>dist/</em> and <em>_tests/</em></li>
</ul>
<p>In other words, <strong>~50s of ~70s no-op build times are spent doing work
we have already done.</strong> This is almost purely clown shoes. Assuming we
can't make make traversal and loading faster, the shortest possible
no-op build time will be ~20s.</p>
<p>Splitting things up a bit more:</p>
<ul>
<li>~22s - platform libs make evaluation</li>
<li>~20s - make file traversal and loading (readying for evaluation)</li>
<li>~10s - repopulating deleted content from <em>dist/</em> and <em>_tests/</em></li>
<li>~7s - platform export make evaluation</li>
<li>~5.5 - app libs make evaluation</li>
<li>~4s - platform tools</li>
</ul>
<p>The ~20s for make file traversal and loading is interesting. I suspect
(although I haven't yet measured) that a lot of this is due to the sheer
size of rules.mk. As I
<a href="http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times/">measured</a>
on Friday, the overhead of rules.mk with pymake is significant. I
hypothesized that it would have a similar impact on GNU make. I think a
good amount of this ~20s is similar overhead. I need to isolate,
however. I am tempted to say that if we truly did no-op builds and make
Makefile's load into make faster, we could attain no-op build times in
the ~10s range. I think this is pretty damn good! Even ~20s isn't too
bad. As surprising as it is for me to say it, <strong>recursive make is not
(a significant) part of our no-op build problem</strong>.</p>
<h2>Why is the Build System Slow?</h2>
<p>People often ask the question above. As the data has told me, the
answer, like many to complicated problems, is nuanced.</p>
<p>If you are doing a clobber build on a fresh machine, the build system is
slow because 1) compiling all the C/C++ takes a lot of time (84:19 CPU
time actually) 2) we don't make efficient use of all available cores
when building. Half of the CPU horsepower during a fresh build is
unharnessed.</p>
<p>If you are doing a no-op build, the build system is slow mainly because
it is performing a lot of needless and redundant work. A significant
contributor is the overhead of make, probably due to rules.mk being
large.</p>
<p>If you are doing an incremental build, you will fall somewhere between
either extreme. You will likely get nipped by both inefficient core
usage as well as redundant work. Which one hurts the most depends on the
scope of the incremental change.</p>
<p>If you are building on a machine with a magnetic hard drive (not an
SSD), your builds are slow because you are waiting on I/O. You can
combat this by putting 8+GB of memory in your system and doing your best
to ensure that building mozilla-central can use as much of it as
possible. I highly recommend 12GB, if not 16GB.</p>
<h2>Follow-ups</h2>
<p>The measurements reported in this post are only the tip of the iceberg.
If I had infinite time, I would:</p>
<ul>
<li>Measure other applications, not just browser/Firefox. I've heard that
  mobile/Fennec's build config is far from optimal, for example. I would
  love to quantify that.</li>
<li>Set up buildbot to record and post measurements so we have a dashboard
  of build times. We have some of this today, but the granularity isn't
  as fine as what I captured.</li>
<li>Record per-directory times.</li>
<li>Isolate time spent in different processes (DTrace could be used here).</li>
<li>Capture I/O numbers.</li>
<li>Correlate the impact of I/O service times on build times.</li>
<li>Isolate the overhead of ccache (mainly in terms of I/O).</li>
<li>Obtain numbers on other platforms and systems. Ensure results can be
  reproduced.</li>
</ul>
<h2>Next Steps</h2>
<p>If we want to make our existing recursive make build backend faster, I
recommend the following actions (in no particular order):</p>
<ol>
<li>Factor pieces out of rules.mk into separate .mk files and
   conditionally load based on presence of specific variables. In other
   words, finish what we have started. This definitely cuts down on the
   overhead with pymake (as measured on Friday) and <em>likely</em> makes GNU
   make faster as well.</li>
<li>Don't blow away parts of <em>dist/</em> and <em>_tests/</em> at the top of builds.
   I know this introduces a problem where we could leave orphaned files
   in the object directory. We should solve this problem by having
   proper manifests for everything so we can detect and delete orphans.
   The cheap man's solution is to periodically clobber these
   directories.</li>
<li>Don't perform unnecessary work during no-op builds. I suspect a lot
   of redundant work is due to rules in Makefile's not the rules in
   rules.mk. As we eliminate rules from Makefile's, this problem should
   gradually go away since rules.mk is generally intelligent about these
   things.</li>
<li>More parallelism. I'm not sure how we're going to solve this with
   recursive make short of using PARALLEL_DIRS more and/or consolidating
   Makefile's together.</li>
</ol>
<p>Again, these steps apply to our current recursive make build backend.</p>
<p>Because the most significant losses are due to ungained parallelism, <strong>our
focus should be on increasing parallelism.</strong> We can only do this so much
with recursive make. It is clear now more than ever that recursive make
needs to be replaced with something that can fully realize the potential
of multiple CPU cores. That could be non-recursive make or a separate
build backend altogether.</p>
<p>We will likely not have an official alternate build backend soon. Until
then, there are no shortage of clown shoes that can be looked at.</p>
<p>The redundant work during no-op builds is definitely tempting to
address, as I think that has significant impact to most developers.
Eliminating the absurdly long no-op build times removes the needs for
hacks like <em>smart-make</em> and instills a culture of <em>trust the build
system.</em></p>
<p>I suspect a lot of the redundant work during no-op builds is due to
poorly implemented rules in individual Makefiles rather than on
silliness in rules.mk. Therefore,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">removing rules from Makefile's</a>
again seems to be one of the most important things we can do to make the
build system faster. It also prepares us for implementing newer build
backends, so it is a win-win!</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-central-build-times#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="mozilla-build-system-overview"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/07/29/mozilla-build-system-overview" rel="bookmark" title="Permanent Link to Mozilla Build System Overview">Mozilla Build System Overview</a></h2>
  <small>July 29, 2012 at 01:15 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>Mozilla's build system is a black box to many. This post attempts to
shed some light onto how it works.</p>
<h2>Configuration File</h2>
<p>The first part of building is creating a configuration file. This
defines what application to build (Firefox, Firefox OS, Fennec, etc) as
well as build options, like to create a release or debug build. This
step isn't technically required, but most people do it.</p>
<p>Configuration files currently exist as <em>mozconfig</em> files. By default,
most people create a <em>.mozconfig</em> file in the root directory of
mozilla-central.</p>
<h2>Interaction</h2>
<p>All interaction with the build system is currently gated through the
<em>client.mk</em> file in the root directory of mozilla-central. Although, I'm
trying to land an alternate (and eventual replacement) to <em>client.mk</em>
called <em>mach</em>. You can read about it in previous posts on this blog.</p>
<p>When you run <em>make -f client.mk</em>, you are invoking the build system and
telling it to do whatever it needs to do build the tree.</p>
<h2>Running Configure</h2>
<p>The first thing <em>client.mk</em> does to a fresh tree is invoke <em>configure</em>.
<em>configure</em> is a shell script in the root directory of the repository.
It is generated from the checked-in <em>configure.in</em> file using the GNU
<em>autoconf</em> utility. I won't go into detail on how autoconf works because
I don't have a beard.</p>
<p><em>configure</em> accomplishes some important tasks.</p>
<p>First, it validates that the build environment is sane. It performs some
sanity testing on the directory tree then looks at the system and build
configuration to make sure everything should work.</p>
<p>It identifies the active compiler, locations of common tools and
utilities, and ensures everything works as needed. It figures out how to
convert desired traits into system-specific options. e.g. the exact
argument to pass to the compiler to enable warnings.</p>
<p>Once <em>configure</em> determines the environment is sane, it writes out what
it learned.</p>
<p>Currently, <em>configure</em> takes what it has learned and invokes the
<em>allmakefiles.sh</em> script in the root directory. This script prints out
the set of Makefile's that will be used to build the tree for the
current configuration. <em>configure</em> takes the output of filenames and
then procedes to generate those files.</p>
<p>Generation of Makefile's is rather simple. In the source tree are a
bunch of <em>.in</em> files, typically <em>Makefile.in</em>. These contain special
markers. <em>configure</em> takes the set of determined configuration variables
and performs substitution of the variable markers in the <em>.in</em> files with
them. The <em>.in</em> files with variables substitutes are written out in the
object directory. There are also some GYP files in the source tree.
<em>configure</em> invokes a tool to convert these into Mozilla-style
Makefile's.</p>
<p><em>configure</em> also invokes <em>configure</em> for other managed projects
in mozilla-central, such as the SpiderMonkey source in <em>js/src</em>.</p>
<p><em>configure</em> finishes by writing out other miscellaneous files in the
object directory.</p>
<h2>Running Make</h2>
<p>The next step of the build is running make. <em>client.mk</em> simply points
GNU make (or pymake) at the <em>Makefile</em> in the top-level directory of the
object directory and essentially says <em>evaluate</em>.</p>
<h3>Build System Tiers</h3>
<p>The build system is broken up into different tiers. Each tier represents
a major phase or product in the build system. Most builds have the
following tiers:</p>
<ol>
<li>base - Builds global dependencies</li>
<li>nspr - Builds NSPR</li>
<li>js - Builds SpiderMonkey</li>
<li>platform - Builds the Gecko platform</li>
<li>app - Builds the configured application (e.g. Firefox, Fennec,
   Firefox OS)</li>
</ol>
<p>Inside each tier are the distinct sub-tiers:</p>
<ol>
<li>export</li>
<li>libs</li>
<li>tools</li>
</ol>
<p>A Makefile generally belongs to 1 main tier. Inside Makefile's or in
other included .mk files (make files that are not typically called
directly by make) are statements which define which directories
belong to which tiers. See
<a href="https://mxr.mozilla.org/mozilla-central/source/toolkit/toolkit-tiers.mk">toolkit-tiers.mk</a>
for an example.</p>
<p>When the top-level Makefile is invoked, it iterates through every tier
and every sub-tier within it. It starts at the first tier and evaluates
the <em>export</em> target on every Makefile/directory defined in it. It then
moves on to the <em>libs</em> target then finally the <em>tools</em> target. When it's
done with the <em>tools</em> target, it moves on to the next tier and does the
same iteration.</p>
<p>For example, we first start by evaluating the <em>export</em> target of the
<em>base</em> tier. Then we evaluate <em>base</em>'s <em>libs</em> and <em>tools</em> tiers. We then
move on to <em>nspr</em> and do the same. And, we keep going. In other words,
the build system makes 3 passes through each tier.</p>
<p>Tiers are composed of directory members. e.g. <em>dom</em> or <em>layout</em>. When
make descends into a tier member directory, it looks for specially named
variables that tell it what sub-directories are also part of this
directory. The <em>DIRS</em> variable is the most common. But, we also use
<em>TEST_DIRS</em>, <em>PARALLEL_DIRS</em>, <em>TOOL_DIRS</em>, and a few others. make will
invoke make for all defined child directories and for the children of
the children, and so on. This is what we mean by <em>recursive make</em>. make
essentially recurses into directory trees, evaluating all the
directories linearly.</p>
<p>Getting back to the tiers, the sub-tiers <em>export</em>, <em>libs</em>, and <em>tools</em>
can be thought of as <em>pre-build</em>, <em>build</em>, and <em>post-build</em> events.
Although, this analogy is far from perfect.</p>
<p><em>export</em> generally prepares the object directory for more comprehensive
building. It copies C/C++ header files into a unified object directory,
generates header files from IDLs files, etc.</p>
<p><em>libs</em> does most of the work. It compiles C++ code and performs lots of
other main work, such as Jar manifest creation.</p>
<p><em>tools</em> does a lot of miscellaneous work. If you have tests enabled,
this is where tests are typically compiled and/or installed, for
example.</p>
<h3>Processing a Makefile</h3>
<p>For each directory inside a tier, make evaluates the Makefile in that
directory for the target/sub-tier specified.</p>
<p>The basic gist of Makefile execution is actually pretty simple.</p>
<p>Mozilla's Makefiles typically look like:</p>
<pre><code>DEPTH := .
topsrcdir := @top_srcdir@
srcdir := @srcdir@
VPATH := @srcdir@

include $(DEPTH)/config/autoconf.mk

IDLSRCS := foo.idl bar.idl
CPPSRCS := hello.cpp world.cpp

include $(topsrcdir)/config/rules.mk
</code></pre>
<p>All the magic in Makefile processing happens in <em>rules.mk</em>. This make file
simply looks for specially named variables (like <em>IDLSRCS</em> or <em>CPPSRCS</em>)
and magically converts them into targets for make to evaluate.</p>
<p>In the above sample Makefile, the <em>IDLSRCS</em> variable will result in an
implicit <em>export</em> target which copies IDLs into the object directory and
compiles them to .h files. <em>CPPSRCS</em> will result in a <em>libs</em> target that
results in each .cpp file being compiled into a .o file.</p>
<p>Of course, there is nothing stopping you from defining targets/rules in
Makefile's themselves. This practice is actually quite widespread.
Unfortunately, it is a bad practice, so you shouldn't do it. The
preferred behavior is to define variables in a Makefile and have
rules.mk magically provide the make targets/rules to do stuff with them.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">Bug 769378</a> tracks
fixing this bad practice.</p>
<h2>Conclusion</h2>
<p>So, there you have it: a very brief overview of how Mozilla's build
system works!</p>
<p>In my next post, I will shed some light onto how much times goes into
different parts of the build system.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="makefile-execution-times"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/07/28/makefile-execution-times" rel="bookmark" title="Permanent Link to Makefile Execution Times">Makefile Execution Times</a></h2>
  <small>July 28, 2012 at 12:45 AM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/pymake'>pymake</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>In my course of hacking about with Mozilla's build system, I've been
using pymake (a Python implementation of GNU make) to parse, examine,
and manipulate make files. In doing so, I've learned some interesting
things, dispelling myths in the process.</p>
<p>People often say that parsing make files is slow and that the sheer
number of Makefile.in's in mozilla-central (Firefox's source tree) is
leading to lots of overhead in make execution. This statement is only
partially correct.</p>
<p><em>Parsing</em> make files is actually pretty fast. Using pymake's parser API,
I'm able to parse every Makefile.in in mozilla-central in under 5
seconds on my 2011 generation MacBook Pro using a single core. Not too
shabby, especially considering that there are about 82,500 lines in all
the Makefile.in's.</p>
<p>Evaluation of make files, however, is a completely different story. You
see, parsing a string containing make file directives is only part of
what needs to be done. Once you've parsed a make file into a statement
list (essentially an AST), you need to load that into a data structure
fit for evaluation. Because of the way make files are evaluated,
you need to iterate through every parsed statement and evaluate it
for side-effects. This occurs before you actually evaluate specific
targets in the make file itself. As I found out, this process can be
time-consuming.</p>
<p>For mozilla-central, the cost of loading the statement list into a data
structure ready for target evaluation takes about 1 minute in aggregate.
And, considering we effectively iterate through every Makefile in
mozilla-central 3 times when building (once for every tier state of
export, libs, and tools), you can multiply this figure by 3.</p>
<p>Put another way, <em>parsing</em> Makefile's is fast: loading them for
target evaluation is slow.</p>
<p>Digging deeper, I uncovered the main source of the additional overhead:
<em>rules.mk</em>.</p>
<p>Nearly every Makefile in mozilla-central has a pattern that looks like:</p>
<pre><code>DEPTH = ../..
topsrcdir = @top_srcdir@
srcdir = @srcdir@
VPATH = @srcdir@

include $(DEPTH)/config/autoconf.mk

&lt;LOCAL MAKE FILE DECLARATIONS&gt;

include $(topsrcdir)/config/rules.mk
</code></pre>
<p>We have a header boilerplate, followed by a bunch of Makefile-specific
variables definitions and rules. Finally, we include the <em>rules.mk</em>
file. This is the make file that takes specially-named variables and
converts them to rules (actions) for make to perform.</p>
<p>A typical Makefile.in is a few dozen lines or so. This often reduces to
maybe a dozen parsed statements. By contrast, <em>rules.mk</em> is massive. It
is currently 1770 lines and may include other make files, bringing the
total to ~3000 lines.</p>
<p>Pymake has an LRU cache that caches the results of <em>parsing</em> make files.
This means it only has to parse a single make file into a statement list
once (assuming no cache eviction). <em>rules.mk</em> is frequently used, so it
should have no eviction. Even if it were evicted, I've measured that
<em>parsing</em> is pretty fast.</p>
<p>Unfortunately, the cache doesn't help with evaluation. For every
Makefile in mozilla-central, pymake will need to evaluate rules.mk
within the context of that specific Makefile. It's impossible to cache
the results of a previous evaluation because the side-effects of rules.mk
are determined by what is defined in the Makefile that includes it.</p>
<p>I performed an experiment where I stripped the <em>include rules.mk</em>
statement from all parsed Makefile.in's. This essentially isolates the
overhead of loading <em>rules.mk</em>. It turns out that all but ~2 seconds
of evaluation time is spent in <em>rules.mk</em>. In other words,
without <em>rules.mk</em>, the Makefile.in's are loaded and ready for evaluation
in just a few seconds (over parsing time), not ~1 minute!</p>
<p>What does this all mean?</p>
<p>Is <em>parsing</em> make files slow? Technically no. <em>Parsing</em> itself is not slow.
It is actually quite fast! Pymake even surprised me at how fast it can
parse all the Makefile.in's in mozilla-central.</p>
<p><em>Loading</em> parsed make file statements to be ready for evaluation is
actually the bit that is slow - at least in the case of mozilla-central.
Specifically, the loading of <em>rules.mk</em> is what constitutes the
overwhelming majority of the time spent loading Makefile's.</p>
<p>That being said, <em>parsing</em> and <em>loading</em> go hand in hand. You almost
never parse a make file without loading and evaluating it. So, if you
consider <em>parsing</em> to include parsing <em>and</em> readying the make file for
execution, there is some truth to the statement that parsing make files
is slow. Someone splitting hairs may say differently.</p>
<p>Is there anything we can do? Good question.</p>
<p>I believe that build times of mozilla-central can be reduced by reducing
the size of <em>rules.mk</em>. Obviously, the content of <em>rules.mk</em> is
important, so we can't just delete content. But, we can be more
intelligent about how it is loaded. For example, we can move pieces of
<em>rules.mk</em> into separate <em>.mk</em> files and conditionally include these
files based on the presence of specific variables. We already do this
today, but only partially: there are still a number of bits of rules.mk
that could be factored out into separate files. By conditionally loading
make file content from <em>rules.mk</em>, we would be reducing the number of
statements that need to be loaded before evaluating each Makefile. And,
this should, in turn, make build times faster. Keep in mind that any
savings will be multiplied by roughly 3 since we do 3 passes over
Makefile's during a build.</p>
<p>To my knowledge, there aren't any bugs yet on file to do this. Given the
measurements I've obtained, I encourage somebody to do this work. Even
if it doesn't reduce build times, I think it will be a win since it will
make the make rules easier to understand since they will be contained in
function-specific files rather than one monolithic file. At worse, we
have better readability. At best, we have better readability and faster
build times. Win!</p>
<p>Finally, I don't know what the impact on GNU make is. Presumably, GNU
make evaluates make files faster than pymake (C is generally faster than
python). Therefore, reducing the size of <em>rules.mk</em> should make GNU make
faster. By how much, I have no clue.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="mozilla-build-system-plan-of-attack"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/07/25/mozilla-build-system-plan-of-attack" rel="bookmark" title="Permanent Link to Mozilla Build System Plan of Attack">Mozilla Build System Plan of Attack</a></h2>
  <small>July 25, 2012 at 11:30 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/build-system'>build system</a>
 | <a href="http://gregoryszorc.com/blog/2012/07/25/mozilla-build-system-plan-of-attack#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>Since I published my <a href="http://gregoryszorc.com/blog/2012/06/25/improving-mozilla%27s-build-system/">brain dump
post</a>
on improving Mozilla's build system for Gecko applications (including
Firefox and Firefox OS), there has been some exciting progress.</p>
<p>It wasn't stated in that original post, but the context for that post
was to propose a plan in preparation of a meeting between the core
contributors to the build system at Mozilla. I'm pleased to report that
the plan was generally well-received.</p>
<p>We pretty much all agreed that parts 1, 2, and 3 are all important and
we should actively work towards them. Parts 4, 5, and 6 were a bit more
contentious. There are some good parts and some bad parts. We're not
ready to adopt them just quite yet. (Don't bother reading the original
post to look up what these parts corresponded to - I'll cover that
later.)</p>
<p>Since that post and meeting, there has also been additional discussion
around more specifics. I am going to share with you now where we stand.</p>
<h2>BuildSplendid</h2>
<p><strong>BuildSplendid</strong> is an umbrella term associated with projects/goals to
make the developer experience (including building) better - more
splendid if you will.</p>
<p><strong>BuildSplendid</strong> started as the name of my personal Git branch for
hacking on the build system. I'm encouraging others to adopt the term
because, well, it is easier to refer to (people like project codenames).
If it doesn't stick, that's fine by me - there are other terms that
will.</p>
<h2>BuildFaster</h2>
<p>An important project inside <em>BuildSplendid</em> is <strong>BuildFaster</strong>.</p>
<p><em>BuildFaster</em> focuses on the following goals:</p>
<ol>
<li>Making the <em>existing</em> build system faster, better, stronger (but not
   harder).</li>
<li>Making changes to the build system to facilitate the <em>future</em> use of
   alternate build backends (like Tup or Ninja). Work to enable Visual
   Studio, Xcode, etc project generation also falls here.</li>
</ol>
<p>The distinction between these goals can be murky. But, I'll try.</p>
<p>Falling squarely in #1 are:</p>
<ul>
<li>Switching the buildbot infrastructure to use pymake on Windows</li>
</ul>
<p>Falling in #2 are:</p>
<ul>
<li>Making Makefile.in's data-centric</li>
<li>Supporting multiple build backends</li>
</ul>
<p>Conflated between the two are:</p>
<ul>
<li>Ensuring Makefile's no-op if nothing has changed</li>
<li>Optimizing existing make rules. This involves merging related
  functionality as well as eliminating clown shoes in existing rules.</li>
</ul>
<p>The two goals of <em>BuildFaster</em> roughly map to the short-term and long-term
strategies, respectively. There is consensus that recursive make (our
existing build backend) does not scale and we will plateau in terms of
performance no matter how optimal we make it. That doesn't mean we are
giving up on it: there are things we can and should do so our existing
non-recursive make backend builds faster.</p>
<p>In parallel, we will also work towards the longer-term solution of
supporting alternate build backends. <strong>This includes non-recursive
make</strong> as well as things like Tup, Ninja, and even Visual Studio and
Xcode. (I consider non-recursive make to be a separate build backend
because changing our existing Makefile.in's to support non-recursive
execution effectively means rewriting the input files (Makefile.in's).
At that point, you've invented a new build backend.)</p>
<p>For people who casually interact with the build system, these two goals
will blend together. It is not important for most to know what bucket
something falls under.</p>
<h3>BuildFaster Action Items</h3>
<p><em>BuildFaster</em> action items are being tracked in Bugzilla using the
[BuildFaster:*] whiteboard annotation.</p>
<p>There is no explicit tracking bug for the short-term goal (#1). Instead,
we are relying on the whiteboard annotation.</p>
<p>We are tracking the longer-term goal of supporting alternate build
backends at <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774049">bug 774049</a>.</p>
<p>The most important task to help us reach the goals is to make our
Makefile.in's data centric. This means:</p>
<ul>
<li>Makefile.in's <strong>must</strong> consist of only simple variable assignment</li>
<li>Makefile.in's <strong>must</strong> not rely on being evaluated to perform variable
  assignment.</li>
</ul>
<p>Basically, our build config should be defined by static key-value pairs.</p>
<p>This translates to:</p>
<ul>
<li>Move all rules out of Makefile.in's <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">bug 769378</a></li>
<li>Remove use of $(shell) from Makefile.in's <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769390">bug 769390</a></li>
<li>Remove filesystem functions from Makefile.in's <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769407">bug 769407</a></li>
<li>And more, as we identify the need</li>
</ul>
<p>While we have these tracking bugs on file, we still don't have bugs
filed that track individual Makefile.in's that need updated. <strong>If you
are a contributor, you can help by doing your part to file bugs for your
Makefile.in's.</strong> If your Makefile.in violates the above rules, please
file a bug in the <strong>Build Config</strong> component of the product it is under
(typically <strong>Core</strong>). See the tree of the above bugs for examples.</p>
<p>Also part of <em>BuildFaster</em> (but not relevant to most) is the task of
changing the build system to support multiple backends. Currently,
pieces like <em>configure</em> assume the Makefile.in to Makefile conversion is
always what is wanted. These parts will be worked on by core
contributors to the build system and thus aren't of concern to most.</p>
<p>I will be the first to admit that a lot of the work to <em>purify</em>
Makefile.in's to be data centric will look like a lot of busy work with
little immediate gain. The real benefits to this work will manifest
down the road. That being said, removing rules from Makefile.in's and
implementing things as rules in rules.mk helps ensure that the
implementation is proper (rules.mk is coded by make ninjas and thus
probably does things <em>right</em>). This can lead to faster build times.</p>
<h2>mozbuild</h2>
<p><strong>mozbuild</strong> is a Python package that provides an API to the build system.</p>
<p>What <em>mozbuild</em> will contain is still up in the air because it hasn't
landed in mozilla-central yet. In the code I'm waiting on review to
uplift to mozilla-central, <em>mozbuild</em> contains:</p>
<ul>
<li>An API for invoking the build system backend (e.g. launching make). It
  basically reimplements client.mk because client.mk sucks and needs to
  be replaced.</li>
<li>An API for launching tests easily. This reimplements functionality in
  testsuite-targets.mk, but in a much cleaner way. Running a single test
  can now be done with a single Python function call. This may sound
  boring, but it is very useful. You just import a module and pass a
  filesystem path to a test file to a function and a test runs. Boom!</li>
<li>Module for extracting compiler warnings from build output and storing
  in a persisted database for post-build retrieval. Compiler warning
  tracking \o/</li>
<li>Module for converting build system output into structured logs. It
  records things like time spent in different directories, etc. We could
  use this for tracking build performance regressions. We just need a
  arewe*yet.com domain...</li>
<li>A replacement for .mozconfig's that sucks less (stronger validation,
  settings for not just build config, convenient Python API, etc).</li>
</ul>
<p>And, upcoming features which I haven't yet tried to land in
mozilla-central include:</p>
<ul>
<li>API for extracting metadata from Makefile.in's and other frontend
  files. Want a Python class instance describing the IDLs defined in an
  individual Makefile.in or across the entire tree? <em>mozbuild</em> can provide
  that. This functionality will be used to configure alternate build
  backends.</li>
<li>Build backend API which allows for different build backends to be
  configured (e.g. recursive make, Tup, Ninja, etc). When we support
  multiple build backends, they'll live in <em>mozbuild</em>.</li>
</ul>
<p><em>mozbuild</em> can really be thought of as a clean backend to the build
system and related functionality (like running tests). Everything in
<em>mozbuild</em> could exist in make files or in .py files littered in
<em>build/</em>, <em>config/</em>, etc. But, that would involve maintaining make files
and/or not having a cohesive API. I wanted a clean slate that was free
from the burdens of the existing world. <em>mozbuild</em> was born.</p>
<p>I concede that there will be non-clear lines of division between
<em>mozbuild</em> and other Python packages and/or Mozilla modules. For
example, is <em>mozbuild</em> the appropriate location to define an API for
taking the existing build configuration and launching a Mochitest? I'm
not sure. For now, I'm stuffing functionality inside <em>mozbuild</em> unless
there is a clear reason for it to exist elsewhere. If we want to
separate (because of module ownership issues, for example), we can do
that.</p>
<p>My vision for <em>mozbuild</em> is for it to be the answer to the question
<em>how does the Mozilla build system work?</em> You should be able to say,
<em>look at the code in python/mozbuild and you will have all the answers.</em></p>
<h3>mozbuild Action Items</h3>
<p>The single action item for <em>mozbuild</em> is getting it landed. I have code
written that I think is good enough for an initial landing (with obvious
shortcomings being addressed in follow-up bugs). It just needs some love
from reviewers.</p>
<p>Landing <em>mozbuild</em> is tracked in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=751795">bug 751795</a>. I
initially dropped a monolithic patch. I have since started splitting
bits up into bite-sized patches to facilitate faster, smaller reviews.
(See the blocking bugs.)</p>
<h2>mach</h2>
<p><em>mozbuild</em> is just a Python package - an API. It has no frontend.</p>
<p>Enter <strong>mach</strong>.</p>
<p><strong>mach</strong> is a command-line frontend to <em>mozbuild</em> and beyond.</p>
<p>Currently, <em>mach</em> provides some convenient shortcuts for performing
common tasks. e.g. you can run a test by tab-completing to its filename
using your shell. It also provides nifty output in supported terminals,
including colorizing and a basic progress indicator during building.</p>
<p>You can think of <em>mach</em> as a replacement for <em>client.mk</em> and other make
targets. But, <em>mach</em>'s purpose doesn't end there. My vision for <em>mach</em>
is for it to be the one-stop shop for all your mozilla-central
interaction needs.</p>
<p>From a mozilla-central tree, you should be able to type
<strong>./mach <action></strong> and do whatever you need to do. This could be
building Firefox, running tests, uploading a patch to Bugzilla, etc.</p>
<p>I'm capturing ideas for <em>mach</em> features in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774108">bug 774108</a>.</p>
<h3>mach Action Items</h3>
<p><em>mach</em> is in the same boat as <em>mozbuild</em>: it's waiting for reviewer
love. If you are interested in reviewing it, please let me know.</p>
<p>Once <em>mach</em> lands, I will be looking to the larger community to improve
it. I want people to go wild implementing features. I believe that
<em>mach</em> will have a significant positive impact on driving contributions
to Mozilla because it will make the process much more streamlined and
less prone to error. I think it is a no-brainer to check in <em>mach</em> as
soon as possible so these wins can be realized.</p>
<p>There is an open question of who will own <em>mach</em> in terms of module
ownership. <em>mach</em> isn't really part of anything. Sure, it interacts with
the build system, testing code, tools, etc. But, it isn't actually part
of any of that. Maybe a new module will be created for it. I'm not
familiar with how the modules system works and I would love to chat with
someone about options here.</p>
<h2>Project Interaction</h2>
<p>How are all of these projects related?</p>
<p><em>BuildFaster</em> is what everyone is working on today. It currently focuses
on making the existing recursive make based build backend faster using
whatever means necessary. <em>BuildFaster</em> could theoretically evolve to
cover other build backends (like non-recursive make). Time will tell
what falls under the <em>BuildFaster</em> banner.</p>
<p><em>mozbuild</em> is immediately focused on providing the functionality to
enable <em>mach</em> to land.</p>
<p><em>mach</em> is about improving the overall developer experience when
it comes to contributing to Firefox and other in-tree applications (like
Firefox OS). It's related to the build system in that it provides a nice
frontend to it. That's the only relationship. <em>mach</em> isn't part of the
build system (at least not yet - it may eventually be used to perform
actions on buildbot machines).</p>
<p>Down the road, <em>mozbuild</em> will gain lots of new features core to the
build system. It will learn how to extract metadata from Makefile.in's
which can be used by other build backends. It will define a build
backend interface and the various build backends will be implemented
in mozbuild. Aspects of the existing build system currently implemented in
make files or in various Python files scattered across the tree will be
added to <em>mozbuild</em> and exposed with a clean, reusable, and testable
API.</p>
<p>Today, <em>BuildFaster</em> is the important project with all the attention.
When <em>mach</em> lands, it will (hopefully) gather a lot of attention. But,
it will be from a different group (the larger contributor community -
not just build system people).</p>
<p><em>mozbuild</em> today is only needed to support <em>mach</em>. But, once <em>mozbuild</em>
lands and <em>mach</em> is on its own, <em>mozbuild</em>'s purpose  will shift to support
<em>BuildFaster</em> and other activities under the <em>BuildSplendid</em> banner.</p>
<h2>Conclusion</h2>
<p>We have a lot of work ahead of us. Please look at the bugs linked above
and help out in any way you can.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/07/25/mozilla-build-system-plan-of-attack#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="one-year-at-mozilla"></a>
  <h2 class="blog_post_title"><a href="/blog/2012/07/18/one-year-at-mozilla" rel="bookmark" title="Permanent Link to One Year at Mozilla">One Year at Mozilla</a></h2>
  <small>July 18, 2012 at 12:00 AM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>, <a href='/blog/category/sync'>Sync</a>
 | <a href="http://gregoryszorc.com/blog/2012/07/18/one-year-at-mozilla#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>It is hard to believe that my first day as a full-time employee of Mozilla
was one year ago today! But, here I am. And, I'd like to think the past
year is worth reflecting on.</p>
<p>So, what have I been doing for a year? Good question!</p>
<h2>Accomplishments</h2>
<ul>
<li>First patch and commit to Firefox: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=673209">bug 673209</a>.
  Yes, my first patch was to configure.in. It scared me too.</li>
<li>Number of non-merge commits: 133</li>
<li>Number of merge commits: 49</li>
<li>Number of reviews: 31</li>
<li>Favorite commit message: <a href="https://hg.mozilla.org/mozilla-central/rev/88d02a07d390">88d02a07d390</a>
  <em>Fix bug 725478 because we run a buggy Python released almost 5 years
  ago; r=tigerblood</em> (it was a bustage follow-up).</li>
<li>Biggest mistake: buildbotcustom change to packaging turned every tree
  red. All of them. Including release. I think I have philor on record
  saying it is the worst burnage he's ever seen. Mission accomplished!</li>
</ul>
<p>Major User-Facing Features:</p>
<ul>
<li>Wrote add-on sync for Firefox (with help from many others, especially
  Dave Townsend and Blair McBride).</li>
<li>Principle reviewer for Apps in the Cloud (apps sync) in Firefox. (Are
  reviewers allowed to take credit?)</li>
</ul>
<p>Honestly, when I see that list, I think <em>that's all?</em> It doesn't feel
like a lot, especially since I work on a major user-facing feature
(Firefox Sync). I do contribute to more. But, if you ask me what the
most significant impact was, I don't think I can call anything else out
as <em>major</em>.</p>
<p>There are certainly a lot of minor things:</p>
<ul>
<li>Actually managed to understand how Firefox Sync works, including the
  crypto model. I even <a href="http://docs.services.mozilla.com/sync/storageformat5.html">documented</a>
  it! I don't think I knew any of that when I started (I basically knew
  that Firefox Sync was using strong client-side encryption. What that
  meant, I had no clue.)</li>
<li>Filed initial bugs (including some patches) to compile mozilla-central
  on Windows 8 and MSVC 2011. By the time people started working on
  Metro development, mozilla-build, configure, and the like already
  supported building.</li>
<li>Configured <a href="https://ci.mozilla.org/job/sync-android/">Android Sync Jenkins Builder</a>.
  I'm told the Android Sync team loves it! You gotta love all the
  built-in dashboards. I really wish we had this for mozilla-central.</li>
<li>Made xpcshell test harness write xUnit files. Machine readable output
  of test results, baby!</li>
<li>Implement <em>send tab to device</em> API in Firefox Sync. Too bad we don't
  have UX to use it :(</li>
<li>Implemented testing-only JavaScript modules. So, instead of the hack
  that is [head] files in tests, you can
  <em>Cu.import("resource://testing-common/foo.js");</em></li>
<li>Made test package generation quieter. This made build logs about 30%
  smaller. This means you can get at build results faster.</li>
<li>Hacked around with JavaScript code coverage using the JS Debugger API.
  Failed in the process. But, I learned a lot about the JS Debugger API,
  so I consider it a win.</li>
<li>Rewrote Firefox Sync's record reconciling algorithm. The old one was
  full of subtle data loss corner cases. The new algorithm is much more
  robust (we think - even with 3 reviewers there was still some head
  scratching).</li>
<li>Emancipated lots of generic JavaScript code from the Sync tree into
  the a <em>services-common</em> package. This anticipated Apps in the Cloud
  and notifications' requirement to use this functionality and allowed
  those projects to get going quicker. At this point, we're effectively
  running a mini Toolkit. We really need to port some of this
  <em>upstream</em>.</li>
<li>Helped design the <a href="http://docs.services.mozilla.com/storage/apis-2.0.html">next version</a>
  of the HTTP service to be used by Sync.</li>
<li>Implemented a standalone JavaScript implementation of the above. The
  production server used by Mozilla runs on Python (running the Python
  server in Mozilla's test environment would be too difficult). The
  server was also implemented using just the spec. This allowed us to
  clarify many parts of the spec. The Python functional tests can also
  be executed against the JS server. This gives us confidence that
  functionality is equivalent and tests hitting the test/JS server will
  behave the same as if they are hitting the production Python server.</li>
<li>Implemented a standalone JavaScript
  <a href="https://hg.mozilla.org/mozilla-central/file/default/services/common/storageservice.js">client</a>  for the above service. Previously, all the logic for this was scattered
  over about a dozen files and was notoriously difficult to audit and
  update. I also think it is a decent example of good code.  Clean.
  Highly documented. No hacks.</li>
<li>Reviewed a skeleton for the notifications service, which will
  eventually power browser notifications in Firefox.</li>
<li>Build system patches to better support Clang. Thankfully, Rafael
  Espndola has been our Clang champion as of late and is now ensuring
  the bleeding edge of Clang does not break the tree. Thanks, Rafael! (I
  actually think he is in the process of switching our OS X builds to
  use Clang as I type this!)</li>
<li>Worked with security and crypto people to devise the security model
  behind the next version of Firefox Sync. (Brian Warner and Ben Adida
  have been doing most of the crypto work. I'm mostly on the sidelines
  making sure they design a system that can easily interop with Sync.)</li>
<li>Helped devise the <a href="http://docs.services.mozilla.com/sync/storageformat6.html">next version</a>
  of Sync's server-side storage format. This will make the next version
  of Sync faster and able to hold more data at lower server cost.</li>
<li>Gave lots of love to documentation at
  <a href="http://docs.services.mozilla.com/">https://docs.services.mozilla.com/</a>
  (especially the Sync docs). It's almost at the point where others can
  implement Sync clients without having to ask one of the fewer than 10
  people on the planet who actually know.</li>
<li>Contributed many small patches to the build system. Mostly general
  cleanup so far. Although, I have much bigger plans in the works.</li>
<li>Many miscellaneous small things. (I get distracted easily.)</li>
</ul>
<p>Well, that list doesn't seem too shabby. But, a lot of it is smaller
ticket items. I don't think there's anything there worth writing home
about.  Whatever. The future is looking bright for Firefox Sync (Persona
integration will make Sync usable by millions more) and new sync
backends are coming (including search engine sync). So, I'm fine with
not having a longer list of big ticket contributions after only a year.</p>
<h2>On Ramping up at Mozilla</h2>
<p>I will be the first to admit that I had a difficult time getting into
the groove at Mozilla and my first months (dare I say my first half
year) were unproductive by my personal standards.</p>
<p>I can't say I wasn't warned. My manager (Mike Connor) told me
multiple times that it would happen. I was skeptical, insteading
rationalizing that my previous track record of learnly quickly
would hold. He was right. I was wrong. I got fat from the humble pie.</p>
<p>There are a few reasons for this. For starters, I was starting a new
job. It's almost impossible achieve 100% productivity on your first day.
Second, I was working with tools I knew little about, including
JavaScript and especially including the flavor of JavaScript used
inside Firefox. (Short version: the JavaScript within Firefox is awesome
in that it implements bleeding-edge features of the language.
Unfortunately, the JavaScript inside Firefox/Gecko is contaminated
by this blight called XPCOM. It makes things ugly and not very
JavaScript-y. XPCOM also makes the learning curve that much harder
because now you have to learn multiple technologies at the same time.)
It was daunting.</p>
<p>Not helping matters was the fact that Firefox Sync is complicated.
Syncing data is in of itself a difficult problem. Throw in remote
servers, an HTTP protocol, a encryption, and interaction with systems
inside Firefox that are themselves complicated, and you have a <strong>hard</strong>
problem. My first months were literally spent being a thorn in Philipp
von Wieter^H^H^H^H^H^H philikon's side, barraging him with an endless
stream of questions. I am forever in beer debt to him because of this.
When Philipp left the team to work on Boot 2 Gecko and the rest of the
Firefox Sync team was retasked to work on Android Sync shortly
thereafter, I was on my own little island to manage Firefox Sync.
I kind of felt like Tom Hanks' character in <em>Castaway</em>.</p>
<p>If I have one piece of advice for people starting at Mozilla it's this:
be prepared to be humbled by your own ignorance. There is a lot to
learn. It's not easy. Don't feel bad when you struggle. The payoff is
worth it.</p>
<h2>On Life at Mozilla</h2>
<p>Despite the hurdles I initially faced ramping up at Mozilla, life at
Mozilla is great. This mostly stems from the people, of course.</p>
<p>If you are just looking for technical excellence, I think Mozilla has
one of the highest concentrations of any company in the world. Sure,
larger companies will have <em>more</em> amazing individuals. But, the number
per capita at Mozilla is just staggering. I don't know how many times
I've met or talked with someone only to find out later they are
considered to be one of the best in his or her respective field. Reading
Mozilla's phonebook is like looking at a <em>Who's Who</em> list. For someone
like me who loves being a sponge for knowledge, Mozilla is an environment
in which I can thrive. Just thinking back at everything I've learned in
the past year makes my mind asplode.</p>
<p>On the personal front, the personalities of Mozillians are also top
notch. People are generally helpful and supportive. (They need to be for
an open source project to thrive.) People recognize good ideas when they
hear them and there is comparatively few political battles to be won
when enacting change. People themselves are generally interesting and
passionate about the world and the work they do. If you are living
inside the Mozilla bubble, you may not realize how lucky you have it.
I could give specific examples, but I'd be writing all night. Just
take my word for it.</p>
<p>If you need something to whet your appetite, just check out the
zaniness that is <a href="http://mozillamemes.tumblr.com/">Mozilla Memes</a>.
I don't expect you to understand many of the posts unless you are a
Mozillian or follower of Reddit and know what internet memes are. But, if
you are either, it pretty much sums up a large part of the culture for
you. Sometimes I feel like I'm living in one giant, happy meme.</p>
<p>One of the aspects I love most about working at Mozilla is I finally
feel that my career interests are aligned with an organization I
philosophically agree with. Just read the
<a href="https://www.mozilla.org/about/manifesto.html">Mozilla Manifesto</a>. What's
not to like?</p>
<p>This is one of the primary factors that convinced me to join Mozilla.
After Microsoft acquired the startup where I had my first post-college
job (Tellme Networks), I could never hold my head high in Silicon Valley
among my friends in the tech sector. <em>Normal</em> people and those outside
of Silicon Valley were like, "Microsoft, cool!" But, something just
didn't feel right about saying I worked for them. I felt like I was working
for the Empire while I really wanted to be working for the Rebel Alliance.
I felt like I had to atone for my time at Microsoft. I felt like I needed
to cleanse my soul. Mozilla was an obvious answer.</p>
<p>(I don't mean to disparage Microsoft. I actually think the culture has
changed since the days when their behavior earned them the reputation
that Silicon Valley stills holds them accountable for. Still, I would
not work for them in Silicon Valley. Anyway, I'm not here to talk about
the past.)</p>
<p>Mozilla is an organization I'm proud to work for. I exercise that pride
by frequently wearing my awesome Firefox hoodie. Nearly every time I do,
random people come up to me and say how they love Firefox and/or what
Mozilla does for the world. Every time they do, it brings a smile to my
face. This constantly reinforces what I know to be true: that I'm
working for a great organization.</p>
<h2>Future at Mozilla</h2>
<p>I'm already looking forward to the next year at Mozilla. It is already
shaping up to be much, much more productive than my first.</p>
<p>On the roadmap, all of my hacking about with the build system is about
to pay dividends. Ever since my first day at Mozilla I have been
frustrated with the build system and the developer experience one must
go through to contribute to Firefox. After many months of casual (mostly
evenings and weekends) experimentation, my work is about to pay off.</p>
<p>I have successfully formulated a <a href="http://gregoryszorc.com/blog/2012/06/25/improving-mozilla%27s-build-system/">plan of attack</a>
and helped convince others this is what we need to do. We have since
<a href="http://coop.deadsquid.com/2012/07/reviving-buildfaster-plan-of-attack/">committed</a>
to the fundamental components of that plan and are
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774049">tracking</a> its
progress. (I don't mean to take sole or even primary responsibility for
this as the credit resides with a number of people. But, I would like to
think that the dozens of times I championed aspects of this plan in IRC
and in hallway chats before I was the first person to articulate it in a
post helped lay the groundwork for the eventual acceptance of this
project.) Once we see progress on this project, great things will come
from it. I promise.</p>
<p>My work towards making the build system faster had an unintended
consequence: the creation of a new tool that serves as a frontend to the
build system. One day, I took a step backwards and realized that the
potential for such a tool is much greater than simply interacting with
the build system. So, I extracted that work from my build system
hacking and polished it up a bit. It is now
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=751795">one review away</a>
from landing. When it does, thousands of Firefox developers will have a
much better experience when developing Firefox. And, my hope is for
<a href="https://bugzilla.mozilla.org/showdependencytree.cgi?id=774108">many more features</a>
to follow to make it even more awesome, especially for first-time
contributors. I believe this is important to help advance Mozilla's
Mission.</p>
<p>Improving the developer experience of Firefox is exciting and it will
likely make a lot of people really happy. But, it's neither the most
exciting nor most important project I'll contribute to in the upcoming
year. The most exciting and important project for me will be
refactoring Firefox Sync to make it faster, more robust, sync more data,
and, most importantly, usable by more people.</p>
<p>Firefox Sync stands out from similar products in that it keeps your data
safe. Really safe. I
<a href="http://gregoryszorc.com/blog/2012/04/08/comparing-the-security-and-privacy-of-browser-syncing/">blogged</a>
about this previously. But, I intentionally kept the tone of that post
neutral and factual. The truth is that the security model of Firefox Sync
makes it look like nearly all other products aren't even trying. I take
immense pride in working on a data-sharing feature that makes users'
lives better <strong>without undermining security</strong>. Firefox Sync stands in
rare company in this regard.</p>
<p>Unfortunately, in our zeal for the best security possible, we designed a
product that isn't usable by the majority of people because it is too
complicated to set up and is prone to losing your data. In the end, this
doesn't really serve the overall Firefox user base.</p>
<p>We've been hard at work devising the next version of Firefox Sync which
will retain the optimum security and privacy settings of the existing
product while extending usability at nearly-comparable security and
ofer data recovery to the vast majority of our users. <strong>This is huge.</strong></p>
<p>Yeah, I'm pretty damn excited about my next year at Mozilla.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2012/07/18/one-year-at-mozilla#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="../3"> Previous Page</a>
  --  
 <a href="../5">Next Page </a>

              </div>
              
          <div id="sidebar">
          <ul>
            <li>
              <h2>Categories</h2>
              <ul>
                <li><a href="/blog/category/clang">Clang</a></li>
                <li><a href="/blog/category/firefox">Firefox</a></li>
                <li><a href="/blog/category/git">Git</a></li>
                <li><a href="/blog/category/mercurial">Mercurial</a></li>
                <li><a href="/blog/category/mozilla">Mozilla</a></li>
                <li><a href="/blog/category/python">Python</a></li>
                <li><a href="/blog/category/sync">Sync</a></li>
                <li><a href="/blog/category/browsers">browsers</a></li>
                <li><a href="/blog/category/build-system">build system</a></li>
                <li><a href="/blog/category/compilers">compilers</a></li>
                <li><a href="/blog/category/internet">internet</a></li>
                <li><a href="/blog/category/logging">logging</a></li>
                <li><a href="/blog/category/mach">mach</a></li>
                <li><a href="/blog/category/make">make</a></li>
                <li><a href="/blog/category/misc">misc</a></li>
                <li><a href="/blog/category/movies">movies</a></li>
                <li><a href="/blog/category/pymake">pymake</a></li>
                <li><a href="/blog/category/security">security</a></li>
                <li><a href="/blog/category/testing">testing</a></li>
              </ul>
            </li>
          </ul>
        </div>



              <div style="clear: both;">&nbsp;</div>
          </div>
        </div>
      </div>
      <div id="footer">
        
  <hr/>
  <p>Copyright (c) 2012 Gregory Szorc. All rights reserved. Design by <a href="http://www.freecsstemplates.org/"> CSS Templates</a>.</p>


      </div>
    </div>
  </body>
</html>





