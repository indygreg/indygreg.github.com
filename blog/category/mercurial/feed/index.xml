<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Gregory Szorc's Digital Home</title>
    <link>http://gregoryszorc.com/blog</link>
    <description>Rambling on</description>
    <pubDate>Fri, 29 May 2015 18:33:21 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Faster Cloning from hg.mozilla.org With Server Provided Bundles</title>
      <link>http://gregoryszorc.com/blog/2015/05/29/faster-cloning-from-hg.mozilla.org-with-server-provided-bundles</link>
      <pubDate>Fri, 29 May 2015 11:30:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/05/29/faster-cloning-from-hg.mozilla.org-with-server-provided-bundles</guid>
      <description>Faster Cloning from hg.mozilla.org With Server Provided Bundles</description>
      <content:encoded><![CDATA[<p>When you type <em>hg clone</em>, the Mercurial server will create a <em>bundle</em>
from repository content at the time of the request and stream it to
the client. (Git works essentially the same way.)</p>
<p>This approach usually <em>just works</em>. But there are some downsides,
particularly with large repositories.</p>
<p>Creating bundles for large repositories is not cheap. For
mozilla-central, Firefox's main repository, it takes ~280s of CPU time
on my 2014 MacBook Pro to generate a bundle. Every time a client runs a
<em>hg clone https://hg.mozilla.org/mozilla-central</em>, a server somewhere
is spinning a CPU core generating ~1.1 GB of data. What's more, if
another clone arrives at the same time, another process will perform
the exact same work! When we talk about multiple minutes of CPU time
per request, this extra work starts to add up.</p>
<p>Another problem with large repositories is interrupted downloads. If
you suffer a connectivity blip during your <em>clone</em> command, you'll
have to start from scratch. This potentially means re-transferring
hundreds of megabytes from the server. It also means the server has
to generate a new bundle, consuming even more CPU time. This is not
good for the user or the server.</p>
<p>There have been multiple outages of hg.mozilla.org as a result of
the service being flooded with clone requests to large repositories.
Dozens of clients (most of them in Firefox or Firefox OS
release automation) have cloned the same repository around the same
time and overwhelmed network bandwidth in the data center or CPU
cores on the Mercurial servers.</p>
<p>A common solution to this problem is to not use the <em>clone</em> command
to receive initial repository data from the server. Instead, a
static <em>bundle</em> file will be generated and made available to clients.
Clients will call <em>hg init</em> to create an empty repository then will
perform an <em>hg unbundle</em> to apply the contents of a pre-generated
bundle file. They will then run <em>hg pull</em> to fetch new data that
was created after the bundle was generated. (It's worth noting that
Git's <em>clone --reference</em> option is similar.)</p>
<p>This is a good technical solution. Firefox and Firefox OS release
automation have effectively implemented this. However, it is a lot of
work: you have to build your own bundle generation and hosting
infrastructure and you have to remember that every <em>hg clone</em> should
probably be using bundles instead. It is extra complexity and complexity
that must be undertaken by every client. If a client forgets, the
consequences can be disastrous (clone flooding leading to service
outage). Client-side opt-in is prone to lapses and doesn't scale.</p>
<p><strong>As of today, we've deployed a more scalable, server-based solution to
hg.mozilla.org.</strong></p>
<p>hg.mozilla.org is now itself generating bundles for a handful of
repositories, including mozilla-central, inbound, fx-team, and
mozharness. These bundles are being uploaded to Amazon S3. And
<strong>those bundles are being advertised by the server over Mercurial's
wire protocol</strong>.</p>
<p>When you install the <em>bundleclone</em> Mercurial extension, <em>hg clone</em> is
taught to look for bundles being advertised on the server. If a bundle
is available, the bundle is downloaded, applied, and then the client
does the equivalent of an <em>hg pull</em> to fetch all new data since when the
bundle was generated. If a bundle exists, it is used transparently: no
client side cooperation is needed beyond installing the <em>bundleclone</em>
extension. If a bundle doesn't exist, it simply falls back to
Mercurial's default behavior. <strong>This effectively shifts responsibility
for doing efficient clones from clients to server operators, which
means server operators don't need cooperation from clients to enact
important service changes.</strong> Before, if clients weren't using bundles,
we'd have to wait for clients to update their code. Now, we can see
a repository is being cloned heavily and start generating bundles for
it without having to wait for the client to deploy new code.</p>
<p>Furthermore, we've built primitive <em>content negotiation</em> into the
process. The server doesn't simply advertise one bundle file: it
advertises several bundle files. We offer gzip, bzip2, and <em>stream</em>
bundles. gzip is what Mercurial uses by default. It works OK. bzip2
bundles are smaller, but they take longer to process. <em>stream</em> bundles
are essentially tar archives of the <em>.hg/store</em> directory and are larger
than gzip bundles, but insanely fast because there is very little CPU
required to apply them. In addition, we advertise URLs for multiple S3
regions, currently us-west-2 (Oregon) and us-east-1 (Virigina). This
enables clients to prefer the bundle most appropriate for them.</p>
<p>A benefit of serving bundles from S3 is that Firefox and Firefox OS
release automation (the biggest consumers of hg.mozilla.org) live in
Amazon EC2. They are able to fetch from S3 over a gigabit network.
And, since we're transferring data within the same AWS region, there
are no data transfer costs. Previously, we were transferring ~1.1 GB
from a Mozilla data center to EC2 for each clone. This took up bandwidth
in Mozilla's network and cost Mozilla money to send data thousands of
miles away. And, we never came close to saturating a gigabit network (we
do with stream bundles). Wins everywhere!</p>
<p>The <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/bundleclone.html">full instructions</a>
detail how to use <em>bundleclone</em>. <strong>I recommend everyone at Mozilla
install the extension</strong> because there should be no downside to doing it.</p>
<p>Once <em>bundleclone</em> is deployed to Firefox and Firefox OS release
automation, we should hopefully never again see those machines bring
down hg.mozilla.org due to a flood of clone requests. We should also
see a drastic reduction in load to hg.mozilla.org. I'm optimistic
bandwidth will decrease by over 50%!</p>
<p>It's worth noting that the functionality from the <em>bundleclone</em> extension
is coming to vanilla Mercurial. The functionality (which was initially
added by Mozilla's Mike Hommey) is part of Mercurial's <em>bundle2</em> protocol,
which is available, but isn't enabled by default yet. <em>bundleclone</em> is thus
a temporary solution to bring us server stability and client
improvements until modern Mercurial versions are deployed everywhere
in a few months time.</p>
<p>Finally, I would like to credit Augie Fackler for the
<a href="http://thread.gmane.org/gmane.comp.version-control.mercurial.devel/54872/focus=54872">original idea</a>
for server-assisted bundle-based clones.</p>]]></content:encoded>
    </item>
    <item>
      <title>Firefox Mercurial Repository with CVS History</title>
      <link>http://gregoryszorc.com/blog/2015/05/18/firefox-mercurial-repository-with-cvs-history</link>
      <pubDate>Mon, 18 May 2015 08:40:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/05/18/firefox-mercurial-repository-with-cvs-history</guid>
      <description>Firefox Mercurial Repository with CVS History</description>
      <content:encoded><![CDATA[<p>When Firefox made the switch from CVS to Mercurial in March 2007, the
CVS history wasn't imported into Mercurial. There were good reasons for
this at the time. But it's a decision that continues to have
side-effects. I am surprised how often I hear of engineers wanting to
access blame and commit info from commits now more than 9 years old!</p>
<p>When individuals created a Git mirror of the Firefox repository a few
years ago, they correctly decided that importing CVS history would be
a good idea. They also correctly decided to combine the logically same
but physically separate <em>release</em> and <em>integration</em> repositories into a
unified Git repository. These are things we can't easily do to the
canonical Mercurial repository because it would break SHA-1 hashes,
breaking many systems, and it would require significant changes in
process, among other reasons.</p>
<p>While Firefox developers do have access to a single Firefox repository
with full CVS history (the Git mirror), they still aren't satisfied.</p>
<p>Running <em>git blame</em> (or <em>hg blame</em> for that matter) can be very
expensive. For this reason, the blame interface is disabled on many
web-based source viewers by default. On GitHub, some blame URLs for
the Firefox repository time out and cause GitHub to display an error
message. No matter how hard you try, you can't easily get blame results
(running a local Git HTTP/HTML interface is still difficult compared to
<em>hg serve</em>).</p>
<p>Another reason developers aren't satisfied with the Git mirror is that
Git's querying tools pale in comparison to Mercurial's. I've said it
before and I'll say it again: Mercurial's revision sets and templates
are incredibly useful features that enable advanced repository querying
and reporting. Git's offerings come nowhere close. (I <em>really</em> wish Git
would steal these awesome features from Mercurial.)</p>
<p>Anyway, enough people were complaining about the lack of a Mercurial
Firefox repository with full CVS history that I decided to create one.
If you point your browsers or Mercurial clients to
<a href="https://hg.mozilla.org/users/gszorc_mozilla.com/gecko-full">https://hg.mozilla.org/users/gszorc_mozilla.com/gecko-full</a>,
you'll be able to access it.</p>
<p>The process used for the conversion was the simplest possible: I used
hg-git to convert the Git mirror back to Mercurial.</p>
<p>Unlike the Git mirror, I didn't include all heads in this new
repository. Instead, there is only mozilla-central's head (the current
development tip). If I were doing this properly, I'd include all heads,
like
<a href="https://hg.mozilla.org/users/gszorc_mozilla.com/gecko-aggregate">gecko-aggregate</a>.</p>
<p>I'm well aware there are oddities in the Git mirror and they now
exist in this new repository as well. My goal for this conversion was to
deliver something: it wasn't a goal to deliver the most correct result
possible.</p>
<p>At this time, this repository should be considered an unstable science
experiment. <strong>By no means should you rely on this repository.</strong> But if
you find it useful, I'd appreciate hearing about it. If enough people
ask, we could probably make this more official.</p>]]></content:encoded>
    </item>
    <item>
      <title>Notes from Git Merge 2015</title>
      <link>http://gregoryszorc.com/blog/2015/05/12/notes-from-git-merge-2015</link>
      <pubDate>Tue, 12 May 2015 15:40:00 PDT</pubDate>
      <category><![CDATA[Git]]></category>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/05/12/notes-from-git-merge-2015</guid>
      <description>Notes from Git Merge 2015</description>
      <content:encoded><![CDATA[<p><a href="http://git-merge.com/">Git Merge 2015</a> was a Git user conference held
in Paris on April 8 and 9, 2015.</p>
<p>I'm kind of a version control geek. I'm also responsible for a large
part of Mozilla's version control hosting. So, when the videos were
made public, you can bet I took interest.</p>
<p>This post contains my notes from a few of the Git Merge talks. I try
to separate content/facts from my opinions by isolating my opinions
(within parenthesis).</p>
<h2>Git at Google</h2>
<p><a href="http://git-merge.com/videos/git-at-google-dave-borowitz.html">Git at Google: Making Big Projects (and everyone else) Happy</a>
is from a Googler (Dave Borowitz) who works on JGit for the Git
infrastructure team at Google.</p>
<p>"Everybody in this room is going to feel some kind of pain working with
Git at scale at some time in their career."</p>
<p>First Git usage at Google in 2008 for Android. 2011 googlesource.com
launches.</p>
<p>24,000 total Git repos at Google. 77.1M requests/day. 30-40 TB/day. 2-3
Gbps.</p>
<p>Largest repo is 210GB (not public it appears).</p>
<p>800 repos in AOSP. Google maintains internal fork of all Android repos
(so they can throw stuff over the wall). Fresh AOSP tree is 17 GiB. Lots
of contracts dictating access.</p>
<p>Chrome repos include Chromium, Blink, Chromium OS. Performed giant
Subversion migration. Developers of Chrome very set in their ways. Had
many workflows integrated with Subversion web interface. Subversion
blame was fast, Git blame slow. Built caching backend for Git blame to
make developers happy.</p>
<p>Chromium 2.9 GiB, 3.6M objects, 390k commits. Blink 5.3 GiB, 3.1M
objects, 177k commits. They merged them into a monorepo. Mention of
Facebook's monorepo talk and Mercurial scaling efforts for a repo larger
then Chromium/Blink monorepo. Benefits to developers for doing atomic
refactorings, etc.</p>
<p>"Being big is hard."</p>
<p>AOSP: 1 Gbps -&gt; 2 minutes for 17 GiB. 20 Mbps -&gt; 3 hours. Flaky internet
combined with non-resumable clone results in badness. Delta resolution
can take a while. Checkout of hundreds of thousands of files can be
slow, especially on Windows.</p>
<p>"As tool developers... it's hard to tell people don't check in large
binaries, do things this way, ... when all they are trying to do is
get their job done." (I couldn't agree more: tools should ideally not
impose sub-optimal workflows.)</p>
<p>They prefer scaling pain to supporting multiple tools. (I think this
meant don't use multiple VCSs if you can just make one scale.)</p>
<p>Shallow clone beneficial. But some commands don't work. log not very
useful.</p>
<p>Narrow clones mentioned. Apparently talked about elsewhere at Git Merge
not captured on video. Non-trivial problem for Git. "We have no idea
when this is going to happen."</p>
<p>Split repos until narrow clone is available. Google wrote repo to manage
multiple repos. They view repo and multiple repos as stop-gap until
narrow clone is implemented.</p>
<p>git submodule needs some love. Git commands don't handle submodules
or multiple repos very well. They'd like to see repo features
incorporated into git submodule.</p>
<p>Transition to server operation.</p>
<p>Pre-2.0, counting objects was hard. For Linux kernel, 60s 100% CPU time
per clone to count objects. "Linux isn't even that big."</p>
<p>Traditionally Git is single homed. Load from users. Load from
automation.</p>
<p>Told anecdote about how Google's automation once recloned the repo after
a failed Git command. Accidentally made a change one day that caused a
command to persistently fail. DoS against server. (We've had this at
Mozilla.)</p>
<p>Garbage collection on server is CPU intensive and necessary. Takes cores
away from clients.</p>
<p>Reachability bitmaps implemented in JGit, ported to Git 2.0. Counting
objects for Linux clones went from 60s CPU to ~100ms.</p>
<p>Google puts static, pre-generated bundles on a CDN. Client downloads
bundle then does incremental fetch. Massive reduction in server load.
Bundle files better for users. Resumable.</p>
<p>They have ideas for integrating bundles into git fetch, but it's
"a little way's off." (This feature is partially implemented in
Mercurial 3.4 and we have plans for using it at Mozilla.) It's feature
in repo today.</p>
<p>Shared filesystem would be really nice to spread CPU load. NFS "works."
Performance problems with high throughput repositories.</p>
<p>Master-mirror replication can help. Problems with replication lag.
Consistency is hard.</p>
<p>Google uses a distributed Git store using Bigtable and GFS built on
JGit. Git-aware load balancer. Completely separate pool of garbage
collection workers. They do replication to multiple datacenters before
pushes. 6 datacenters across world. Some of their stuff is open source.
A lot isn't.</p>
<p>Humans have difficulty managing hundreds of repositories. "How do you as
a human know what you need to modify?" Monorepos have this problem too.
Inherent with lots of content. (Seemed to imply it is worse with
multiple repos than with a monorepo.)</p>
<p>Porting changes between forks is hard. e.g. cherry picking between
internal and external Android repos.</p>
<p>ACLs are a mess.</p>
<p>Google built Gerrit code review. It does ACLs, auto rebasing, release
branch management. It's a swiss army knife. (This aligns with my
vision for MozReview and code-centric development.)</p>
<h2>Scaling Git at Twitter</h2>
<p>Wilhelm Bierbaum from Twitter talks about
<a href="http://git-merge.com/videos/scaling-git-at-twitter-wilhelm-bierbaum.html">Scaling Git at Twitter</a>.</p>
<p>"We've decided it's really important to make Twitter a good place to work for
developers. Source control is one of those points where we were
lacking. We had some performance problems with Git in the past."</p>
<p>Twitter runs a monorepo. Used to be 3 repos. "Working with a single
repository is the way they prefer to develop software when developing
hundreds of services." They also have a single build system. They have
a geo diverse workforce.</p>
<p>They use normal canonical implementation of Git + some optimizations.</p>
<p>Benefits of a monorepo:</p>
<p>Visibility. Easier for people to find code in one repo. Code search tools
tailored towards single repos.</p>
<p>Single toolchain. single set of tools to build, test, and deploy. When
improvements to tools made, everyone benefits because one toolchain.</p>
<p>Easy to share code (particularly generated code like IDL). When operating
many small services, services developed together. Code duplication is
minimized. Twitter relies on IDL heavily.</p>
<p>Simpler to predict the impact of your changes. Easier to look at single
code base then to understand how multiple code bases interact. Easy to
make a change and see what breaks rather than submit changes to N repos
and do testing in N repos.</p>
<p>Makes refactoring less arduous.</p>
<p>Surfaces architecture issues earlier.</p>
<p>Breaking changes easier to coordinate</p>
<p>Drawbacks of monorepos:</p>
<p>Large disk footprint for full history.</p>
<p>Tuning filesystem only goes so far.</p>
<p>Forces some organizations to adopt sparse checkouts and shallow clones.</p>
<p>Submodules aren't good enough to use. <em>add</em> and <em>commit</em> don't recognize
submodule boundaries very well and aren't very usable.</p>
<p>"To us, using a tool such as repo that is in effect a secondary version
control tool on top of Git does not feel right and doesn't lead to a
fluid experience."</p>
<p>Twitter has centralized use of Git. Don't really benefit from
distributed version control system. Feature branches. Goal is to live as
close to master as possible. Long-running branches discouraged. Fewer
conflicts to resolve.</p>
<p>They have project-level ownership system. But any developer can change
anything.</p>
<p>They have lots of read-only replicas. Highly available writable server.</p>
<p>They use reference repos heavily so object exchange overhead is
manageable.</p>
<p>Scaling issues with many refs. Partially due to how refs are stored on
disk. File locking limits in OS. Commands like status, add, and commit
can be slow, even with repo garbage collected and packed. Locking issues
with garbage collection.</p>
<p>Incorporated file alteration monitor to make status faster. Reference to
Facebook's work on watchman and its Mercurial integration. Significant
impact on OS X. "Pretty much all our developers use OS X." (I assume
they are using Watchman with Git - I've seen patches for this on the Git
mailing list but they haven't been merged into core yet.)</p>
<p>They implemented a custom index format. Adopted faster hashing
algorithm that uses native instructions.</p>
<p>Discovery with many refs didn't scale. 13 MB of raw data for refs
exchange at Twitter. (!!) Experimenting with clients sending a bloom
filter of refs. Hacked it together via HTTP header.</p>
<p>Fetch protocol is expensive. Lots of random I/O. Can take minutes
to do incremental fetches. Bitmap indices help, but aren't good enough
for them. Since they have central and well-defined environment, they
changed fetch protocol to work like a journal: send all changed data since
client's last fetch. Server work is essentially a sendfile system call.
git push appends push packs to a log-structured journal. On fetch,
clients "replay" the transactions from the journal. Similar to MySQL
binary log replication. (This is very similar to some of the Mercurial
replication work I'm doing at Mozilla. Yay technical validation.)
(Append only files are also how Mercurial's storage model works by
default.)</p>
<p>Log-structured data exchange means server side is cheap. They can insert
HTTP caches to handle Range header aware requests.</p>
<p>Without this hack, they can't scale their servers.</p>
<p>Initial clone is seeded by BitTorrent.</p>
<p>It sounds like everyone's unmerged feature branches are on the one
central repo and get transferred everywhere by default. Their journal
fetch can selectively fetch refs so this isn't a huge problem.</p>
<p>They'd like to experiment with sparse repos. But they haven't gotten to
that yet. They'd like a better storage abstraction in Git to enable
necessary future scalability. They want a network-aware storage backend.
Local objects not necessary if the network has them.</p>
<p>They are running a custom Git distribution/fork on clients. But they
don't want to maintain forever. Prefer to send upstream.</p>]]></content:encoded>
    </item>
    <item>
      <title>Dropping Explicit Support for Mercurial 3.0</title>
      <link>http://gregoryszorc.com/blog/2015/05/07/dropping-explicit-support-for-mercurial-3.0</link>
      <pubDate>Thu, 07 May 2015 16:05:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/05/07/dropping-explicit-support-for-mercurial-3.0</guid>
      <description>Dropping Explicit Support for Mercurial 3.0</description>
      <content:encoded><![CDATA[<p>As of a few minutes ago, we explicitly dropped support for Mercurial 3.0
for all the Mercurial code in the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools">version-control-tools</a>
repository. File issues in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1162304">bug 1162304</a>.</p>
<p>Code may still work against Mercurial 3.0. But it isn't supported and
could break hard at any time.</p>
<p>Supporting multiple versions of <em>any</em> software carries
with it some cost. The people writing tooling around Mercurial are busy.
It is a waste of our time to bend over backwards to support old versions
of software that <strong>all</strong> users should have upgraded from months ago.
Still using older Mercurial versions means you aren't getting the best
performance and may encounter bugs that have since been fixed.</p>
<p>See the <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/installing.html">Mozilla tailored Mercurial installation instructions</a>
for info on how to upgrade to the latest/greatest Mercurial version.</p>]]></content:encoded>
    </item>
    <item>
      <title>Reporting Mercurial Issues</title>
      <link>http://gregoryszorc.com/blog/2015/05/04/reporting-mercurial-issues</link>
      <pubDate>Mon, 04 May 2015 13:45:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/05/04/reporting-mercurial-issues</guid>
      <description>Reporting Mercurial Issues</description>
      <content:encoded><![CDATA[<p>I semi-frequently stumble upon conversations in hallways and
on irc.mozilla.org about issues people are having with Mercurial.
These conversations periodically involve a legitimate bug with
Mercurial. Unfortunately, these conversations frequently end
without an actionable result. Unless someone files a bug, pings me,
etc, the complaints disappear into ether. That's not good for
anyone and only results in bugs living longer than they should.</p>
<p>There are posters around Mozilla offices that say
<em>if you see something, file something.</em> This advice does not just
apply to Mozilla projects!</p>
<p><strong>If you encounter an issue in Mercurial, please take the time
to report it somewhere meaningful.</strong> The
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/issues.html">Reporting Issues with Mercurial</a>
page from the
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/index.html">Mercurial for Mozillians</a>
guide tells you how to do this.</p>
<p>It is OK to complain about something. But if you don't inform
someone empowered to do something about it, you are part of the
problem without being part of the solution. Please make the
incremental effort to be part of the solution.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mercurial 3.4 Released</title>
      <link>http://gregoryszorc.com/blog/2015/05/04/mercurial-3.4-released</link>
      <pubDate>Mon, 04 May 2015 12:40:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/05/04/mercurial-3.4-released</guid>
      <description>Mercurial 3.4 Released</description>
      <content:encoded><![CDATA[<p>Mercurial 3.4 was released on May 1 (following Mercurial's time-based
schedule of releasing a new version every 3 months).</p>
<p>3.4 is a significant release for a few reasons.</p>
<p>First, the next version of the wire protocol (<em>bundle2</em>) has been
marked as non-experimental on servers. This version of the protocol
paves over a number of deficiencies in the classic protocol. I won't
go into low-level details. But I will say that the protocol enables
some rich end-user experiences, such as having the server hand out URLs
for pre-generated bundles (e.g. offload clones to S3), atomic push
operations, and advanced workflows, such as having the server rebase
automatically on push. Of course, you'll need a server running 3.4
to realize the benefits of the new protocol. hg.mozilla.org won't be
updated until at least June 1.</p>
<p>Second, Mercurial 3.4 contains improvements to the tags cache to make
performance concerns a thing of the past. Due to the structure of the
Firefox repositories, the previous implementation of the tags cache
could result in pauses of dozens of seconds during certain workflows.
The problem should go away with Mercurial 3.4. <strong>Please note that on
first use of Mercurial 3.4, your repository may perform a one-time
upgrade of the tags cache. This will spin a full CPU core and will
take up to a few minutes to complete on Firefox repos. Let it run to
completion and performance should not be an issue again.</strong> I wrote the
patches to change the tags cache (with lots of help from Pierre-Yves
David, a Mercurial core contributor). So if you find anything wrong,
I'm the one to complain to.</p>
<p>Third, the HTTP interface to Mercurial (hgweb) now has JSON output
for nearly every endpoint. The implementation isn't yet complete,
but it is better than nothing. But, it should be good enough for
services to start consuming it. Again, this won't be available on
hg.mozilla.org until the server is upgraded on June 1 at the earliest.
This is a feature I added to core Mercurial. If you have feature
requests, send them my way.</p>
<p>Fourth, a number of performance regressions introduced in Mercurial
3.3 were addressed. These performance issues frequently manifested
during <em>hg blame</em> operations. Many Mozillians noticed them on
hg.mozilla.org when looking at blame through the web interface.</p>
<p>For a more comprehensive list of changes, see
<a href="https://groups.google.com/d/msg/mozilla.dev.version-control/z4aWvBoAGYw/d0hUGKJU_psJ">my post about the 3.4 RC</a>
and the
<a href="http://mercurial.selenic.com/wiki/WhatsNew#Mercurial_3.4_.282015-05-01.29">official release notes</a>.</p>
<p>3.4 was a significant release. There are compelling reasons to upgrade.
That being said, there were a lot of changes in 3.4. If you want to wait
until 3.4.1 is released (scheduled for June 1) so you don't run into
any regressions, nobody can fault you for that.</p>
<p>If you want to upgrade, I recommend reading the
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/installing.html">Mercurial for Mozillians Installation Page</a>.</p>]]></content:encoded>
    </item>
    <item>
      <title>Automatically Redirecting Mercurial Pushes</title>
      <link>http://gregoryszorc.com/blog/2015/04/30/automatically-redirecting-mercurial-pushes</link>
      <pubDate>Thu, 30 Apr 2015 12:30:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/04/30/automatically-redirecting-mercurial-pushes</guid>
      <description>Automatically Redirecting Mercurial Pushes</description>
      <content:encoded><![CDATA[<p>Managing URLs in distributed version control tools can be a pain,
especially if multiple repositories are involved. For example,
with Mozilla's repository-based code review workflow (you push to a
special review repository to initiate code review - this is conceptually
similar to GitHub pull requests), there exist
<a href="https://reviewboard-hg.mozilla.org/">separate code review repositories</a>
for each logical repository. Figuring out how repositories map to each
other and setting up remote paths for each new clone can be a pain and
time sink.</p>
<p>As of today, we can now do something better.</p>
<p>If you push to <em>ssh://reviewboard-hg.mozilla.org/autoreview</em>,
Mercurial will automatically figure out the appropriate review
repository and redirect your push automatically. In other words, if we
have <a href="https://reviewboard.mozilla.org/">MozReview</a> set up to review
whatever repository you are working on,
your push and review request will automatically go through. No need to
figure out what the appropriate review repo is or configure
repository URLs!</p>
<p>Here's what it looks like:</p>
<div class="pygments_murphy"><pre>$ hg push review
pushing to ssh://reviewboard-hg.mozilla.org/autoreview
searching for appropriate review repository
redirecting push to ssh://reviewboard-hg.mozilla.org/version-control-tools/
searching for changes
remote: adding changesets
remote: adding manifests
remote: adding file changes
remote: added 1 changesets with 1 changes to 1 files
remote: Trying to insert into pushlog.
remote: Inserted into the pushlog db successfully.
submitting 1 changesets for review

changeset:  11043:b65b087a81be
summary:    mozreview: create per-commit identifiers (bug 1160266)
review:     https://reviewboard.mozilla.org/r/7953 (draft)

review id:  bz://1160266/gps
review url: https://reviewboard.mozilla.org/r/7951 (draft)
(visit review url to publish this review request so others can see it)
</pre></div>

<p>Read the <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/mozreview/install.html#review-repositories">full instructions</a>
for more details.</p>
<p>This requires an updated <a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
repository, which you can get by running <em>mach mercurial-setup</em> from a
Firefox repository.</p>
<p>For those that are curious, the <em>autoreview</em> repo/server advertises a list
of repository URLs and their root commit SHA-1. The client automatically
sends the push to a URL sharing the same root commit. The
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/rev/0b02cd388590">code</a>
is quite simple.</p>
<p>While this is only implemented for MozReview, I could envision us doing
something similar for other centralized repository-centric services, such
as <em>Try</em> and <em>Autoland</em>. Stay tuned.</p>]]></content:encoded>
    </item>
    <item>
      <title>New High Scores for hg.mozilla.org</title>
      <link>http://gregoryszorc.com/blog/2015/03/19/new-high-scores-for-hg.mozilla.org</link>
      <pubDate>Thu, 19 Mar 2015 20:20:00 PDT</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/03/19/new-high-scores-for-hg.mozilla.org</guid>
      <description>New High Scores for hg.mozilla.org</description>
      <content:encoded><![CDATA[<p>It's been a <a href="/blog/2015/03/18/network-events/">rough week</a>.</p>
<p>The very short summary of events this week is that both the Firefox
and Firefox OS release automation has been performing a denial of
service attack against
<a href="https://hg.mozilla.org/">hg.mozilla.org</a>.</p>
<p>On the face of it, this is nothing new. The release automation
is by far the top consumer of hg.mozilla.org data, requesting several
terabytes per day via several million HTTP requests from thousands of
machines in multiple data centers. The very nature of their existence
makes them a significant denial of service threat.</p>
<p>Lots of things went wrong this week. While a post mortem will shed
light on them, many fall under the umbrella of <em>release automation was
making more requests than it should have and was doing so in a way
that both increased the chances of an outage occurring and increased
the chances of a prolonged outage.</em> This resulted in the hg.mozilla.org
servers working harder than they ever have. As a result, we have some
new <em>high scores</em> to share.</p>
<ul>
<li>
<p>On UTC day March 19, hg.mozilla.org transferred 7.4 TB of data.
  This is a significant increase from the ~4 TB we expect on a typical
  weekday. (Even more significant when you consider that most load is
  generated during peak hours.)</p>
</li>
<li>
<p>During the 1300 UTC hour of March 17, the cluster received 1,363,628
  HTTP requests. No HTTP 503 Service Not Available errors were
  encountered in that window! 300,000 to 400,000 requests per hour is
  typical.</p>
</li>
<li>
<p>During the 0800 UTC hour of March 19, the cluster transferred 776 GB
  of repository data. That comes out to at least 1.725 Gbps on average
  (I didn't calculate TCP and other overhead). Anything greater than 250
  GB per hour is not very common. No HTTP 503 errors were served from
  the origin servers during this hour!</p>
</li>
</ul>
<p>We encountered many periods where hg.mozilla.org was operating more than
twice its normal and expected operating capacity and it was able to
handle the load just fine. As a server operator, I'm proud of this.
The servers were provisioned beyond what is normally needed of them and
it took a truly exceptional event (or two) to bring the service down.
This is generally a good way to do hosted services (you rarely want to be
barely provisioned because you fall over at the slighest change and you
don't want to be grossly over-provisioned because you are wasting money
on idle resources).</p>
<p>Unfortunately, the hg.mozilla.org service did fall over. Multiple times,
in fact. There is room to improve. As proud as I am that the service
operated well beyond its expected limits, I can't help but feel ashamed
that it did eventual cave in under even extreme load and that people are
probably making under-informed general assumptions like <em>Mercurial can't
scale</em>. The simple fact of the matter is that clients cumulatively
generated an exceptional amount of traffic to hg.mozilla.org this week.
All servers have capacity limits. And this week we encountered the limit
for the current configuration of hg.mozilla.org. Cause and effect.</p>]]></content:encoded>
    </item>
    <item>
      <title>Branch Cleanup in Firefox Repositories</title>
      <link>http://gregoryszorc.com/blog/2015/01/28/branch-cleanup-in-firefox-repositories</link>
      <pubDate>Wed, 28 Jan 2015 20:35:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/28/branch-cleanup-in-firefox-repositories</guid>
      <description>Branch Cleanup in Firefox Repositories</description>
      <content:encoded><![CDATA[<p>Mozilla has historically done some funky things with the Firefox
Mercurial repositories. One of the things we've done is create
a bunch of named branches to track the Firefox release process.
These are branch names like <em>GECKO20b12_2011022218_RELBRANCH</em>.</p>
<p>Over in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=927219">bug 927219</a>,
we started the process of cleaning up some cruft left over from
many of these old branches.</p>
<p>For starters, the old named branches in the Firefox repositories
are being actively closed. When you <em>hg commit --close-branch</em>,
Mercurial creates a special commit that says <em>this branch is closed</em>.
Branches that are closed are automatically hidden from the output
of <em>hg branches</em> and <em>hg heads</em>. As a result, the output of these
commands is now much more usable.</p>
<p>Closed branches still constitute <em>heads</em> on the DAG. And several heads
lead to degraded performance in some situations (notably push and pull
times - the same thing happens in Git). I'd like to eventually merge
these old heads so that repositories only have 1 or a small number of
DAG heads. However, extra care must be taken before that step. Stay
tuned.</p>
<p>Anyway, for the average person reading, you probably won't be impacted
by these changes at all. The greatest impact will be from the person who
lands the first change on top of any repository whose last commit
was a branch close. If you commit on top of the <em>tip</em> commit,
you'll be committing on top of a previously closed branch! You'll
instead want to <em>hg up default</em> after you pull to ensure you are on
the proper DAG head! And even then, if you have local commits, you may
not be based on top of the appropriate commit! A simple run of
<em>hg log --graph</em> should help you decipther the state of the world.
(Please note that the usability problems around discovering the
appropriate head to land on are a result of our poor branching strategy
for the Firefox repositories. We probably should have named branches
tracking the active Gecko releases. But that ship sailed years ago
and fixing that is pretty far down the priority list. Wallpapering
over things with the
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/firefoxtree.html">firefoxtree extensions</a>
is my recommended solution until matters are fixed.)</p>]]></content:encoded>
    </item>
    <item>
      <title>Modern Mercurial Documentation for Mozillians</title>
      <link>http://gregoryszorc.com/blog/2015/01/15/modern-mercurial-documentation-for-mozillians</link>
      <pubDate>Thu, 15 Jan 2015 14:45:00 PST</pubDate>
      <category><![CDATA[Mercurial]]></category>
      <category><![CDATA[Mozilla]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2015/01/15/modern-mercurial-documentation-for-mozillians</guid>
      <description>Modern Mercurial Documentation for Mozillians</description>
      <content:encoded><![CDATA[<p>Mozilla's Mercurial documentation has historically been pretty bad. The
documentation on MDN (which I refuse to link to) is horribly disjointed
and contains a lot of outdated recommendations. I've made attempts to
burn some of it to the ground, but it is just too overwhelming.</p>
<p>I've been casually creating my own Mercurial documentation tailored for
Mozillians. It's called
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/index.html">Mercurial for Mozillians</a>.</p>
<p>It started as a way to document extensions inside the
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/">version-control-tools</a>
repository. But, it has since evolved to cover other topics, like how to
install Mercurial, how to develop using bookmarks, and how to interact
with a unified Firefox repository. The documentation is nowhere near
complete. But it already has some very useful content beyond what MDN
offers.</p>
<p>I'm not crazy about the idea of having generic Mercurial documentation
on a Mozilla domain (this should be part of the official Mercurial
documentation). Nor am I crazy about moving content off MDN. I'm sure
content will move to its appropriate location later. Until then,
enjoy some curated Mercurial documentation!</p>
<p>If you would like to contribute to Mercurial for Mozillians,
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/contributing.html">read the docs</a>.</p>]]></content:encoded>
    </item>
  </channel>
</rss>
