<?xml version="1.0" encoding="UTF-8"?>
<feed
  xmlns="http://www.w3.org/2005/Atom"
  xmlns:thr="http://purl.org/syndication/thread/1.0"
  xml:lang="en"
   >
  <title type="text">Gregory Szorc's Digital Home</title>
  <subtitle type="text">Rambling on</subtitle>

  <updated>2015-09-01T22:01:50Z</updated>
  <generator uri="http://blogofile.com/">Blogofile</generator>

  <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog" />
  <id>http://gregoryszorc.com/blog/feed/atom/</id>
  <link rel="self" type="application/atom+xml" href="http://gregoryszorc.com/blog/feed/atom/" />
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Serving Mercurial Clones from a CDN]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/09/01/serving-mercurial-clones-from-a-cdn" />
    <id>http://gregoryszorc.com/blog/2015/09/01/serving-mercurial-clones-from-a-cdn</id>
    <updated>2015-09-01T15:00:00Z</updated>
    <published>2015-09-01T15:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Serving Mercurial Clones from a CDN]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/09/01/serving-mercurial-clones-from-a-cdn"><![CDATA[<p>For the past few months, Mozilla has been
<a href="http://gregoryszorc.com/blog/2015/07/08/cloning-from-s3/">serving Mercurial clones from Amazon S3</a>.
We upload snapshots (called <em>bundles</em>) of large and/or high-traffic
repositories to S3. We have a custom Mercurial extension on the
client and server that knows how to exchange the URLs for these
snapshots and to transparently use them to bootstrap a clone. The
end result is drastically reduced Mercurial server load and faster
clone times. The benefits are seriously ridiculous when you operate
version control at scale.</p>
<p><a href="https://aws.amazon.com/cloudfront/">Amazon CloudFront</a> is a CDN.
You can easily configure it up to be backed by an S3 bucket. So
we did.</p>
<p><a href="https://hg.cdn.mozilla.net/">https://hg.cdn.mozilla.net/</a> is
Mozilla's CDN for hosting Mercurial data. Currently it's just bundles to
be used for cloning.</p>
<p>As of today, if you
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/bundleclone.html">install the bundleclone Mercurial extension</a>
and <em>hg clone</em> a repository on
<a href="https://hg.mozilla.org/">hg.mozilla.org</a> such as
<a href="https://hg.mozilla.org/mozilla-central">mozilla-central</a>
(<em>hg clone https://hg.mozilla.org/mozilla-central</em>), the CDN
URLs will be preferred by default. (Previously we preferred S3 URLs
that hit servers in Oregon, USA.)</p>
<p><strong>This should result in clone time reductions for Mozillians not
close to Oregon, USA</strong>, as the CloudFront CDN has servers all across
the globe and your Mercurial clone should be bootstrapped from the
closest and hopefully therefore fastest server to you.</p>
<p>Unfortunately, you do need the the aforementioned <em>bundleclone</em>
extension installed for this to work. But, this should only be
temporary: I've
<a href="https://mercurial.selenic.com/wiki/StaticBundlePlan">proposed</a>
integrating this feature into the core of Mercurial so if a client
talks to a server advertising pre-generated bundles the clone
offload <em>just works</em>. I already have tentative buy-in from one
Mercurial maintainer. So hopefully I can land this feature in
Mercurial 3.6, which will be released November 1. After that,
I imagine some high-traffic Mercurial servers (such as Bitbucket)
will be very keen to deploy this so CPU load on their servers
is drastically reduced.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[JSON APIs on hg.mozilla.org]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/08/18/json-apis-on-hg.mozilla.org" />
    <id>http://gregoryszorc.com/blog/2015/08/18/json-apis-on-hg.mozilla.org</id>
    <updated>2015-08-18T16:00:00Z</updated>
    <published>2015-08-18T16:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[JSON APIs on hg.mozilla.org]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/08/18/json-apis-on-hg.mozilla.org"><![CDATA[<p>I added a feature to Mercurial 3.4 that exposes JSON from Mercurial's
various <a href="https://hg.mozilla.org/mozilla-central/help/hgweb">web APIs</a>.
Unfortunately, due to the presence of legacy code on hg.mozilla.org
providing similar functionality, we weren't able to deploy this
feature to hg.mozilla.org when we deployed Mercurial 3.4 several weeks
ago.</p>
<p>I'm pleased to announce that as of today, JSON is now exposed from
hg.mozilla.org!</p>
<p>To access JSON output, simply add <strong>json-</strong> to the <em>command</em> name
in URLs. e.g. instead of
<a href="https://hg.mozilla.org/mozilla-central/rev/de7aa6b08234">https://hg.mozilla.org/mozilla-central/rev/de7aa6b08234</a>
use <a href="https://hg.mozilla.org/mozilla-central/json-rev/de7aa6b08234">https://hg.mozilla.org/mozilla-central/json-rev/de7aa6b08234</a>.
The full list of web commands, URL patterns, and their parameters are
<a href="https://hg.mozilla.org/mozilla-central/help/hgweb">documented</a> in
the <em>hgweb</em> help topic.</p>
<p>Not all web commands support JSON output yet. Not all web commands
expose all data available to them. If there is data you need but isn't
exposed, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Developer%20Services&amp;component=Mercurial%3A%20hg.mozilla.org">file a bug</a>
and I'll see what I can do.</p>
<p>Thanks go to Steven MacLeod for
<a href="https://reviewboard.mozilla.org/r/15617/">reviewing</a> the rather large
series it took to make this happen.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[moz.build metadata on hg.mozilla.org]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/08/04/moz.build-metadata-on-hg.mozilla.org" />
    <id>http://gregoryszorc.com/blog/2015/08/04/moz.build-metadata-on-hg.mozilla.org</id>
    <updated>2015-08-04T19:55:00Z</updated>
    <published>2015-08-04T19:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[moz.build metadata on hg.mozilla.org]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/08/04/moz.build-metadata-on-hg.mozilla.org"><![CDATA[<p>Sometime last week we enabled a new API on hg.mozilla.org:
<em>json-mozbuildinfo</em>. This endpoint will return JSON describing
moz.build-derived metadata about the files that changed in a commit.</p>
<p><a href="https://hg.mozilla.org/mozilla-central/json-mozbuildinfo/1164ec236273">Example</a>.
<a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/mozbuildinfo.html">Docs</a>.</p>
<p>We plan to eventually leverage this API to do cool things like
have MozReview automatically file bugs in the appropriate component and
assign appropriate reviewers given the set of changed files in a commit.</p>
<p>The API is currently only available on mozilla-central. And, we have
very conservative resource limits in place. So large commits may cause
it to error out. As such, the API is considered experimental. Also,
performance is not as optimal as it could be. You have to start
somewhere.</p>
<p>I'd like to thank Guillaume Destuynder (kang) for his help with the
security side of things. When I started on this project, I didn't think
I'd be writing
<a href="https://hg.mozilla.org/hgcustom/version-control-tools/file/02e353037996/testing/docker/builder-hgweb-chroot/mozbuild-eval.c">C code for spawning secure processes</a>,
but here we are. In the not so distant future, I'll likely be adding
<a href="http://man7.org/linux/man-pages/man2/seccomp.2.html">seccomp(2)</a>
into the mix, which will make the execution environment as
or more secure than the Firefox content process sandbox, depending
on how it is implemented. The rabbit holes we find ourselves in to
implement proper security...</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[hg.mozilla.org Operational Workings Now Open Sourced]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/08/04/hg.mozilla.org-operational-workings-now-open-sourced" />
    <id>http://gregoryszorc.com/blog/2015/08/04/hg.mozilla.org-operational-workings-now-open-sourced</id>
    <updated>2015-08-04T14:30:00Z</updated>
    <published>2015-08-04T14:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[hg.mozilla.org Operational Workings Now Open Sourced]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/08/04/hg.mozilla.org-operational-workings-now-open-sourced"><![CDATA[<p>Just a few minutes ago, hg.mozilla.org reached an important milestone:
deployments are now performed via Ansible from our open source
<a href="https://hg.mozilla.org/hgcustom/version-control-tools">version-control-tools</a>
repository instead of via Puppet from Mozilla's private <em>sysadmins</em>
repository. This is important for a few reasons.</p>
<p>First, the code behind the operation of hg.mozilla.org is now open source
and available for the public to see and change. I strive for my work at
Mozilla to be open by default. With hg.mozilla.org's private Puppet
repository, people weren't able to see what was going on under the
covers. Nor were they empowered to change anything. This may come as a
shock, but even I don't have commit privileges to the internal Puppet
repository that was previously powering hg.mozilla.org! I did have read
access. But any change I wanted to make involved me proxying it through
one of two people. It was tedious, made me feel uncomfortable for having to
nag people to do my work, and slowed everyone down. We no longer have this
problem, thankfully.</p>
<p>Second, having the Ansible code in version-control-tools enables us to
use the same operational configuration in production as we do in our
Docker test environment. I can now spin up a cluster of Docker
containers that behave very similarly to the production servers (which
aren't running Docker). This enables us to write end-to-end tests of
complex systems running across multiple Docker containers and have
relatively high confidence that our production and testing environments
behave very similarly. In other words, I can test complex interactions
between multiple systems all from my local machine - even from a plane!
For example, we can and do test that SSH connections to a simulated
production environment running in Docker behave as expected, complete
with an OpenSSH server speaking to an OpenLDAP server for SSH public
key lookup. While we still have many tests to write, we had no such
tests a year ago and every production deployment was a
cross-your-fingers type moment. Having comprehensive tests gives us
confidence to move fast and not break things.</p>
<p>One year ago, hg.mozilla.org's infrastructure was opaque, didn't have
automated tests, and was deployed too seldomly. There was the often
correct perception that changing this critical-to-Mozilla service was
difficult and slow. Today, things couldn't be more different. <strong>The
hg.mozilla.org infrastructure is open, we have tests, and we can and
do deploy multiple times per day without forward notice and without
breaking things.</strong> I love this brave new world of open infrastructure
and moving fast.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Mercurial 3.5 Released]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/31/mercurial-3.5-released" />
    <id>http://gregoryszorc.com/blog/2015/07/31/mercurial-3.5-released</id>
    <updated>2015-07-31T13:15:00Z</updated>
    <published>2015-07-31T13:15:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Mercurial 3.5 Released]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/31/mercurial-3.5-released"><![CDATA[<p>Mercurial 3.5 was released today (following Mercurial's time-based
schedule of releasing a new version every 3 months).</p>
<p>There were roughly 1000 commits between 3.4 and 3.5, making this a
busy version. Although, 1000 commits per release has become the new
norm, as development on Mercurial has accelerated in the past few
years.</p>
<p>In my mind, the major highlight of Mercurial 3.5 is that the new
<em>bundle2</em> wire protocol for transferring data during <em>hg push</em>
and <em>hg pull</em> is now enabled by default on the client. Previously,
it was enabled by default only on the server.
<a href="https://hg.mozilla.org/">hg.mozilla.org</a> is running Mercurial 3.4,
so clients that upgrade to 3.5 today will be speaking to it using
the new wire protocol.</p>
<p>The <em>bundle2</em> wire protocol succeeds the existing protocol
(which has been in place for years) and corrects many of its
deficiencies. Before bundle2, pull and push operations were not
atomic because Mercurial was performing a separate API call for
each piece of data. It would start by transferring changeset data
and then have subsequent transfers of metadata like bookmarks
and phases. As you can imagine, there were race conditions and
scenarios where pushes could be incomplete (not atomic). bundle2
transfers all this data in one large chunk, so there are much
stronger guarantees for data consistency and for atomic operations.</p>
<p>Another benefit of bundle2 is it is a fully extensible data exchange
format. Peers can add additional <em>parts</em> to the payload. For
extensions that wish to transfer additional metadata (like
Mozilla's <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/pushlog.html">pushlog</a>
data), they can simply add this directly into the data
stream without requiring additional requests over the wire protocol.
This translates to fewer network round trips and faster push and pull
operations.</p>
<p>The <em>progress</em> extension has been merged into Mercurial's core and
is enabled by default. It is now safe to remove the
<em>extensions.progress</em> config option from your hgrc.</p>
<p>Mercurial 3.5 also (finally) drops support for Python 2.4 and 2.5.
Hopefully nobody reading this is still running these ancient and
unsupported versions of Python. This is a win for Mercurial developers,
as we were constantly having to work around deficiencies with these old
Python releases. There were dozens of commits removing hacks and
workarounds for Python 2.4 and 2.5. Dropping 2.4 and 2.5 also
means Python 3 porting can begin in earnest. However, this isn't a high
priority for anyone, so don't hold your breath.</p>
<p>There were a number of performance improvements in 3.5:</p>
<ul>
<li>operations involving obsolescence markers are faster (for users of
  changeset evolution)</li>
<li>various revsets were optimized</li>
<li>parts of phases calculation are now performed in C. The <em>not public()</em>
  revset should be much faster.</li>
<li><em>hg status</em> and things walking the filesystem are faster (Mozillians
  should be using <em>hgwatchman</em> to make <em>hg status</em> insanely fast)</li>
</ul>
<p>A <em>ui.allowemptycommit</em> config option was introduced to control whether
empty commits are allowed. Mozillians manually creating <em>trychooser</em>
commits may run into problems creating empty commits without this
option (a better solution is to use <em>mach push-to-try</em>).</p>
<p>Work is progressing on per-directory manifests. Currently, Mercurial
stores the mapping of files to content in a giant list called the
manifest. For repositories with tens or hundreds of thousands of
files, decoding and reading large manifests is very CPU intensive.
Work is being done to enable Mercurial to split manifests by directory.
So instead of a single manifest, there are several. This is a prequisite
to <em>narrow clone</em>, which is the ability to clone history for a subset
of files (like how Subversion works). This work will eventually enable
repositories with millions of files to exist without significant
performance loss. It will also allow
<a href="/blog/2014/09/09/on-monolithic-repositories/">monolithic repositories</a>
to exist without the common critique that they are too unwieldy to
use because they are so large.</p>
<p><em>hgignore</em> files now have an <em>include:</em> and <em>subinclude:</em> syntax that
can be used to include other files containing ignore rules. This
feature is useful for a number of reasons. First, it makes sense for
ignore rules to live in the directory hierarchy next to paths they
impact. Second, for people working with monolithic repositories, it
means you can <em>export</em> a sub-directory of your monorepo (to e.g. a
Git repository) and its ignore rules - being defined in local
directories - can still work. (I'm pretty sure Facebook is using this
approach to make its syncing of directories/projects from its Mercurial
monorepo to GitHub easier to manage.)</p>
<p>Significant work has been done on the template parser. If you have
written custom templates, you may find that Mercurial 3.5 is more
strict about parsing certain syntax.</p>
<p>Revsets with chained <em>or</em> no longer result in stack exhaustion. Before,
programmatically generated revsets like <em>1 or 2 or 3 or 4 or 5 or 6...</em>
would likely fail.</p>
<p>Interactions with servers over SSH should now display server output in
real time. Before, server output was buffered and only displayed at the
end of the operation. (You may not see this on hg.mozilla.org until
the server is upgraded to 3.5, which is planned for early September.)</p>
<p>There are now static analysis checks in place to ensure that Mercurial
config options have corresponding documentation in <em>hg help config</em>.
As a result, a lot of formerly undocumented options are now documented.</p>
<p>I contributed
<a href="/blog/2015/07/31/my-contributions-to-mercurial-3.5/">various improvements</a>.
These include:</p>
<ul>
<li>auto sharing repository data during clone</li>
<li>clone and pull performance improvements</li>
<li><em>hg help scripting</em></li>
</ul>
<p>There were tons of other changes, of course. See the
<a href="https://mercurial.selenic.com/wiki/WhatsNew#Mercurial_3.5_.282015-07-31.29">official release notes</a>
and the
<a href="https://mercurial.selenic.com/wiki/UpgradeNotes#A3.5:_no_more_support_for_Python_2.4_or_2.5">upgrade notes</a>
for more.</p>
<p>The <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmozilla/installing.html">Mercurial for Mozillians Installing Mercurial</a>
article provides a Mozilla tailored yet generally applicable guide for
installing or upgrading Mercurial to 3.5. As always, conservative
software users may want to wait until September 1 for the 3.5.1 point
release to fix any issues or regressions from 3.5.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[My Contributions to Mercurial 3.5]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/31/my-contributions-to-mercurial-3.5" />
    <id>http://gregoryszorc.com/blog/2015/07/31/my-contributions-to-mercurial-3.5</id>
    <updated>2015-07-31T10:55:00Z</updated>
    <published>2015-07-31T10:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[My Contributions to Mercurial 3.5]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/31/my-contributions-to-mercurial-3.5"><![CDATA[<p>Mercurial 3.5 was released today. I contributed some small
improvements to this version that I thought I'd share with the world.</p>
<p>The feature I'm most proud of adding to Mercurial 3.5 is what I'm
referring to as <em>auto share</em>. The existing <em>hg share</em> extension/command
enables multiple checkouts of a repository to share the same backing
repository store. Essentially the <em>.hg/store</em> directory is a symlink
to shared directory. This feature has existed in Mercurial for years
and is essentially identical to the <em>git worktree</em> feature just
recently added in Git 2.5.</p>
<p>My addition to the <em>share</em> extension is the ability for Mercurial to
automatically perform an <em>hg clone</em> + <em>hg share</em> in the same operation.
If the <em>share.pool</em> config option is defined, <em>hg clone</em>
will automatically clone or pull the repository data somewhere inside
the directory pointed to by <em>share.pool</em> then create a new working copy
from that shared location. But here's the magic: <strong>Mercurial can
automatically deduce that different remotes are the same logical
repository (by looking at the root changeset) and automatically have
them share storage</strong>. So if you first <em>hg clone</em> the <em>canonical</em>
repository then later do a <em>hg clone</em> of a <em>fork</em>, Mercurial will
pull down the changesets unique to the fork into the previously
created shared directory and perform a checkout from that. Contrast
with performing a full clone of the fork. <strong>If you are cloning multiple
repositories that are logically derived from the same original one,
this can result in a significant reduction of disk space and network
usage.</strong> I wrote this feature with automated consumers in mind,
particularly continuous integration systems. However, there is also
mode more suitable for humans where repositories are pooled not by their
root changeset but by their URL. For more info, see <em>hg help -e share</em>.</p>
<p>For Mercurial 3.4, I contributed changes that refactored how Mercurial's
tags cache works. This cache was a source of performance problems at
Mozilla's scale for many years. Since upgrading to Mercurial 3.4,
Mozilla has not encountered any significant performance problems with
the cache on either client or server as far as I know.</p>
<p>Building on this work, Mercurial 3.5 supports transferring tags cache
entries from server to client when clients clone/pull. Before, clients
would have to recompute tags cache entries for pulled changesets. On
repositories that are very large in terms of number of files (over 50,000)
or heads (hudreds or more), this could take several dozen seconds or
even minutes. This would manifest as a delay either during or after
initial clone. In Mercurial 3.5 - assuming both client and server
support the new <em>bundle2</em> wire protocol - the cache entries are
transferred from server to client and no extra computation needs to
occur. The client does pay a very small price for transferring this
additional data over the wire, but the payout is almost always worth it.
<strong>For large repositories, this feature means clones are usable sooner.</strong></p>
<p>A few weeks ago, a coworker told me that connections to a Mercurial
server were timing out mid clone. We investigated and discovered a
potential for a long CPU-intensive pause during clones where Mercurial
would not touch the network. On this person's under-powered EC2
instance, the pause was so long that the server's inactivity timeout
was triggered and it dropped the client's TCP connection. I refactored
Mercurial's cloning code so there is no longer a pause. There should
be no overall change in clone time, but there is no longer a perceivable
delay between applying changesets and manifests where the network could
remain idle. This investigation also revealed some potential follow-up
work for Mercurial to be a bit smarter about how it interacts with
networks.</p>
<p>Finally, I contributed <em>hg help scripting</em> to Mercurial's help database.
This help topic covers how to use Mercurial from scripting and other
automated environments. It reflects knowledge I've learned from seeing
Mercurial used in automation at Mozilla.</p>
<p>Of course, there are plenty of other changes in Mercurial 3.5. Stay
tuned for another blog post.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Prompting to Run mach mercurial-setup]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/17/prompting-to-run-mach-mercurial-setup" />
    <id>http://gregoryszorc.com/blog/2015/07/17/prompting-to-run-mach-mercurial-setup</id>
    <updated>2015-07-17T11:35:00Z</updated>
    <published>2015-07-17T11:35:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Prompting to Run mach mercurial-setup]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/17/prompting-to-run-mach-mercurial-setup"><![CDATA[<p>Earlier this week, I landed some changes to the Firefox development
environment that aggressively make <em>mach</em> prompt to run <em>mach
mercurial-setup</em>. Full details in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1182677">bug 1182677</a>.</p>
<p>As expected, the change resulted in a fair amount of whining and
bemoaning among various Firefox developers. I wanted to take some time
to explain why we moved forward, even though we knew not everyone would
like the feature.</p>
<p>My official job title at Mozilla is <em>Developer Productivity Engineer</em>.
My job is to make you do your job better.</p>
<p>I've been an employee at Mozilla for four years and in that time I've
witnessed a surprising lack of understanding around version control
tools. (I don't think Mozilla is significantly different from most
other companies here.) I find that a significant number of people
are practicing sub-optimal version control workflows because they don't
know any better (common) or because they are unwilling to change from
learned habits.</p>
<p>Furthermore, Mercurial is a highly customizable tool. A lot of
Mozillians have spent a lot of time developing useful extensions to
Mercurial that enable Mozillians to use Mercurial more effectively and
to thus become more productive. The latest epic time-saving hack
is <a href="http://www.ncalexander.net/blog/2015/07/02/build-fennec-frontend-fast-with-mach-artifact/">Nick Alexander's work to make Fennec build 80% faster by
having deep integration with version control</a>.</p>
<p><em>mach mercurial-setup</em> is almost
<a href="/blog/2013/07/29/mercurial-setup-wizard-for-firefox-development/">two years old</a>.
Yet, when assisting my fellow Mozillians with Mercurial issues, my
"have you run mach mercurial-setup?" question is still often met with
blank stares followed by "wait, there's a mach mercurial-setup?!" What's
even more frustrating is people wrongly believing that Mercurial can't
do things like rebasing and then spreading misinformation about the
lackings of Mercurial. (Mercurial has many advanced features disabled
out of the box so new users don't footgun themselves.)</p>
<p>Just like Firefox would be irrelevant if it didn't have millions of users,
your awesome tool is mostly irrelevant if you are its only user. That's
why when I hear of someone say they created an amazing tool for
themselves or modified a third party tool without sending the improvements
upstream, my blood pressure rises a little. It rises because here this
person did something awesome and they or some limited subset of people
who happened to be following the person on Twitter or reading their blog
at that point in time managed to a) know about the tool b) take the
effort to install it. The uptake rate is insanely low and return on
investment for that tool is low. It results in duplication of effort.
I find this painfully frustrating because I want everyone to have easy
access to the best tools available. This requires that tools are well
advertised and easy to install and use.</p>
<p>The primary goal of <em>mach mercurial-setup</em> is to make it super easy for
anyone to have an optimal Mercurial experience. It was apparent to me that
despite <em>mach mercurial-setup</em> existing, numerous people didn't know it
existed or weren't using it. Your awesome tool isn't very awesome unless
people are using it. And a lot of the awesome tools people have built
around Mercurial at Mozilla weren't being utilized and lots of
productivity wins were thus being unrealized. Forcefully pushing <em>mach
mercurial-setup</em> onto people is thus an attempt to unlock unrealized
productivity wins and to make people happier about the state of their
tools.</p>
<p>I'm not thrilled that mach's prompting to run <em>mach mercurial-setup</em> is
as disruptive as it is. It's bad user experience. I know better. But,
(and this is explained somewhat in the bug), other solutions are more
complicated and have other gotchas. The current, invasive implementation
was the easiest to implement and has the biggest bang for the buck in
terms of adoption. We knew people would complain about it. But from
my perspective, it was do this or do nothing. And nothing hadn't been
very effective. So we did something.</p>
<p>There has been lots of feedback about the change this week. Most
surprising to me is the general sentiment of "I don't want something
automatically changing my hgrc file." I find this surprising because
<em>mach mercurial-setup</em> puts the user firmly in control by prompting
before doing anything, thus respecting user choice and avoiding gotchas
and unwanted changes. It's clear this property needs to be advertised a
bit more so people aren't scared to run <em>mach mercurial-setup</em> and don't
spread fear, uncertainty, and doubt about the tool to others. (I also
find it somewhat surprising people would think this in the first place:
I'd like to think we'd implicitly trust most Mozillians to implement
tools that respect user choice and don't do <em>malicious</em> things.)</p>
<p>Like all software, things can and will change. The user experience of
this new feature isn't terrific. We'll iterate on it. If you want to
help enact change, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=mach">file a bug in Core :: mach</a>
(for now) and we'll go from there.</p>
<p>Thank you for your patience and your understanding.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Cloning From S3]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/07/08/cloning-from-s3" />
    <id>http://gregoryszorc.com/blog/2015/07/08/cloning-from-s3</id>
    <updated>2015-07-08T11:40:00Z</updated>
    <published>2015-07-08T11:40:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Cloning From S3]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/07/08/cloning-from-s3"><![CDATA[<p>A month ago, I <a href="/blog/2015/05/29/faster-cloning-from-hg.mozilla.org-with-server-provided-bundles/">blogged about faster cloning from hg.mozilla.org using
bundle files</a>.
But deploying the feature on the servers was only the tip of the
iceberg.</p>
<p>At the end of last week, Firefox release automation rolled out the
<em>bundleclone</em> extension to their Linux and OS X machines. Essentially,
clones are bootstrapped from Amazon S3 automatically once this extension
is installed.</p>
<p>In just a few days of deployment, we've already seen a drastic shift in
traffic. On UTC day 2015-07-07, S3 served 1,563,014,396,236 bytes of
repository data! The hg.mozilla.org servers themselves served a total of
1,976,057,201,583 bytes.</p>
<p>But we're not done. The <em>bundleclone</em> extension
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1181597">isn't yet deployed on Windows</a>. Nor is it always used on TaskCluster. In addition, there are
still some high-use repositories that don't have bundles being
generated. Yesterday, I crunched the data and
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1181373">enabled bundles on more repositories</a>. It's too early to have conclusive data, but this should
move an additional several hundred gigabytes of traffic to S3.</p>
<p>At Whistler, I said that reducing traffic on hg.mozilla.org by 90% is
within the realm of possibility. Between a partial rollout of S3
clone offload that is already serving 44% of traffic and a
<a href="https://selenic.com/pipermail/mercurial-devel/2015-July/071777.html">feature I'm working on in core Mercurial to enable auto sharing of repository data</a>,
I'd say we're well on track.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Changeset Metadata on hg.mozilla.org]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/06/04/changeset-metadata-on-hg.mozilla.org" />
    <id>http://gregoryszorc.com/blog/2015/06/04/changeset-metadata-on-hg.mozilla.org</id>
    <updated>2015-06-04T13:55:00Z</updated>
    <published>2015-06-04T13:55:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Changeset Metadata on hg.mozilla.org]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/06/04/changeset-metadata-on-hg.mozilla.org"><![CDATA[<p>Just a few minutes ago, I deployed some updates to
<a href="https://hg.mozilla.org/">hg.mozilla.org</a> to display more
metadata on changeset pages. See
<a href="https://hg.mozilla.org/mozilla-central/rev/4b69a62d1905">4b69a62d1905</a>,
<a href="https://hg.mozilla.org/mozilla-central/rev/dc4023d54436">dc4023d54436</a>,
and <a href="https://hg.mozilla.org/mozilla-central/rev/b617a57d6bf1">b617a57d6bf1</a>
for examples of what's shown.</p>
<p>We currently display:</p>
<ul>
<li>More detailed pushlog info. (Before you had to load another page to
  see things like the date of the push.)</li>
<li>The list of reviewers, each being a link that searches for other
  changesets they've reviewed.</li>
<li>A concise list of bugs referenced in the commit message.</li>
<li>Links to changesets that were backed out by this changeset.</li>
<li>On changesets that were backed out, we <em>may</em> also display a message
  that the changeset was backed out.</li>
<li>For Firefox repos, we also display the application <em>milestone</em>. This
  is the Gecko/app version recorded in the <em>config/milestone.txt</em> file
  in that changeset. The value can be used to quickly answer the
  question <em>What versions of Firefox have this changeset.</em></li>
</ul>
<p>If you notice any issues or have requests for new features, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Developer%20Services&amp;component=Mercurial%3A%20hg.mozilla.org">file a bug</a>.</p>
<p>This work is built on top of a feature I added to Mercurial 3.4 to make
it easier to inject extra data into Mercurial's web templates. We just
deployed Mercurial 3.4.1 to hg.mozilla.org yesterday. It's worth noting
that this deployment happened in the middle of the day with no
user-perceived downtime. This is a far cry from where we were a year
ago, when any server change required a maintenance window. We've
invested a lot of work into a test suite for this service so we can
continuously deploy without fear of breaking things. Moving fast feels
so good.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Faster Cloning from hg.mozilla.org With Server Provided Bundles]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2015/05/29/faster-cloning-from-hg.mozilla.org-with-server-provided-bundles" />
    <id>http://gregoryszorc.com/blog/2015/05/29/faster-cloning-from-hg.mozilla.org-with-server-provided-bundles</id>
    <updated>2015-05-29T11:30:00Z</updated>
    <published>2015-05-29T11:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mercurial" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <summary type="html"><![CDATA[Faster Cloning from hg.mozilla.org With Server Provided Bundles]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2015/05/29/faster-cloning-from-hg.mozilla.org-with-server-provided-bundles"><![CDATA[<p>When you type <em>hg clone</em>, the Mercurial server will create a <em>bundle</em>
from repository content at the time of the request and stream it to
the client. (Git works essentially the same way.)</p>
<p>This approach usually <em>just works</em>. But there are some downsides,
particularly with large repositories.</p>
<p>Creating bundles for large repositories is not cheap. For
mozilla-central, Firefox's main repository, it takes ~280s of CPU time
on my 2014 MacBook Pro to generate a bundle. Every time a client runs a
<em>hg clone https://hg.mozilla.org/mozilla-central</em>, a server somewhere
is spinning a CPU core generating ~1.1 GB of data. What's more, if
another clone arrives at the same time, another process will perform
the exact same work! When we talk about multiple minutes of CPU time
per request, this extra work starts to add up.</p>
<p>Another problem with large repositories is interrupted downloads. If
you suffer a connectivity blip during your <em>clone</em> command, you'll
have to start from scratch. This potentially means re-transferring
hundreds of megabytes from the server. It also means the server has
to generate a new bundle, consuming even more CPU time. This is not
good for the user or the server.</p>
<p>There have been multiple outages of hg.mozilla.org as a result of
the service being flooded with clone requests to large repositories.
Dozens of clients (most of them in Firefox or Firefox OS
release automation) have cloned the same repository around the same
time and overwhelmed network bandwidth in the data center or CPU
cores on the Mercurial servers.</p>
<p>A common solution to this problem is to not use the <em>clone</em> command
to receive initial repository data from the server. Instead, a
static <em>bundle</em> file will be generated and made available to clients.
Clients will call <em>hg init</em> to create an empty repository then will
perform an <em>hg unbundle</em> to apply the contents of a pre-generated
bundle file. They will then run <em>hg pull</em> to fetch new data that
was created after the bundle was generated. (It's worth noting that
Git's <em>clone --reference</em> option is similar.)</p>
<p>This is a good technical solution. Firefox and Firefox OS release
automation have effectively implemented this. However, it is a lot of
work: you have to build your own bundle generation and hosting
infrastructure and you have to remember that every <em>hg clone</em> should
probably be using bundles instead. It is extra complexity and complexity
that must be undertaken by every client. If a client forgets, the
consequences can be disastrous (clone flooding leading to service
outage). Client-side opt-in is prone to lapses and doesn't scale.</p>
<p><strong>As of today, we've deployed a more scalable, server-based solution to
hg.mozilla.org.</strong></p>
<p>hg.mozilla.org is now itself generating bundles for a handful of
repositories, including mozilla-central, inbound, fx-team, and
mozharness. These bundles are being uploaded to Amazon S3. And
<strong>those bundles are being advertised by the server over Mercurial's
wire protocol</strong>.</p>
<p>When you install the <em>bundleclone</em> Mercurial extension, <em>hg clone</em> is
taught to look for bundles being advertised on the server. If a bundle
is available, the bundle is downloaded, applied, and then the client
does the equivalent of an <em>hg pull</em> to fetch all new data since when the
bundle was generated. If a bundle exists, it is used transparently: no
client side cooperation is needed beyond installing the <em>bundleclone</em>
extension. If a bundle doesn't exist, it simply falls back to
Mercurial's default behavior. <strong>This effectively shifts responsibility
for doing efficient clones from clients to server operators, which
means server operators don't need cooperation from clients to enact
important service changes.</strong> Before, if clients weren't using bundles,
we'd have to wait for clients to update their code. Now, we can see
a repository is being cloned heavily and start generating bundles for
it without having to wait for the client to deploy new code.</p>
<p>Furthermore, we've built primitive <em>content negotiation</em> into the
process. The server doesn't simply advertise one bundle file: it
advertises several bundle files. We offer gzip, bzip2, and <em>stream</em>
bundles. gzip is what Mercurial uses by default. It works OK. bzip2
bundles are smaller, but they take longer to process. <em>stream</em> bundles
are essentially tar archives of the <em>.hg/store</em> directory and are larger
than gzip bundles, but insanely fast because there is very little CPU
required to apply them. In addition, we advertise URLs for multiple S3
regions, currently us-west-2 (Oregon) and us-east-1 (Virginia). This
enables clients to prefer the bundle most appropriate for them.</p>
<p>A benefit of serving bundles from S3 is that Firefox and Firefox OS
release automation (the biggest consumers of hg.mozilla.org) live in
Amazon EC2. They are able to fetch from S3 over a gigabit network.
And, since we're transferring data within the same AWS region, there
are no data transfer costs. Previously, we were transferring ~1.1 GB
from a Mozilla data center to EC2 for each clone. This took up bandwidth
in Mozilla's network and cost Mozilla money to send data thousands of
miles away. And, we never came close to saturating a gigabit network (we
do with stream bundles). Wins everywhere!</p>
<p>The <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/bundleclone.html">full instructions</a>
detail how to use <em>bundleclone</em>. <strong>I recommend everyone at Mozilla
install the extension</strong> because there should be no downside to doing it.</p>
<p>Once <em>bundleclone</em> is deployed to Firefox and Firefox OS release
automation, we should hopefully never again see those machines bring
down hg.mozilla.org due to a flood of clone requests. We should also
see a drastic reduction in load to hg.mozilla.org. I'm optimistic
bandwidth will decrease by over 50%!</p>
<p>It's worth noting that the functionality from the <em>bundleclone</em> extension
is coming to vanilla Mercurial. The functionality (which was initially
added by Mozilla's Mike Hommey) is part of Mercurial's <em>bundle2</em> protocol,
which is available, but isn't enabled by default yet. <em>bundleclone</em> is thus
a temporary solution to bring us server stability and client
improvements until modern Mercurial versions are deployed everywhere
in a few months time.</p>
<p>Finally, I would like to credit Augie Fackler for the
<a href="http://thread.gmane.org/gmane.comp.version-control.mercurial.devel/54872/focus=54872">original idea</a>
for server-assisted bundle-based clones.</p>]]></content>
  </entry>
</feed>
