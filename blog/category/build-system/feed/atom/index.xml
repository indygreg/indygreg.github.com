<?xml version="1.0" encoding="UTF-8"?>
<feed
  xmlns="http://www.w3.org/2005/Atom"
  xmlns:thr="http://purl.org/syndication/thread/1.0"
  xml:lang="en"
   >
  <title type="text">Gregory Szorc's Digital Home</title>
  <subtitle type="text">Rambling on</subtitle>

  <updated>2017-03-07T17:54:50Z</updated>
  <generator uri="http://blogofile.com/">Blogofile</generator>

  <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog" />
  <id>http://gregoryszorc.com/blog/feed/atom/</id>
  <link rel="self" type="application/atom+xml" href="http://gregoryszorc.com/blog/feed/atom/" />
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Investing in the Firefox Build System in 2016]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2016/01/11/investing-in-the-firefox-build-system-in-2016" />
    <id>http://gregoryszorc.com/blog/2016/01/11/investing-in-the-firefox-build-system-in-2016</id>
    <updated>2016-01-11T14:20:00Z</updated>
    <published>2016-01-11T14:20:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[Investing in the Firefox Build System in 2016]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2016/01/11/investing-in-the-firefox-build-system-in-2016"><![CDATA[<p>Most of Mozilla gathered in Orlando in December for an all hands meeting.
If you attended any of the plenary sessions, you probably heard people
like David Bryant and Lawrence Mandel make references to improving the
Firefox build system and related tools. Well, the cat is out of the bag:
<strong>Mozilla will be investing heavily in the Firefox build system and related
tooling in 2016!</strong></p>
<p>In the past 4+ years, the Firefox build system has mostly been held
together and incrementally improved by a loose coalition of people who
cared. We had a period in 2013 where a number of people were making
significant updates (this is when moz.build files happened). But for the
past 1.5+ years, there hasn't really been a coordinated effort to
improve the build system - just a lot of one-off tasks and
(much-appreciated) individual heroics. This is changing.</p>
<p>Improving the build system is a high priority for Mozilla in 2016.
And investment has already begun. In Orlando, we had a marathon 3 hour
meeting planning work for Q1. At least 8 people have committed to
projects in Q1.</p>
<p>The focus of work is split between immediate short-term wins and
longer-term investments. <strong>We also decided to prioritize the Firefox and
Fennec developer workflows (over Gecko/Platform) as well as the
development experience on Windows.</strong> This is because these areas have
been under-loved and therefore have more potential for impact.</p>
<p>Here are the projects we're focusing on in Q1:</p>
<ul>
<li>Turnkey artifact based builds for Firefox and Fennec (download
  pre-built binaries so you don't have to spend 20 minutes compiling
  C++)</li>
<li>Running tests from the source directory (so you don't have to copy
  tens of thousands of files to the object directory)</li>
<li>Speed up configure / prototype a replacement</li>
<li>Telemetry for mach and the build system</li>
<li>NSPR, NSS, and (maybe) ICU build system rewrites</li>
<li><em>mach build faster</em> improvements</li>
<li>Improvements to build rules used for building binaries (enables
  non-make build backends)</li>
<li>mach command for analyzing C++ dependencies</li>
<li>Deploy automated testing for <em>mach bootstrap</em> on TaskCluster</li>
</ul>
<p>Work has already started on a number of these projects. I'm optimistic
2016 will be a watershed year for the Firefox build system and the
improvements will have a drastic positive impact on developer
productivity.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[MacBook Pro Firefox Build Times Comparison]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison" />
    <id>http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison</id>
    <updated>2013-11-05T10:00:00Z</updated>
    <published>2013-11-05T10:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[MacBook Pro Firefox Build Times Comparison]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/11/05/macbook-pro-firefox-build-times-comparison"><![CDATA[<p>Many developers use MacBook Pros for day-to-day Firefox development.
So, I thought it would be worthwhile to perform a comparison of
Firefox build times for various models of MacBook Pros.</p>
<h2>Test setup</h2>
<p>The numbers in this post are obtained from 3 generations of MacBook
Pros:</p>
<ol>
<li>
<p>A 2011 Sandy Bridge 4 core x 2.3 GHz with 8 GB RAM and an aftermarket
   SSD.</p>
</li>
<li>
<p>A 2012 Ivy Bridge retina with 4 core x 2.6 GHz, 16 GB RAM, and a
   factory SSD (or possibly flash storage).</p>
</li>
<li>
<p>A 2013 Haswell retina with 4 core x 2.6 GHz, 16 GB RAM, and flash
   storage.</p>
</li>
</ol>
<p>All machines were running OS X 10.9 Mavericks and were using the
Xcode 5.0.1 toolchain (<em>Xcode 5 clang: Apple LLVM version 5.0
(clang-500.2.79) (based on LLVM 3.3svn)</em>) to build.</p>
<p>The power settings prevented machine sleep and machines were plugged
into A/C power during measuring. I did not use the machines while
obtaining measurements.</p>
<p>The 2012 and 2013 machines were very vanilla OS installs. However,
the 2011 machine was my primary work computer and may have had a
few background services running and may have been slower due to
normal wear and tear. The 2012 machine was a loaner machine from
IT and has an unknown history.</p>
<p>All data was obtained from mozilla-central revision d4a27d8eda28.</p>
<p>The mozconfig used contained:</p>
<p>export MOZ_PSEUDO_DERECURSE=1
  mk_add_options MOZ_OBJDIR=@TOPSRCDIR@/obj-firefox.noindex</p>
<p>Please note that the objdir name ends with <em>.noindex</em> to prevent Finder
from indexing build files.</p>
<p>I performed all tests multiple times and used the fastest time. I used
<em>time</em> command for obtaining measurements of wall, user, and system
time.</p>
<h2>Results</h2>
<h3>Configure Times</h3>
<p>The result of <em>mach configure</em> is as follows:</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>29.748</td>
    <td>17.921</td>
    <td>11.644</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>26.765</td>
    <td>15.942</td>
    <td>10.501</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>21.581</td>
    <td>12.597</td>
    <td>8.595</td>
  </tr>
</table>

<h3>Clobber build no ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
not enabled.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>22:29 (1349)</td>
    <td>145:35 (8735)</td>
    <td>12:03 (723)</td>
    <td>157:38 (9458)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>15:00 (900)</td>
    <td>94:18 (5658)</td>
    <td>8:14 (494)</td>
    <td>102:32 (6152)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>11:13 (673)</td>
    <td>69:55 (4195)</td>
    <td>6:04 (364)</td>
    <td>75:59 (4559)</td>
  </tr>
</table>

<h3>Clobber build with empty ccache</h3>
<p><em>mach build</em> was performed <em>after</em> running <em>mach configure</em>. ccache was
enabled. The ccache ccache was cleared before running <em>mach configure</em>.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>25:57 (1557)</td>
    <td>161:30 (9690)</td>
    <td>18:21 (1101)</td>
    <td>179:51 (10791)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>16:58 (1018)</td>
    <td>104:50 (6290)</td>
    <td>12:32 (752)</td>
    <td>117:22 (7042)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>12:59 (779)</td>
    <td>79:51 (4791)</td>
    <td>9:24 (564)</td>
    <td>89:15 (5355)</td>
  </tr>
</table>

<h3>Clobber build with populated ccache</h3>
<p><em>mach build</em> was performed after running <em>mach configure</em>. ccache was
enabled and the ccache was populated with the results of a prior build.
In theory, all compiler invocations should be serviced by ccache
entries.</p>
<p>This measure is a very crude way to measure how fast clobber builds
would be if compiler invocations were nearly instantaneous.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>3:59 (239)</td>
    <td>8:04 (484)</td>
    <td>3:21 (201)(</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3:11 (191)</td>
    <td>6:45 (405)</td>
    <td>2:53 (173)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2:31 (151)</td>
    <td>5:22 (322)</td>
    <td>2:12 (132)</td>
  </tr>
</table>

<h3>No-op builds</h3>
<p><em>mach build</em> was performed on a tree that was already built.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>1:58 (118)</td>
    <td>2:25 (145)</td>
    <td>0:41 (41)</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>1:42 (102)</td>
    <td>2:02 (122)</td>
    <td>0:37 (37)</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>1:20 (80)</td>
    <td>1:39 (99)</td>
    <td>0:28 (28)</td>
  </tr>
</table>

<h3>binaries no-op</h3>
<p><em>mach build binaries</em> was performed on a fully built tree. This results
in nothing being executed. It's a way to test the overhead of the
<em>binaries</em> make target.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>4.21</td>
    <td>4.38</td>
    <td>0.92</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>3.17</td>
    <td>3.37</td>
    <td>0.71</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>2.67</td>
    <td>2.75</td>
    <td>0.56</td>
  </tr>
</table>

<h3>binaries touch single .cpp</h3>
<p><em>mach build binaries</em> was performed on a fully built tree after touching
the file <em>netwerk/dns/nsHostResolver.cpp</em>. ccache was enabled but
cleared before running this test. This test simulates common C++
developer workflow of changing C++ and recompiling.</p>
<table border="1">
  <tr>
    <th>Machine</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
  </tr>
  <tr>
    <td>2011</td>
    <td>12.89</td>
    <td>13.88</td>
    <td>1.96</td>
  </tr>
  <tr>
    <td>2012</td>
    <td>10.82</td>
    <td>11.63</td>
    <td>1.78</td>
  </tr>
  <tr>
    <td>2013</td>
    <td>8.57</td>
    <td>9.29</td>
    <td>1.23</td>
  </tr>
</table>

<h3>Tier times</h3>
<p>The times of each build system <em>tier</em> were measured on the 2013 Haswell
MacBook Pro. These timings were obtained out of curiosity to help
isolate the impact of different parts of the build. ccache was not
enabled for these tests.</p>
<table border="1">
  <tr>
    <th>Action</th>
    <th>Wall time</th>
    <th>User time</th>
    <th>System time</th>
    <th>Total CPU time</th>
  </tr>
  <tr>
    <td>export clobber</td>
    <td>15.75</td>
    <td>66.11</td>
    <td>11.33</td>
    <td>77.44</td>
  </tr>
  <tr>
    <td>compile clobber</td>
    <td>9:01 (541)</td>
    <td>64:58 (3898)</td>
    <td>5:08 (308)</td>
    <td>70:06 (4206)</td>
  </tr>
  <tr>
    <td>libs clobber</td>
    <td>1:34 (94)</td>
    <td>2:15 (135)</td>
    <td>0:39 (39)</td>
    <td>2:54 (174)</td>
  </tr>
  <tr>
    <td>tools clobber</td>
    <td>9.33</td>
    <td>13.41</td>
    <td>2.48</td>
    <td>15.89</td>
  </tr>
  <tr>
    <td>export no-op</td>
    <td>3.01</td>
    <td>9.72</td>
    <td>3.47</td>
    <td>13.19</td>
  </tr>
  <tr>
    <td>compile no-op</td>
    <td>3.18</td>
    <td>18.02</td>
    <td>2.64</td>
    <td>20.66</td>
  </tr>
  <tr>
    <td>libs no-op</td>
    <td>58.2</td>
    <td>46.9</td>
    <td>13.4</td>
    <td>60.3</td>
  </tr>
  <tr>
    <td>tools no-op</td>
    <td>8.82</td>
    <td>12.68</td>
    <td>1.72</td>
    <td>14.40</td>
  </tr>
</table>

<h2>Observations and conclusions</h2>
<p>The data speaks for itself: <strong>the 2013 Haswell MacBook Pro is
significantly faster than its predecessors.</strong> It clocks in at 2x faster
than the benchmarked 2011 Sandy Bridge model (keep in mind the 300 MHz
base clock difference) and is ~34% faster than the 2012 Ivy Bridge (at
similar clock speed). Personally, I was surprised by this. I was
expecting speed improvements over Ivy Bridge, but not 34%.</p>
<p>It should go without saying: <strong>if you have the opportunity to upgrade
to a new, Haswell-based machine: do it.</strong> If possible, purchase
the upgrade to a 2.6 GHz CPU, as it contains ~13% more MHz than the
base 2.3 GHz model: this will make a measurable difference in build
times.</p>
<p>It's worth noting the increased efficiency of Haswell over its
predecessors. The total CPU time required to build decreased from ~158
minutes to ~103 minutes to 76 minutes! That 76 minute number is worth
highlighting because it means if we get 100% CPU saturation during
builds, we'll be able to build the tree in under 10 wall time minutes!</p>
<p>I hadn't performed crude benchmarks of high-level build system actions
since the <em>MOZ_PSEUDO_DERECURSE</em> work landed and I wanted to use the
opportunity of this hardware comparison to grab some numbers.</p>
<p>The overhead of ccache continues to surprise me. On the 2013
machine, enabling ccache increased the wall time of a clobber build by
1:46 and added 13:16 of CPU time. This is an increase of 16% and 17%,
respectively.</p>
<p>It's worth highlighting just how much time is spent compiling C/C++. In
our artificial tier measuring results, our clobber build time was ~660
wall time seconds (11 minutes) and used ~4473s CPU time (74:33). Of
this, 9:01 wall time and 70:06 CPU time was spent compiling C/C++. This
represents ~82% wall time and ~94% CPU time! Please note this does not
include linking. <strong>Anything we can do to decrease the CPU time used by
the compiler will make the build faster.</strong></p>
<p>I also found it interesting to note variances in obtained times. Even on
my brand new 2013 Haswell MacBook Pro where I know there aren't many
background processes running, wall times could vary significantly. I
<em>think</em> I isolated it to CPU bursting and heat issues. If I wait a few
minutes between CPU intensive tests, results are pretty consistent. But
if I perform CPU intensive tests back-to-back, the run times often vary.
The only other thing coming into play could be page caching or
filesystem indexing. I accounted for the latter by disabling Finder
on the object directory. And, I'd like to think that flash storage is
fast enough to remove I/O latency from the equation. Who knows. At the
end of the day, laptops aren't servers and OS X is a consumer OS, so I
don't expect ultra consistency.</p>
<p>Finally, I want to restate just how fast Haswell is. If you have the
opportunity to upgrade, do it.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Distributed Compiling and Firefox]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox" />
    <id>http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox</id>
    <updated>2013-10-31T11:35:00Z</updated>
    <published>2013-10-31T11:35:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[Distributed Compiling and Firefox]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/10/31/distributed-compiling-and-firefox"><![CDATA[<p>If you had infinite CPU cores available and the Firefox build system
could distribute them all for concurrent compilation, Firefox
clobber build times would likely be 3-5 minutes instead of ~15
minutes on modern machines. This is a massive win. It therefore
should come as no surprise that distributed compiling is very
interesting to us.</p>
<p>Up until recently, the benefits of distributed compiling in the Firefox
build system couldn't be fully realized. This was because the build
system was performing recursive make traversal and make only <em>knew</em>
about a tiny subset of the tree's total C++ files at one time. For
example, when visiting <em>/layout/base</em> it only knew about 35 of the
close to 6000 files that get compiled as part of building Firefox. This
meant there was a hard ceiling to the max concurrency the build system
could achieve. This ceiling was often higher than the number of cores in
an individual machine, so it wasn't a huge issue for single machine
builds. But it did significantly limit the benefits of distributed
compiling. This all changed recently.</p>
<p><strong>As of a few weeks ago, the build system no longer encounters a low
ceiling preventing distributed compilation from reaping massive
benefits.</strong> If you have build with <em>make -j128</em>, make will spawn
128 compiler processes when processing the <em>compile</em> tier (which
is where most compilation occurs). If your compiler is set to a
distributed compiler, you will win.</p>
<p>So, what should you do about it?</p>
<p>I encourage people to set up distributed compilation <em>networks</em>
to reap the benefits of distributed compilation. Here are some tools you
should know about and some things to keep in mind.</p>
<p><a href="https://code.google.com/p/distcc/">distcc</a> is the tried and proven tool
for performing distributed compilation. It's heavily used and gets the
job done. It even works on Windows and can perform remote processing,
which is a huge win for our tree, where preprocessing can be
computationally expensive because of excessive includes. But, it has
a few significant drawbacks. Read the next paragraph.</p>
<p>I'm personally more excited about
<a href="https://github.com/icecc/icecream">icecream</a>. It has some very
compelling advantages to distcc. It has a scheduler that can
intelligently distribute load between machines. It uses network
broadcast to discover the scheduler. So, you just start the client
daemon and if there is a scheduler on the local network, it's all
set up. Icecream transfers the compiler toolchain between nodes
so you are guaranteed to have consistent output. (With distcc,
output may not be idempotent if the nodes aren't homogenous since distcc
relies on the system-local toolchain. If different versions are
installed on different nodes, you are out of luck). Icecream also
supports cross-compiling. In theory, you can have Linux machines
building for OS X, 32-bit machines building for 64-bit, etc. This
is all very difficult (if not impossible) to do with distcc.
Unfortunately, icecream doesn't work on Windows and doesn't appear
to support server-side preprocessing. Although, I imagine
both could be made to work if someone put in the effort.</p>
<p>Distributed compilation is very network intensive. I haven't measured,
but I suspect Wi-Fi bandwidth and latency constraints might make it
prohibitive there. It certainly won't be good for Wi-Fi saturation!
<strong>If you are in a Mozilla office, please do not attempt to perform
distributed compilation over Wi-Fi!</strong> For the same reasons, distributed
compilation will likely not benefit you if you are attempting to compile
on network-distant nodes.</p>
<p>I have set up an icecream server in the Mozilla San Francisco office. If
you install the icecream client daemon (iceccd) on your machine, it
should just work. I'm not sure what broadcast nets are configured as,
but I've successfully had machines on the 7th floor discover it
automatically. I guarantee no SLA for this server. Ping me privately
if you have difficulty connecting.</p>
<p>I've started very preliminary talks with Mozilla IT about setting up
dedicated <em>compiler farms</em> in Mozilla offices. I'm not saying this is
coming any time soon. I feel this will have a major impact on developer
productivity and I wanted to get the ball rolling months in advance
so nobody can claim this is a fire drill.</p>
<p>For distributed compilation to work well, the build system really needs
to be aware of distributed compilation. For example, to yield the
benefits of distributed compilation with make, you need to pass -j64 or
some other large value for concurrency. However, this value would be
universal for <em>every</em> task in the build. There are still thousands of
processes that must run locally. Using -j64 on these local tasks could
cause memory exhaustion, I/O saturation, excessive context switching,
etc. But if you decrease the concurrency ceiling, you lose the benefits
of distributed compilation! The build system thus needs to be taught
when distributed compilation is available and what tasks can be made
concurrent so it can intelligently adjust the -j concurrency limit at
run-time. This is why we have a higher-level build wrapper tool: <em>mach
build</em>. (This is another reason why people should be building through
mach instead of invoking make directly.)</p>
<p>No matter what technical solution we employ, I would like the build
system to automatically discover and use distributed compilation if
it is available. If we need to hardcode Mozilla IP addresses or
hostnames into the build system, I'm fine with that. I just don't want
developers not achieving much-faster build times because they are
ignorant. If you are in a physical location with distributed compilation
support, you should get that automatically: fast builds should not be
hard.</p>
<p>We can and should investigate distributed compilation as part of release
automation. Icecream should mitigate the concerns about build
reproducibility since the toolchain is transferred at build time.</p>
<p>I have had success getting Icecream to work with Linux builds. However,
OS X is problematic. Specifically, Icecream is unable to create the
build environment for distribution (likely modern OS X/Xcode
compatibility issue). Details are in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=927952">bug 927952</a>.</p>
<p>Build peers have a lot on our plate this quarter and making distributed
compilation work well is not in our official goals. <strong>I would love, love,
love if someone could step up and be a hero to make distributed
compilation work better with the build system.</strong> If you are interested,
pop into #build on irc.mozilla.org.</p>
<p>In summary, there are massive developer productivity wins waiting to be
realized through distributed compiling. There is nobody tasked to work
on this officially. Although, I'd love it if there were. If you find
yourself setting up ad-hoc networks in offices, I'd <em>really</em> like to see
some kind of discovery in <em>mach</em>. If not, there will be people left
behind and that really stinks for those individuals. If you do any
work around distributed compiling, please have it tracked under
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=485559">bug 485559</a>.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[The State of the Firefox Build System (2013 Q3 Review)]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/10/15/the-state-of-the-firefox-build-system-(2013-q3-review)" />
    <id>http://gregoryszorc.com/blog/2013/10/15/the-state-of-the-firefox-build-system-(2013-q3-review)</id>
    <updated>2013-10-15T13:00:00Z</updated>
    <published>2013-10-15T13:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[The State of the Firefox Build System (2013 Q3 Review)]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/10/15/the-state-of-the-firefox-build-system-(2013-q3-review)"><![CDATA[<p>As we look ahead to Q4 planning for the Firefox build system, I wanted
to take the time to reflect on what was accomplished in Q3 and to
simultaneously look forward to Q4 and beyond.</p>
<h2>2013 Q3 Build System Improvements</h2>
<p>There were notable improvements in the build system during the last
quarter.</p>
<p>The issues our <em>customers</em> care most about is speed. Here is a list of
accomplishments in that area:</p>
<ul>
<li>
<p><em>MOZ_PSEUDO_DERECURSE</em> work to change how make directory traversal
  works. This enabled the <em>binaries</em> make target, which can do no-op
  libxul-only builds in just a few seconds. Of all the changes that
  landed this quarter, this is the most impactful to local build
  times. This change also enables C++ compilation to scale out to
  as many cores as you have. Previously, the build system was
  <em>starved</em> in many parts of the tree when compiling C++. Mike Hommey
  is responsible for this work. I reviewed most of it.</p>
</li>
<li>
<p>WebIDL and IPDL bindings are now compiled in <em>unified</em> mode,
  reducing compile times and linker memory usage. Nathan Froyd wrote the
  code. I reviewed the patches.</p>
</li>
<li>
<p>XPIDL files are generated much more efficiently. This removed a
  few minutes of CPU core time from builds. I wrote these patches and
  Mike Hommey reviewed.</p>
</li>
<li>
<p>Increased reliance on install manifests to process file installs.
  They have drastically reduced the number of processes required to
  build by performing all actions inside Python processes as system
  calls and removing the clownshoes of having to delete parts of the
  object directory at the beginning of builds. When many mochitests
  were converted to manifests, no-op build times dropped by ~15%
  on my machine. Many people are responsible for this work. Mike Hommey
  wrote the original install code for packaging a few months ago. I
  built in manifest file support, support for symlinks, and made the
  code a bit more robust and faster. Mike Hommey reviewed these
  patches.</p>
</li>
<li>
<p>Many bugs and issues around dependency files on Windows have been
  discovered and fixed. These were a common source of clobbers.
  Mike Hommey found most of these, many during his work to make
  MOZ_PSEUDO_DERECURSE work.</p>
</li>
<li>
<p>The effort to reduce C++ include hell is resulting in significantly
  shorter incremental builds. While this effort is largely outside the
  build config module, it is worth mentioning. Ehsan Akhgari is leading
  this effort. He's been assisted by too many people to mention.</p>
</li>
<li>
<p>The build system now has different build modes favoring faster
  building vs release build options depending on the environment. Mike
  Hommey wrote most (all?) of the patches.</p>
</li>
</ul>
<p>A number of other non-speed related improvements have been made:</p>
<ul>
<li>
<p>The build system now monitors resource usage during builds and can
  graph the results. I wrote the code. Ted Mielczarek, Mike Hommey,
  and Mike Shal had reviews.</p>
</li>
<li>
<p>Support for test manifests has been integrated with the build system.
  This enabled some build speed wins and is paving the road for better
  testing UX, such as the automagical <em>mach test</em> command, which will
  run the appropriate test suite automatically. Multiple people were
  involved in the work to integrate test manifests with the build
  system. I wrote the patches. But Ted Mielczarek got primary review.
  Joel Maher, Jeff Hammel, and Ms2ger provided excellent assistance
  during the design and implementation phase. The work around
  mochitest manifests likely wouldn't have happened this quarter if
  all of us weren't attending an A*Team work week in August.</p>
</li>
<li>
<p>There are now in-tree build system docs. They are
  <a href="https://ci.mozilla.org/job/mozilla-central-docs/Build_Documentation/index.html">published automatically</a>.
  Efforts have been made to purge MDN of cruft. I am responsible for
  writing the code and most of the docs. Benjamin Smedberg and Mike Shal
  performed code reviews.</p>
</li>
<li>
<p>Improvements have been made to object directory detection in mach.
  This was commonly a barrier to some users using mach. I am responsible
  for the code. Nearly every peer has reviewed patches.</p>
</li>
<li>
<p>We now require Python 2.7.3 to build, making our future Python 3
  compatibility story much easier while eliminating a large class
  of Python 2.7.2 and below bugs that we constantly found ourselves
  working around.</p>
</li>
<li>
<p>mach bootstrap has grown many new features and should be more robust
  than ever. There are numerous contributors here, including many
  community members that have found and fixed bugs and have added
  support for additional distributions.</p>
</li>
<li>
<p>The boilerplate from Makefile.in has disappeared. Mike Hommey is to
  thank.</p>
</li>
<li>
<p>dumbmake integrated with mach. Resulted in friendlier build interface
  for a nice UX win. Code by Nick Alexander. I reviewed.</p>
</li>
<li>
<p>Many variables have been ported from Makefile.in to moz.build. We
  started Q3 with support for 47 variables and now support 73. We
  started with 1226 Makefile.in and 1517 moz.build and currently
  have 941 Makefile.in and 1568 moz.build. Many people contributed to
  this work. Worth mentioning are Joey Armstrong, Mike Shal, Joshua
  Cranmer, and Ms2ger.</p>
</li>
<li>
<p>Many build actions are moving to Python packages. This enabled pymake
  <em>inlining</em> (faster builds) and is paving the road towards no .pyc
  files in the source directory. (pyc files commonly are the source of
  clobber headaches and make it difficult to efficiently perform builds
  on read-only filesystems.) I wrote most of the patches and Mike Shal
  and Mike Hommey reviewed.</p>
</li>
<li>
<p>moz.build is now more strict about what it accepts. We check for
  missing files at config parse time rather than build time, causing
  errors to surface faster. Many people are responsible for this work.
  Mike Shal deserves kudos for work around C/C++ file validation.</p>
</li>
<li>
<p>mach has been added to the B2G repo. Jonathan Griffin and Andrew
  Halberstadt drove this.</p>
</li>
</ul>
<h2>Current status of the build bystem</h2>
<p>Q3 was a very significant quarter for the build system. For the first
time in years, we made fundamental changes to how the build system
goes about building. The moz.build work to free our build config from
the shackles of make files had enabled us to consume that data and do
new and novel things with it. This has enabled improvements in build
robustness and - most importantly - speed.</p>
<p>This is most evident with the MOZ_PSEUDO_DERECURSE work, which
effectively replaces how make traverses directories. The work there
has allowed Gecko developers focused on libxul to go from e.g. 50s
no-op build times to less than 5s. Combined with optimized building
of XPIDL, IPDL, and WebIDL files, processing of file installs via
manifests, and C++ header dependency reduction, and a host of other
changes, and we are finally turning a corner on build times! Much of
this work wouldn't have been possible without moz.build files providing
a whole world view of our build config.</p>
<p>The quarter wasn't all roses. Unfortunately, we also broke things. A lot.
The total number of required clobbers this quarter grew slightly from
38 in Q2 to 43 in Q3. Many of these clobbers were regressions from
supposed improvements to the build system. Too many of these
regressions were Windows/pymake only and surely would have been found
prior to landing if more build peers were actively building on Windows.
There are various reasons we aren't. We should strive to fix them so
more build development occurs on Windows and Windows users aren't
unfairly punished.</p>
<p>The other class of avoidable clobbers mostly revolves
around the theme that <em>the build system is complicated</em>, particularly
when it comes to integration with release automation. Build automation
has its build logic currently coded in Buildbot config files. This means
it's all but impossible for build peers to test and reproduce that build
environment and flow without time-intensive, stop-energy abundant
excessive try pushes or loading out build slaves. The RelEng effort
to extract this code from buildbot to mozharness can't come soon enough. See
<a href="/blog/2013/07/16/analysis-of-firefox%27s-build-automation/">my overview</a>
on how automation works for more.</p>
<p>This quarter, the sheriffs have been filing bugs whenever a clobber is
needed. This has surfaced clobber issues to build peers better and I
have no doubt their constant pestering caused clobber issues to be
resolved sooner. It's a terrific incentive for us to fix the build
system.</p>
<p>I have mixed feelings on the personnel/contribution front in Q3. Kyle
Huey no longer participates in active build system development or patch
review. Ted Mielczarek is also starting to drift away from active coding
and review. Although, he does constantly provide knowledge and historical
context, so not all is lost. It is disappointing to see fantastic
people and contributors no longer actively participating on the coding
front. But, I understand the reasons behind it. Mozilla doesn't have a
build team with a common manager and decree (a mistake if you ask me).
Ted and Kyle are both insanely smart and talented and they work for
teams that have other important goals. They've put in their time (and
suffering). So I see why they've moved on.</p>
<p>On the plus side, Mike Hommey has been spending a lot more time on build
work. He was involved in many of the improvements listed above. Due to
review load and Mike's technical brilliance, I don't think many of our
accomplishments would have happened without him. If there is one
Mozillian who should be commended for build system work in Q3, it should
be Mike Hommey.</p>
<p>Q3 also saw the addition of new build peers. Mike Shal is now a full
build config module peer. Nick Alexander is now a peer of a submodule
covering just the Fennec build system. Aside from his regular patch
work, Mike Shal has been developing his review skills and
responsibilities. Without him, we would likely be drowning in review
requests and bug investigations due to the departures of Kyle and Ted.
Nick is already doing what I'd hope he'd do when put in charge of the
Fennec build system: looking at a proper build backend for Java (not
make) and Eclipse project generation. (I still can't believe many of
our Fennec developers code Java in vanilla text editors, not powerful
IDEs. If there is one language that would miss IDEs the most, I'd think
it would be Java. Anyway.)</p>
<p>There was a steady stream of contributions from people not in the build
config module. Joshua Cranmer has been keeping up with moz.build
conversions for comm-central. Nathan Froyd and Boris Zbarsky have helped
with all kinds of IDL work. Trevor Saunders has helped keep things
clean. Ms2ger has been eager to provide assistance through code and
reviews. Various community contributors have helped with moz.build
conversion patches and improvements to mach and the bootstrapper. Thank
you to everyone who contributed last quarter!</p>
<h2>Looking to the future</h2>
<p>At the beginning of the quarter, I didn't think it would be possible
to attain no-op build speeds with make as quickly as <em>make binaries</em> now
does. But, Mike Hommey worked some magic and this is now possible.
This was a game changer. The code he wrote can be applied to other
build actions. And, our other solutions involving moz.build files to
autogenerated make files seems to be working pretty well too.
This raises some interesting questions with regards to priortization.</p>
<p>Long term, we know we want to move away from make. It is old
and clumsy. It's easy to do things wrong. It doesn't scale to handle a
single DAG as large as our build system. The latter is particularly
important if we are to ever have a build system that doesn't require
clobbers periodically.</p>
<p>Up to this point we've prioritized work on moz.build conversion, with
the rationale being that it would more soon enable a clean break from
make and thus we'd arrive at drastically faster builds sooner. The assumption in that
argument was that drastically faster builds weren't attainable with
make. Between the directory traversal overhaul and the release of GNU
make 4.0 last week (which actually seems to work on Windows, making the
pymake slowness a non-issue), the importance of breaking away from make
now seems much less pressing.</p>
<p>While we would like to actively move off make, developments in the past
few weeks seem to say that we can reassess priorities. I believe that we
can drive down no-op builds with make to a time that satisfies many -
let's say under 10s to be conservative. Using clever tricks optimizing
for common developer workflows, we can probably get that under 5s
everywhere, including Windows (people only caring about libxul can
get 2.5s on mozilla-central today). This isn't the 250ms we could get
with Tup. But it's much better than 45s. If we got there, I don't think
many people would be complaining.</p>
<p>So, the big question for goals setting this quarter will be whether we
want to focus on a new build backend (likely Tup) or whether we should
continue with an emphasis on make. Now, a lot of the work involved
applies to both make and any other build backend. But, I have little
doubt it would be less overall work to support one build backend (make)
than two. On the other hand, we know we want to support multiple build
backends eventually. Why wait? In the balance are
<a href="https://etherpad.mozilla.org/build-system-goals">numerous other projects</a>
that have varying impact for developers and release automation. While
important in their own right, it is difficult to balance them against
build speed. While we could strive towards instantaneous builds, at some
point we'll hit <em>good enough</em> and the diminishing returns that accompany
them. There is already a small vocal faction advocating for Ninja
support, even though it would only decrease no-op libxul build times
from ~2.5s to 250ms. While a factor of 10x improvement, I think this is
dangerously close to diminishing returns territory and our time
investment would be better spent elsehwere. (Of course, once we can
support building libxul with Ninja, we could easily get it for Tup. And,
I believe Tup wins that tie.). Anyway, I'm sure it will be an
interesting discussion!</p>
<p>Whatever the future holds, it was a good quarter for the build system and
the future is looking brighter than ever. We have transitioned from a
maintain-and-react mode (which I understand has largely been the norm
since the dawn of Firefox) to a proactive and future-looking approach
that will satisfy the needs of Firefox and its developers for the next
ten years. All of this progress is even more impressive when you consider
that we still react to an aweful lot of fire drills and unwanted
maintenance!</p>
<p>The Firefox build system is improving. I'm as anxioux as you are to see
various milestones in terms of build speed and other features. But it's
hard work. Wish us luck. Please help out where you can.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Build System Status Update 2013-05-14]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/05/13/build-system-status-update-2013-05-14" />
    <id>http://gregoryszorc.com/blog/2013/05/13/build-system-status-update-2013-05-14</id>
    <updated>2013-05-13T19:35:00Z</updated>
    <published>2013-05-13T19:35:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[Build System Status Update 2013-05-14]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/05/13/build-system-status-update-2013-05-14"><![CDATA[<p>I'd like to make an attempt at delivering regular status updates on the
Gecko/Firefox build system and related topics. Here we go with the
first instance. I'm sure I missed awesomeness. Ping me and I'll add it
to the next update.</p>
<h2>MozillaBuild Windows build environment updated</h2>
<p>Kyle Huey
<a href="https://groups.google.com/d/msg/mozilla.dev.platform/XRecAHF-H28/aSbrdKJLUNoJ">released version 1.7</a>
of our Windows build environment. It contains a newer version of Python
and a modern version of Mercurial among other features.</p>
<p><strong>I highly recommend every Windows developer update ASAP.</strong> Please note
that you will likely encounter Python errors unless you clobber your
build.</p>
<h2>New submodule and peers</h2>
<p>I used my power as module owner to create a submodule of the build
config module whose scope is the (largely mechanical) transition of
content from Makefile.in to moz.build files. I granted Joey Armstrong
and Mike Shal peer status for this module. I would like to eventually
see both elevated to build peers of the main build module.</p>
<h2>moz.build transition</h2>
<p>The following progress has been made:</p>
<ul>
<li>Mike Shal has converted variables related to defining XPIDL files in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=818246">bug 818246</a>.</li>
<li>Mike Shal converted MODULE in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844654">bug 844654</a>.</li>
<li>Mike Shal converted EXPORTS in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=846634">bug 846634</a>.</li>
<li>Joey Armstrong converted xpcshell test manifests in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844655">bug 844655</a>.</li>
<li>Brian O'Keefe converted PROGRAM in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=862986">bug 862986</a>.</li>
<li>Mike Shal is about to land conversion of CPPSRCS in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=864774">bug 864774</a>.</li>
</ul>
<h2>Non-recursive XPIDL generation</h2>
<p>In <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=850380">bug 850380</a>
I'm trying to land non-recursive building of XPIDL files. As part of
this I'm trying to combine the generation of .xpt and .h for each input
.idl file into a single process call because profiling revealed that
parsing the IDL consumes most of the CPU time. This shaves a few dozen
seconds off of build times.</p>
<p>I have encounterd multiple pymake bugs when developing this patch, which
is the primary reason it hasn't landed yet.</p>
<h2>WebIDL refactoring</h2>
<p>I was looking at my build logs and noticed WebIDL generation was taking
longer than I thought it should. I filed
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=861587">bug 861587</a> to
investigate making it faster. While my initial profiling turned out to
be wrong, Boris Zbarsky looked into things and discovered that the
serialization and deserialization of the parser output was extremely
slow. He is currently trying to land a refactor of how WebIDL bindings
are handled. The early results look <strong>very</strong> promising.</p>
<p>I think the bug is a good example of the challenges we face improving
the build system, as Boris can surely attest.</p>
<h2>Test directory reorganization</h2>
<p>Joel Maher is injecting sanity into the naming scheme of test
directories in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=852065">bug 852065</a>.</p>
<h2>Manifests for mochitests</h2>
<p>Jeff Hammel, Joel Maher, Ted Mielczarek, and I are working out using
manifests for mochitests (like xpcshell tests) in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=852416">bug 852416</a>.</p>
<h2>Mach core is now a standalone package</h2>
<p>I extracted the mach core to a
<a href="https://github.com/indygreg/mach">standalone repository</a> and
<a href="https://pypi.python.org/pypi/mach/">added it to PyPI</a>.</p>
<p>Mach now <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=856392">categorizes</a>
commands in its help output.</p>
<h2>Requiring Python 2.7.3</h2>
<p>Now that the Windows build environment ships with Python 2.7.4, I've
filed <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=870420">bug 870420</a>
to require Python 2.7.3+ to build the tree. We already require
Python 2.7.0+. I want to bump the point release because there are
<a href="http://hg.python.org/cpython/file/d46c1973d3c4/Misc/NEWS">many</a> small
bug fixes in 2.7.3, especially around Python 3 compatibility.</p>
<p>This is currently blocked on RelEng rolling out 2.7.3 to all the
builders.</p>
<h2>Eliminating master xpcshell manifest</h2>
<p>Now that xpcshell test manifests are defined in moz.build files, we
theoretically don't need the master manifest. Joshua Cranmer is working
on removing them in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=869635">bug 869635</a>.</p>
<h2>Enabling GTests and dual linking libxul</h2>
<p>Benoit Gerard and Mike Hommey are working in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844288">bug 844288</a> to
dual link libxul so GTests can eventually be enabled and executed as
part of our automation.</p>
<p>This will regress build times since we need to link libxul twice. But,
giving C++ developers the ability to write unit tests with a real
testing framework is worth it, in my opinion.</p>
<h2>ICU landing</h2>
<p>ICU was briefly enabled in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=853301">bug 853301</a> but
then backed out because it broke cross-compiling. It should be on track
for enabling in Firefox 24.</p>
<h2>Resource monitoring in mozbase</h2>
<p>I <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=802420">gave mozbase</a>
a class to record system resource usage. I plan to eventually hook this
up to the build system so the build system records how long it took to
perform key events. This will give us better insight into slow and
inefficient parts of the build and will help us track build system speed
improvements over time.</p>
<h2>Sorted lists in moz.build files</h2>
<p>I'm working on requiring lists in moz.build be sorted. Work is happening
in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=863069">bug 863069</a>.</p>
<p>This idea started as a suggestion on the dev-platform list. If anyone
has more great ideas, don't hold them back!</p>
<h2>Smartmake added to mach</h2>
<p>Nicholas Alexander
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=677452">taught mach</a> how
to build intelligently by importing some of Josh Matthews' smartmake
tool's functionality into the tree.</p>
<h2>Source server fixed</h2>
<p>Kyle Huey and Ted Mielczarek
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=846864">collaborated</a> to
fix the source server.</p>
<h2>Auto clobber functionality</h2>
<p>Auto clobber functionality was added to the tree. After flirting briefly
with on-by-default, we changed it to opt-in. When you encounter it, it
will tell you how to enable it.</p>
<h2>Faster clobbers on automation</h2>
<p>I was looking at build logs and identified we were inefficiently
performing clobber.</p>
<p>Massimo Gervasini and Chris AtLee
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=851270">deployed changes</a>
to automation to make it more efficient. My measurements showed a
Windows try build that took 15 fewer minutes to start - a <em>huge</em>
improvement.</p>
<h2>Upgrading to Mercurial 2.5.4</h2>
<p>RelEng is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=741353">tracking</a>
the global deployment of Mercurial 2.5.4. hg.mozilla.org is
currently running 2.0.2 and automation is all over the map. The upgrade
should make Mercurial operations faster and more robust across the
board.</p>
<p>I'm considering adding code to mach or the build system that prompts the
user when her Mercurial is out of date (since an out of date Mercurial
can result in a sub-par user experience).</p>
<h2>Parallelize reftests</h2>
<p>Nathan Froyd is
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=813742">leading an effort</a>
to parallelize reftest execution. If he pulls this off, it could shave
hours off of the total automation load per checkin. Go Nathan!</p>
<h2>Overhaul of MozillaBuild in the works</h2>
<p>I am mentoring a pair of interns this summer. I'm still working out the
final set of goals, but I'm keen to have one of them overhaul the
MozillaBuild Windows development environment. Cross your fingers.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Mozilla Build System Brain Dump]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump" />
    <id>http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump</id>
    <updated>2013-05-13T17:25:00Z</updated>
    <published>2013-05-13T17:25:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="Firefox" />
    <category scheme="http://gregoryszorc.com/blog" term="mach" />
    <summary type="html"><![CDATA[Mozilla Build System Brain Dump]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump"><![CDATA[<p>I hold a lot of context in my head when it comes to the future of
Mozilla's build system and the interaction with it. I wanted to
perform a brain dump of sorts so people have an idea of where I'm
coming from when I inevitably propose radical changes.</p>
<h2>The sad state of build system interaction and the history of mach</h2>
<p>I believe that Mozilla's build system has had a poor developer
experience for as long as there has been a Mozilla build system.
Getting started with Firefox development was a rite of passage. It
required following (often out-of-date) directions on MDN. It
required finding pages through MDN search or asking other people
for info over IRC. It was the kind of process that turned away
potential contributors because it was just too damn hard.</p>
<p>mach - while born out of my initial efforts to radically change
the build system proper - morphed into a generic command
dispatching framework by the time it landed in mozilla-central.
It has one overarching purpose: provide a single gateway point for
performing common developer tasks (such as building the tree and
running tests). The concept was nothing new - individual developers
had long coded up scripts and tools to streamline workflows. Some
even published these for others to use. What set mach apart was a
unified interface for these <em>commands</em> (the mach script in the
top directory of a checkout) and that these productivity gains
were <strong>in the tree</strong> and thus easily discoverable and usable by
<em>everybody</em> without significant effort (just run <em>mach help</em>).</p>
<p>While mach doesn't yet satisfy everyone's needs, it's slowly
growing new features and making developers' lives easier with
every one. All of this is happening despite that there
is not a single person tasked with working on mach full time.
Until a few months ago, mach was largely my work. Recently, Matt
Brubeck has been contributing a flurry of enhancements - thanks
Matt! Ehsan Akhgari and Nicholas Alexander have contributed a
few commands as well! There are also a few people with a single
command to their name. This is fulfilling my original vision of
facilitating developers to scratch their own itches by
contributing mach commands.</p>
<p>I've noticed more people referencing mach in IRC channels. And,
more people get angry when a mach command breaks or changes
behavior. So, I consider the mach experiment a success. Is it
perfect, no. If it's not good enough for you, please file a bug
and/or code up a patch. If nothing else, please tell me: I love to
know about everyone's subtle requirements so I can keep them in
mind when refactoring the build system and hacking on mach.</p>
<h2>The object directory is a black box</h2>
<p>One of the ideas I'm trying to advance is that the object directory
should be considered a black box for the majority of developers. In
my ideal world, developers don't need to look inside the object
directory. Instead, they interact with it through condoned and
supported tools (like mach).</p>
<p>I say this for a few reasons. First, as the build config module owner
I would like the ability to massively refactor the <em>internals</em> of
the object directory without disrupting workflows. If people are
interacting directly with the object directory, I get significant
push back if things change. This inevitably holds back much-needed
improvements and triggers resentment towards me, build peers, and
the build system. Not a good situation. Whereas if people are
indirectly interacting with the object directory, we simply need to
maintain a consistent interface (like mach) and nobody should care
if things change.</p>
<p>Second, I believe that the methods used when directly interacting
with the object directory are often sub-par compared with going
through a more intelligent tool and that productivity suffers as a
result. For example, when you type <em>make</em> in inside the object
directory you need to know to pass <em>-j8</em>, use make vs pymake,
and that you also need to build <em>toolkit/library</em>, etc.
Also, by invoking make directly, you bypass other handy features,
such as automatic compiler warning aggregation (which only happens
if you invoke the build system through mach). If you go through a
tool like <em>mach</em>, you <em>should</em> automatically get the most ideal
experience possible.</p>
<p>In order for this vision to be realized, we need massive
improvements to tools like mach to cover the missing workflows that
still require direct object directory interaction. We also need people
to start using mach. I think increased mach usage comes after mach
has established itself as obviously superior to the alternatives
(I already believe it offers this for tasks like running tests).</p>
<h2>I don't want to force mach upon people but...</h2>
<p>Nobody likes when they are forced to change a process that has been
familiar for years. Developers especially. I get it. That's why
I've always attempted to position mach as an alternative to
existing workflows. If you don't like mach, you can always fall
back to the previous workflow. Or, you can improve mach (patches
more than welcome!). Having gone down the
please-use-this-tool-it's-better road before at other
organizations, I strongly believe that the best method to incur
adoption of a new tool is to gradually sway people through
obvious superiority and praise (as opposed to a mandate to switch).
I've been trying this approach with mach.</p>
<p>Lately, more and more people have been saying things like
<em>we should have the build infrastructure build through mach
instead of client.mk</em> and <em>why do we need testsuite-targets.mk when
we have mach commands.</em> While I personally feel that client.mk
and testsuite-targets.mk are antiquated as a developer-facing
interface compared to mach, I'm reluctant to eliminate them because
I don't like forcing change on others. That being said, there are
compelling reasons to eliminate or at least refactor how they work.</p>
<p>Let's take <em>testsuite-targets.mk</em> as an example. This is the make
file that provides the targets to run tests (like <em>make xpcshell-test</em>
and <em>make mochitest-browser-chrome</em>). What's interesting about this
file is that it's only used in local builds: our automation
infrastructure does not use <em>testsuite-targets.mk</em>! Instead,
<em>mozharness</em> and the old buildbot configs manually build up the
command used to invoke the test harnesses. Initially, the mach
commands for running tests simply invoked make targets defined
in <em>testsuite-targets.mk</em>. Lately, we've been converting the mach
commands to invoke the Python test runners directly. I'd argue that
the logic for <em>invoke the test runner</em> only needs to live in one
place in the tree. Furthermore as a build module peer, I have little
desire to support multiple implementations. Especially considering
how fragile they can be.</p>
<p>I think we're trending towards an outcome where mach (or the code
behind mach commands) transitions into the authoratitive invocation
method and <em>legacy</em> interfaces like <em>client.mk</em> and
<em>testsuite-targets.mk</em> are reimplemented to either call mach
commands or the same routine that powers them. Hopefully this
will be completely transparent to developers.</p>
<h2>The future of mozconfigs and environment configuration</h2>
<p><em>mozconfig</em> files are shell scripts used to define variables consumed
by the build system. They are the only officially supported mechanism
for configuring how the build system works.</p>
<p>I'd argue mozconfig files are a mediocre solution at best. First,
there's the issue of mozconfig statements that don't actually do
anything. I've seen no-op mozconfig content cargo culted into the
in-tree mozconfigs (used for the builder configurations)! Oops.
Second, doing things in mozconfig files is just awkward. Defining
the object directory requires <em>mk_add_options MOZ_OBJDIR=some-path</em>.
What's <em>mk_add_options</em>? If <em>some-path</em> is relative, what is it
relative <em>to</em>? While certainly addressable, the documentation on
how mozconfig files work is not terrific and fails to explain many
pitfalls. Even with proper documentation, there's still the issue
of the file format allowing no-op variable assignments to persist.</p>
<p>I'm very tempted to reinvent build configuration as something not
mozconfigs. What exactly, I don't know. mach has support for ini-like
configuration files. We could certainly have mach and the build
system pull configs from the same file.</p>
<p>I'm not sure what's going to happen here. But deprecating mozconfig
files as they are today is part of many of the options.</p>
<h2>Handling multiple mozconfig files</h2>
<p>A lot of developers only have a single mozconfig file (per source tree
at least). For these developers, life is easy. You simply install
your mozconfig in one of the default locations and it's automagically
used when you use mach or client.mk. Easy peasy.</p>
<p>I'm not sure what the relative numbers are, but many developers
maintain multiple mozconfig files per source tree. e.g. they'll
have one mozconfig to build desktop Firefox and another one for
Android. They may have debug variations of each.</p>
<p>Some developers even have a single mozconfig file but leverage the
fact that mozconfig files are shell scripts and have their
mozconfig dynamically do things depending on the current working
directory, value of an environment variable, etc.</p>
<p>I've also seen wrapper scripts that glorify setting environment
variables, changing directory, etc and invoke a command.</p>
<p>I've been thinking a lot about providing a common and well-supported
solution for switching between active build configurations.
<a href="https://developer.mozilla.org/en-US/docs/Developer_Guide/mach#Adding_mach_to_your_shell%27s_search_path">Installing mach on $PATH</a>
goes a long way to facilitate this. If you are in an object
directory, the mozconfig used when that object directory was
created is automatically applied. Simple enough. However, I want
people to start treating object directories as black boxes. So, I'd
rather not see people have their shell inside the object directory.</p>
<p>Whenever I think about solutions, I keep arriving at a
virtualenv-like solution. Developers would potentially need to
<em>activate</em> a Mozilla build environment (similar to how Windows
developers need to launch MozillaBuild). Inside this environment,
the shell prompt would contain the name of the current build
configuration. Users could switch between configurations using
<em>mach switch</em> or some other magic command on the $PATH.</p>
<p>Truth be told, I'm skeptical if people would find this useful. I'm
not sure it's that much better than exporting the MOZCONFIG
environment variable to define the active config. This one requires
more thought.</p>
<h2>The integration between the build environment and Python</h2>
<p>We use Python extensively in the build system and for common
developer tasks. mach is written in Python. moz.build processing
is implemented in Python. Most of the test harnesses are written in
Python.</p>
<p>Doing practically anything in the tree requires a Python
interpreter that knows about all the Python code in the tree and
how to load it.</p>
<p>Currently, we have two very similar Python environments. One is
a virtualenv created while running configure at the beginning of
a build. The other is essentially a cheap knock-off that mach
creates when it is launched.</p>
<p>At some point I'd like to consolidate these Python environments.
From any Python process we should have a way to automatically
bootstrap/activate into a well-defined Python environment. This
certainly sounds like establishing a unified Python virtualenv
used by both the build system and mach.</p>
<p>Unfortunately, things aren't straightforward. The virtualenv today
is constructed in the object directory. How do we determine the
current object directory? By loading the mozconfig file. How do we
do that? Well, if you are mach, we use Python. And, how does mach
know where to find the code to load the mozconfig file? You can
see the dilemma here.</p>
<p>A related issue is that of portable build environments. Currently, a
lot of our automation recreates the build system's virtualenv from
its own configuration (not that from the source tree). This has
and will continue to bite us. We'd <em>really</em> like to package up the
virtualenv (or at least its config) with tests so there is no
potential for discrepancy.</p>
<p>The inner workings of how we integrate with Python should be
invisible to most developers. But, I figured I'd capture it
here because it's an annoying problem. And, it's also related
to an <em>activated</em> build environment. What if we required all
developers to <em>activate</em> their shell with a Mozilla build
environment (like we do on Windows)? Not only would this solve
Python issues, but it would also facilitate simpler config
switching (outlined above). Hmmm...</p>
<h2>Direct interaction with the build system considered harmful</h2>
<p>Ever since there was a build system developers have been typing
<em>make</em> (or <em>make.py</em>) to build the tree. One of the goals of the
transition to <em>moz.build</em> files is to facilitate building the tree
with Tup. <em>make</em> will do nothing when you're not using Makefiles!
Another goal of the <em>moz.build</em> transition is to start
derecursifying the make build system such that we build things in
parallel. It's likely we'll produce monolithic make files and then
process <em>all</em> targets for a related class <em>IDLs</em>, <em>C++ compilation</em>,
etc in one invocation of <em>make</em>. So, uh, what happens during a partial
tree build? If a .cpp file from <em>/dom/src/storage</em> is being handled by
a monolithic make file invoked by the Makefile at the top of the
tree, how does a partial tree build pick that up? Does it build just
that target or every target in the monolithic/non-recursive make file?</p>
<p>Unless the build peers go out of our way to install redundant targets
in leaf Makefiles, directly invoking <em>make</em> from a subdirectory of
the tree won't do what it's done for years.</p>
<p>As I said above, I'm sympathetic to forced changes in procedure, so
it's likely we'll provide backwards-compatibile behavior. But, I'd
prefer to not do it. I'd first prefer partial-tree builds are not
necessary and a full tree build finishes quickly. But, we're not going
to get there for a bit. As an alternative, I'll take people building
through <em>mach build</em>. That way, we have an easily extensible interface
on which to build partial tree logic. We saw this recently when
dumbmake/smartmake landed. And, going through <em>mach</em> also reinforces my
ideal that the object directory is a black box.</p>
<h2>Semi-persistent state</h2>
<p>Currently, most state as it pertains to a checkout or build is in the
object directory. This is fine for artifacts from the build system.
However, there is a whole class of state that arguably shouldn't be in
the object directory. Specifically, it shouldn't be clobbered when you
rebuild. This includes logs from previous builds, the warnings database,
previously failing tests, etc. The list is only going to grow over time.</p>
<p>I'd like to establish a location for semi-persistant state related to
the tree and builds. Perhaps we change the clobber logic to ignore a
specific directory. Perhaps we start storing things in the user's home
directory. Perhaps we could establish a second <em>object directory</em> named
the <em>state directory</em>? How would this interact with <em>build environments</em>?</p>
<p>This will probably sit on the backburner until there is a compelling use
case for it.</p>
<h2>The battle against C++</h2>
<p>Compiling C++ consumes the bulk of our build time. Anything we can do to
speed up C++ compilation will work wonders for our build times.</p>
<p>I'm optimistic things like precompiled headers and compiling multiple
.cpp files with a single process invocation will drastically decrease
build times. However, no matter how much work we put in to make C++
compilation faster, we still have a giant issue: dependency hell.</p>
<p>As <a href="/presentations/2012-11-29-firefox-build-system/#34">shown</a> in my
build system presentation a few months back, we have dozens of header
files included by hundreds if not thousands of C++ files. If you change
one file: you invalidate build dependencies and trigger a rebuild. This
is why whenever files like mozilla-config.h change you are essentially
confronted with a full rebuild. ccache may help if you are lucky. But, I
fear that as long as headers proliferate the way they do, there is
little the build system by itself can do.</p>
<p>My attitude towards this is to wait and see what we can get out of
precompiled headers and the like. Maybe that makes it good enough. If
not, I'll likely be making a lot of noise at Platform meetings
requesting that C++ gurus brainstorm on a solution for reducing
header proliferation.</p>
<h2>Conclusion</h2>
<p>Belive it or not, these are only some of the topics floating around in
my head! But I've probably managed to bore everyone enough so I'll
call it a day.</p>
<p>I'm always interested in opinions and ideas, especially if they are
different from mine. I encourage you to leave a comment if you have
something to say.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[moz.build Files and the Firefox Build System]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2013/02/28/moz.build-files-and-the-firefox-build-system" />
    <id>http://gregoryszorc.com/blog/2013/02/28/moz.build-files-and-the-firefox-build-system</id>
    <updated>2013-02-28T19:45:00Z</updated>
    <published>2013-02-28T19:45:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="Firefox" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[moz.build Files and the Firefox Build System]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2013/02/28/moz.build-files-and-the-firefox-build-system"><![CDATA[<p>The next time you update mozilla-central you may notice some significant
changes with the build system. That's because this morning we finally
landed the start of a massive overhaul of the build system! There are
many end goals to this effort. The important ones for most will be
faster build times and a build system that is friendlier to make changes
to.</p>
<h2>Introducing moz.build Files</h2>
<p>If you look in the tree, you'll notice that nearly every directory
now has a <em>moz.build</em> file.</p>
<p><em>moz.build</em> files are what we are using to define the build system. Think of
them each as a descriptor that describes how to build its own part of the
tree. An individual <em>moz.build</em> file will contain the C++ sources to
compile, the headers to export, the tests to run, etc. Eventually.
Currently, they are limited to directory traversal information.</p>
<p><em>moz.build</em> files essentially add a level of indirection between the
build system definition and how the tree is actually built. Before
<em>moz.build</em> files, the same metadata we are now capturing in <em>moz.build</em>
files (or plan to capture) was captured in <em>Makefile.in</em> files. We
performed simple variable substitution on these <em>Makefile.in</em> files to
produce <em>Makefile</em> files in the object directory. These <em>Makefile</em> files
were used by GNU Make (or Pymake on Windows) to build the tree.</p>
<p>As I outlined in <a href="/blog/2012/06/25/improving-mozilla's-build-system/">Improving Mozilla's Build System</a>,
<em>Makefile.in</em> are suboptimal for a number of reasons. The important
bit is they essentially tie us to the use of make (recursive or otherwise).
We are very interested in supporting modern build systems such as Tup
(the theory being they will build the tree faster).</p>
<p>Enter <em>moz.build</em> files. Storing our build configuration in
<em>moz.build</em> files allows us to decouple the definition of the build
system from the tool used to build it.</p>
<h2>How moz.build Files Work</h2>
<p>At the tail end of <em>configure</em>, the build system invokes the
<em>config.status</em> script in the object directory. The role of
<em>config.status</em> is to combine the information collected during
<em>configure</em> with the build configuration obtained from <em>moz.build</em> files
and take the necessary actions to ensure the build backend (make) can
build the tree.</p>
<p>Before today, <em>config.status</em> essentially iterated over the source tree
and converted <em>Makefile.in</em> files to <em>Makefile</em> in the object directory.
Things are now slightly more complicated with <em>moz.build</em> files.</p>
<p>When <em>config.status</em> runs, it starts with the
<a href="https://hg.mozilla.org/mozilla-central/file/87de54667483/moz.build">root moz.build</a>
from the source tree. It feeds this file into a Python interpreter. It
then looks for special variables like <em>DIRS</em> and <em>PARALLEL_DIRS</em> to determine
which directories contain additional <em>moz.build</em> files. It then descends
into all the referenced directories, reading their <em>moz.build</em> files.
While this is happening, we are converting the results of each
<em>moz.build</em> file execution into <em>backend.mk</em> files that make knows how
to build. It also performs the <em>Makefile.in</em> to <em>Makefile</em> conversion
like it always has. When the whole process has finished, the object
directory contains a bunch of <em>Makefile</em> and <em>backend.mk</em> files. make
runs like it always has. The only real difference is some variables are
coming from the <em>moz.build</em>-derived <em>backend.mk</em> files instead of
<em>Makefile</em>.</p>
<p>This is just a brief overview, of course. If you want to know more,
see the code in <em>/python/mozbuild/mozbuild/frontend</em> and
<em>/python/mozbuild/mozbuild/backend</em>.</p>
<h2>Build System Future</h2>
<p>With the introduction of <em>moz.build</em> files, the intent is to <strong>eventually
completely eliminate Makefile.in and have all the build definition live
in moz.build files.</strong></p>
<p>Doing this all at once would have been next to impossible. So, we
decided to eliminate <em>Makefile.in</em> gradually. The first step is what
landed today: essentially moving <em>DIRS</em> variables out of <em>Makefile.in</em>
and into <em>moz.build</em> files. Next, we will be eliminating empty
<em>Makefile.in</em> (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844635">bug 844635</a>)
and will be moving more parts of the build definition from <em>Makefile.in</em>
to <em>moz.build</em> files. The next part to move over will likely be IDLs
(<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=818246">bug 818246</a>).
After that, it may be exported files (<em>EXPORTS</em> in <em>Makefile.in</em>
parlance). And repeat until we have no more <em>Makefile.in</em> in the tree.</p>
<p>Each migration of build definition data to <em>moz.build</em> files will likely
occur in two phases:</p>
<ol>
<li>A largely mechanical move of the variables from <em>Makefile.in</em> to
   <em>moz.build</em>.</li>
<li>Better build backend integration resulting from the move.</li>
</ol>
<p>In phase #1, we will essentially cut and paste variable assignments to
<em>moz.build</em> files. make will read the same variables it does today and
perform the same actions. The only difference is the values in these
variables will be defined in <em>moz.build</em> files.</p>
<p>In phase #2, we will leverage the fact that our build definition now has
an API. We will change our existing make backend to be more efficient.
For example, we should soon be able to compile IDLs and copy exported
headers without make traversing through the directory tree at build time.
We will be able to do this because the <em>moz.build</em> traversal at
pre-build time sees data from all <em>moz.build</em> files and with this
<em>complete world view</em> is able to produce more optimal make files than
what you would get if you recursed into multiple directories. In short:
it will make the build faster.</p>
<p>Once we have a sufficient portion of the build definition moved to
<em>moz.build</em> files we will be able to experiment with new build backends
(like Tup), look into automatic Visual Studio project generation, and
more easily experiment with different ways of building (such as
precompiled headers, fewer compiler process invocations, etc). These
should all contribute to faster build times.</p>
<h2>Frequently Asked Questions</h2>
<h4>What impact will I see from this change?</h4>
<p>If you never touched <em>Makefile.in</em> files in the tree, you should not
notice anything different about how the tree builds or how the build
system works. You should have nothing to fear.</p>
<p>The most obvious changes to the source tree are:</p>
<ol>
<li>There is a <em>moz.build</em> file in almost every directory now.</li>
<li>The variables related to directory traversal (those containing <em>DIRS</em>
   in their name) are now defined in <em>moz.build</em> files instead of
   <em>Makefile.in</em>.</li>
<li>If your <em>Makefile.in</em> contains a variable that has been moved to
   <em>moz.build</em> files, make will spew an error when processing that file
   and the build will fail.</li>
</ol>
<h4>Will this change how I build?</h4>
<p>It shouldn't. You should build the tree just like you always have. Most
of you won't notice any differences.</p>
<p>If you see something weird, speak up in #build or file a bug if you are
really confident it is wrong.</p>
<h4>What are the risks to this change?</h4>
<p>The migration of variables from <em>Makefile.in</em> to <em>moz.build</em> files is
largely mechanical and significant portions are done manually. This can
be a mind-numbing and tedious process. Not helping things is the fact
that Splinter's review interface for these kinds of patches is hard to
read.</p>
<p>This all means that there is a non-trivial risk for <em>transcription</em>
errors. All it takes is an inverted conditional block and all of a
sudden large parts of the tree are no longer built, for example.</p>
<p>We have established <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=846425">bug 846825</a>
to investigate any oddities from the initial transfer. Developers are
encouraged to help with the effort. Please spot check that your
directories are still being built, tests run, etc. Pay special attention
to changes made in the last 4 months as these parts of <em>Makefile.in</em>
would have been bit rotted and more prone to data loss.</p>
<p>Parts of the tree not enabled in standard configurations are more prone
to breakage due to less testing. i.e. build configurations not captured
by TBPL have a higher chance of breaking.</p>
<h4>Will this make the tree build faster?</h4>
<p>Not yet. But eventually it will. This initial landing paves the
groundwork to making the tree build faster (see the <em>Future</em> section
above).</p>
<h4>I see a lot of empty moz.build files!</h4>
<p>Yes. Sorry about that. The good news is they shouldn't be empty for
long. As things move from <em>Makefile.in</em> to <em>moz.build</em> we'll see fewer
and fewer empty <em>moz.build</em> files. We'll also see fewer and fewer
<em>Makefile.in</em> files once we start deleting empty <em>Makefile.in</em>.</p>
<p>If you want to know why we must have empty files, it's mainly for
validation. If we allowed <em>moz.build</em> files to be optional, how would
you detect a typo in a directory name? Directory exists? What if that
directory exists but isn't supposed to have a <em>moz.build</em> file?</p>
<h4>You bitrotted my patches!</h4>
<p>Yes. I'm sorry. The transition period to <em>moz.build</em> files could be a
little messy. There will be lots of changes to <em>Makefile.in</em> and
<em>moz.build</em> files and lots of chances for bit rot. Uplifts could be
especially nasty. (Although I don't believe many uplifts involve
significant changes to the build configuration.)</p>
<p>This all means there is a strong incentive for us to complete the
transition as quickly as possible.</p>
<h4>Can I help with the transition to moz.build files?</h4>
<p>Yes!</p>
<p>The transition is largely mechanical (at least phase #1). If you are
interested in moving a variable or set of variables, hop in #build on
IRC and speak up!</p>
<h4>You said moz.build files are actually Python files?!</h4>
<p>Yes they are! However, they are executed in a very tightly controlled
sandbox. You can't import modules, open files, etc. UPPERCASE variable
names are reserved and only a few functions are exposed. If you attempt
to assign to an unknown UPPERCASE variable or assign an invalid value,
an error will occur. This is already much better than Makefile because
we can now detect errors earlier in the build process (rather than 15
minutes into a build).</p>
<h4>What variables and functions are available in moz.build files?</h4>
<p>If you run |./mach mozbuild-reference| you will see a print-out of
all the variables, functions, and symbols that are exposed to the Python
sandbox that moz.build files execute in. There are even tests that will
fail the build if the sandbox contains symbols not in this output!</p>
<p>The output should be valid reSTructuredText (in case you want to convert
to HTML for reading in your browser).</p>
<h4>What if a moz.build file contains an error?</h4>
<p>The build will break.</p>
<p>A lot of work has gone into making the output of moz.build errors human
friendly and actionable. If you do something wrong, it won't just
complain: it will tell you how to fix it!</p>
<h4>Besides build times, how else will this improve the build system?</h4>
<p>There are several ways!</p>
<p>As mentioned above, moz.build are more strict about what data is allowed
to be defined. If you assign to an UPPERCASE variable, that variable
must be known to the sandbox or else the assignment will error. This
means that if you assign to an UPPERCASE variable, you know it has a
side-effect. No more cargo culting of old, meaningless variables!</p>
<p>To change the behavior of moz.build files (add new variables or
functions, change how makefile generation works, etc) will require
changes to the code in /python/mozbuild. This code belongs squarely to
the build module and requires appropriate review. A problem with
Makefiles is that they have lots of foot guns by default and its easy
for self-inflicted wounds to land in the tree without explicit build
peer review. This problem largely goes away with moz.build files because
the sandbox takes away all of make's foot guns.</p>
<p>The output of a moz.build execution is essentially a static data
structure. It's easy to validate them for conformance. If we discover
bad practices in our build definition, we can centrally add tests for
them and enforce best practices.</p>
<p>We will also see user experience wins by moving data to moz.build files.
Take mochitests for an example. We currently have several flavors
(plain, browser, chrome, etc). Sometimes you cannot distinguish the
flavor by the filename alone. With moz.build files, it will be easier to
answer questions like "what mochitest flavor is this file?" mach could
hook into this so you can type |mach mochitest path/to/file.html|
instead of |mach mochitest-plain path/to/file.html|. Even better, you
should just be able to type |mach path/to/test.html| and mach knows from
the build definition that path/to/test.html is a plain mochitest file
and assumes you want to run it. There are dozens of small development
workflow wins to be gained here!</p>
<h4>If I change a moz.build file, what happens?</h4>
<p>If you change a moz.build file, then make should detect that it
has changed and it will update the dynamically generated <em>backend.mk</em>
file and reinvoke the requested build action. This should all happen
automatically (just like <em>Makefile.in</em> to <em>Makefile</em> conversion works
automatically).</p>
<h4>My build seems to pause for a few seconds before starting!</h4>
<p>A change to <em>any</em> moz.build file will cause a full traversal of the
entire moz.build tree. On modern machines, this should only take 1-3
seconds. If your source tree is not in the page cache (and you need
to load moz.build files from disk) or if you are on older hardware, this
could be a little slower.</p>
<p>This is an unfortunate side-effect of having a whole world view of the
build definition. The build delay incurred by these full scans should
eventually be cancelled out by build backend optimizations resulting
from having this whole world view, however.</p>
<p>The good news is this full scan should only occur if a mozbuild file
changes. And, if you are performing make recursion, it should only
happen once (not in every directory). If you notice multiple moz.build
scanning-related pauses during builds, please file a bug in Core ::
Build Config!</p>
<p>Finally, we are performing the reads on a single thread currently. We
can throw more cores at the task if someone codes up a patch.</p>
<h4>What happened to allmakefiles.sh?</h4>
<p>It has been sacked. allmakefiles.sh was an optimization to perform all
the Makefile.in to Makefile conversion in one go. The directory
traversal performed by moz.build reading effectively replaces the role
of allmakefiles.sh. Not only that, but the moz.build build definition is
always up to date! allmakefiles.sh was typically out of sync with
reality and was a burden to maintain.</p>
<h4>Did we just invent our own build system?</h4>
<p>Kinda. We invented a generic Python sandboxing infrastructure. Then we
hooked up code to populate it with variables from our build system and
told it how to perform file traversal by reading specific variables set
during file execution. Then we hooked up code for taking the evaluated
results of all those sandboxes and convert them into make files.</p>
<p>Conceptually, what we invented is like GYP but with a different config
file format. We have dabbled with the idea of converting the parsed
build definition into GYP classes and then leveraging GYP to produce
Makefiles, Ninja files, Visual Studio Projects, etc. This would an
interesting experiment!</p>
<p>If you want to call it a build system, call it a build system. However,
it is currently tightly coupled to Mozilla's needs, so you can't just
use it anywhere. The concept might be worth exploring, however.</p>
<h4>Is there anything else you'd like to share?</h4>
<p>I think we set the record for most parts in a bug: 61. Although, they
are numbered 1-17, 19-20. Part 18 has 30+ sub-parts using letters from
the English and Greek alphabet for identifiers. Part 61 uses the
infinity symbol as its number. See the
<a href="https://hg.mozilla.org/mozilla-central/pushloghtml?changeset=c65d59d33aa8">pushlog</a>.</p>
<p>Finally, I'd like to thank everyone who helped with this effort. The bug
itself was <em>only</em> 6 months old and had active development off and on for
a lot of it. Ted Mielczarek and Mike Hommey provided invaluable feedback
on the core build system patches. A number of module owners stepped in
to lend eyes to the mechanical conversion of their files. Last but not
least, Ms2ger provided invaluable review aid on many of the patches. The
work was so good that we all agreed that an Ms2ger f+ was good enough
for a build peer rs! If reviewing the patches wasn't enough, Ms2ger
also oversaw the tree closure and merging of the landing. I don't know
how I will repay this debt.</p>
<h4>Any more questions?</h4>
<p>If you have more questions, drop in #build on irc.mozilla.org and ask
away.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Firefox Build System Presentation]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2012/11/30/firefox-build-system-presentation" />
    <id>http://gregoryszorc.com/blog/2012/11/30/firefox-build-system-presentation</id>
    <updated>2012-11-30T14:00:00Z</updated>
    <published>2012-11-30T14:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="Firefox" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[Firefox Build System Presentation]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2012/11/30/firefox-build-system-presentation"><![CDATA[<p>In case you missed it, I gave a presentation on the state of Firefox's
build system yesterday.</p>
<p>You can <a href="https://air.mozilla.org/the-future-of-the-firefox-build-system/">watch</a>
it and <a href="http://gregoryszorc.com/presentations/2012-11-29-firefox-build-system/#1">view</a>
the slides online.</p>
<p>If you build Firefox from source regularly, you should definitely at
least skim through the slide deck.</p>
<p>I'm not an HTML expert, so my apogolies for bad UI on the interactive
slides. You may need to press <strong>enter</strong> to select items in
dropdown menus. Also, the interactive slides are a bit resource
intensive. If the slide deck is really slow, turn off those elements.
I've also only tested the slides in Firefox 19 and 20. My apologies if
they don't work everywhere.</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Visual Studio Project Generation for mozilla-central]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central" />
    <id>http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central</id>
    <updated>2012-08-28T12:00:00Z</updated>
    <published>2012-08-28T12:00:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="Firefox" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[Visual Studio Project Generation for mozilla-central]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central"><![CDATA[<p>I have very alpha support for Visual Studio project generation for
mozilla-central that daring people can dogfood.</p>
<p>I want to emphasize that this is extremely alpha. Normally, I wouldn't
release things as fragile as they are. But, I know Windows developers
sorely miss Visual Studio, especially IntelliSense. The current Visual
Studio projects support IntelliSense, so I want to get this in the hands
of Windows developers ASAP.</p>
<p>The current directions for making this all work are a bit hacky. Things
will change once things have matured. For now, please excuse the mess.</p>
<p>First, you will need to grab the code. If you use Git, set up a remote
to my repository:</p>
<pre><code>git remote add indygreg git://github.com/indygreg/mozilla-central.git
git fetch indygreg
</code></pre>
<p>The branch of interest is <em>build-splendid</em>. I periodically rebase this
branch on top of master. You have been warned.</p>
<p>You can switch to this branch:</p>
<pre><code>git checkout -b build-splendid indygreg/build-splendid
</code></pre>
<p>Alternatively, you can squash it down to a single commit and merge it
into your local branch. Once you've done that, you can record the SHA-1
of the commit and cherry-pick that wherever you like!</p>
<pre><code>git merge --squash indygreg/build-splendid
git commit
</code></pre>
<p>In the current state, you need to build the tree or the Visual Studio
projects will complain about missing files. It doesn't matter if you
build the tree before or after Visual Studio projects are generated.
But, we might as well get it out of the way. From your MozillaBuild
environment, run:</p>
<pre><code>./mach build
</code></pre>
<p>That should <em>just work</em>. If it doesn't, you may need to configure
mach.ini. See my <a href="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid/">previous post</a>
on how to configure mach.ini. As a reference, my Windows config is:</p>
<pre><code>[build]

configure_extra = --disable-webgl

[compiler]

[paths]
source_directory = c:\dev\src\mozilla-central-git
object_directory = c:\dev\src\mozilla-central-git\objdir
</code></pre>
<p>Now, to generate Visual Studio project files:</p>
<pre><code>./mach backendconfig visualstudio
</code></pre>
<p>That should take about a minute to finish. When it's done, it should
have created <em>objdir/msvc/mozilla.sln</em>. You should be able to load that
in Visual Studio!</p>
<p>You will need to regenerate Visual Studio project files when the build
config changes. As a rule of thumb, do this every time you pull source.
You don't need to perform a full build before you generate Visual Studio
files (you do need to perform configure, however). However, if you have
not performed a full build, Visual Studio may not be able to find some
files, like headers generated from IDLs.</p>
<p><strong>Please close the solution before regenerating the project files.</strong> If
you don't, Visual Studio puts up a modal dialog for each project file
that changed and you have to click through over a hundred of these. It's
extremely frustrating. I'm investigating workarounds.</p>
<h2>Current State</h2>
<p>Currently, it only generates projects for C/C++ compilation (libraries).
I still need to add support for IDL, headers, etc. However, each
project has proper compiler flags, header search paths, etc. So,
IntelliSense is happy and some things do manage to compile!</p>
<p>Many parts are broken and sub-par.</p>
<p>I've only tested on Visual Studio 2008. If you are running Visual Studio
\2010, you can try to upgrade the solution. This <em>may</em> work. The backend
supports generating solutions for different versions. But, I haven't
tested things work on non-2008 and I don't want to expose untested behavior.</p>
<p>Compiling within Visual Studio works for some things. On my system, I
get a lot of <em>nullptr not defined</em> errors. I'm not sure why. This will
hopefully be worked out soon.</p>
<p>If you do manager to compile within Visual Studio, the output files
don't go in the right places. So, if you do a build from the
command-line, it will have to re-compile to pick up changes.</p>
<p>Project names are based on the name of the library they produce. I'm not
sure if this is the best solution.</p>
<p>Project dependencies are not set up. They will be added later.</p>
<p>Projects for linking libxul or building firefox.exe are not yet
provided. Along the same vein, debugging support is not built-in. I'm
working on it.</p>
<p>Basically, IntelliSense works. You can now use Visual Studio as a rich
editor. Hopefully this is a step in the right direction.</p>
<p>I'm anxious to hear if this works for other people. Please leave
comments!</p>]]></content>
  </entry>
  <entry>
    <author>
      <name>Gregory Szorc</name>
      <uri>http://gregoryszorc.com/blog</uri>
    </author>
    <title type="html"><![CDATA[Build Firefox Faster with Build Splendid]]></title>
    <link rel="alternate" type="text/html" href="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid" />
    <id>http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid</id>
    <updated>2012-08-15T14:30:00Z</updated>
    <published>2012-08-15T14:30:00Z</published>
    <category scheme="http://gregoryszorc.com/blog" term="Mozilla" />
    <category scheme="http://gregoryszorc.com/blog" term="Firefox" />
    <category scheme="http://gregoryszorc.com/blog" term="build system" />
    <summary type="html"><![CDATA[Build Firefox Faster with Build Splendid]]></summary>
    <content type="html" xml:base="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid"><![CDATA[<p>Would you like to build Firefox faster? If so, do the following:</p>
<pre><code>hg qimport http://people.mozilla.org/~gszorc/build-splendid.patch
hg qpush
rm .mozconfig* (you may want to create a backup first)
./mach build
</code></pre>
<p>This should <em>just work</em> on OS X, Linux, and other Unix-style systems.
<strong>Windows support is currently broken, sorry.</strong></p>
<p><em>mach</em> can do much more than build. Run the following to see what:</p>
<pre><code>./mach --help
</code></pre>
<h2>Important Info</h2>
<p><em>mach</em> replaces client.mk. <em>mach</em> has its own configuration file. The
first time you run <em>mach</em>, it will create the file <em>mach.ini</em> in the
same directory as the <em>mach</em> script. This is your new <em>mozconfig</em> file.</p>
<p>The default <em>mach.ini</em> places the object directory into the directory
<em>objdir</em> under the top source directory. It also builds an optimized
binary without debug info.</p>
<p>Run the following to see which config settings you can add to
<em>mach.ini</em>:</p>
<pre><code>./mach settings-create
./mach settings-list
</code></pre>
<p>This <em>may</em> fail because I'm still working out the kinks with <em>gettext</em>.
If it doesn't work, open <em>python/mozbuild-bs/mozbuild/base.py</em> and search
for <em>_register_settings</em>. Open
<em>python/mozbuild-bs/mozbuild/locale/en-US/LC_MESSAGES/mozbuild.po</em> for
the help messages.</p>
<p>As a point of reference, my <em>mach.ini</em> looks like the following:</p>
<pre><code>[build]
application = browser

configure_extra = --enable-dtrace --enable-tests

[compiler]
cc = /usr/local/llvm/bin/clang
cxx = /usr/local/llvm/bin/clang++

cflags = -fcolor-diagnostics
cxxflags = -fcolor-diagnostics

[paths]
source_directory = /Users/gps/src/mozilla-central-git
object_directory = /Users/gps/src/mozilla-central-git/objdir
</code></pre>
<p>I am on OS X and am using a locally-built version of LLVM/Clang, which I
have installed to <em>/usr/local/llvm</em>.</p>
<p>You'll notice there are no options to configure make. The patch
automatically selects optimal settings for your platform!</p>
<h2>Known Issues and Caveats</h2>
<p>This is alpha. It works in scenarios in which I have tested it, mainly
building the <em>browser</em> application on OS X and Linux. There are many
features missing and likely many bugs.</p>
<p>I have been using this as part of my day-to-day development for weeks.
However, your mileage may vary.</p>
<p>As stated above, Windows support is lacking. It will appear to work, but
things will blow up during building. Don't even try to use it on
Windows.</p>
<p>There are likely many bugs. Please don't file Bugzilla bugs, as this
isn't part of the build system just yet.</p>
<p><strong>This patch takes over the build system. Do not attempt to use
client.mk or run make directly with this patch applied.</strong></p>
<p>If you encounter an issue, your methods of recourse are:</p>
<ol>
<li>Post a comment on this blog post</li>
<li>Ping me on irc.mozilla.org. My nick is <em>gps</em>. Try the #buildfaster
   channel.</li>
<li>Send an email to gps@mozilla.com</li>
</ol>
<p>I am particularly interested in exceptions and build failures.</p>
<p>If you encounter an issue building with this, just reverse the patch and
build like you have always done (don't forget to restore your mozconfig
file).</p>
<p>If <em>mach.ini</em> does not support everything you were doing in your
mozconfig, please send me a copy of your mozconfig so I can implement
whatever you need.</p>
<h2>Other Info</h2>
<p>I will likely write a follow-up post detailing what's going on. If you
are curious, the code lives in <em>python/mozbuild-bs</em>. The <em>backend</em> and
<em>frontend</em> sub-packages are where the magic is at. Once the backend has
been configured, check out <em>hybridmake.mk</em> and all of the <em>splendid.mk</em>
files in the object directory.</p>
<p>I am particularly interested in the real-world impact of this patch on
people's build times. In this early version of the patch, you likely
won't see drastic speed increases. On my MacBook Pro with an SSD, I see
end-to-end clobber build times decrease by over a minute. With a little
more work, I should be able to shave another minute or two off of that.</p>
<p>I will try to keep the patch up-to-date as I improve the build system.
Refresh early and often.</p>]]></content>
  </entry>
</feed>
