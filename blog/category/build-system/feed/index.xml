<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Gregory Szorc's Digital Home</title>
    <link>http://gregoryszorc.com/blog</link>
    <description>Rambling on</description>
    <pubDate>Tue, 14 May 2013 02:38:50 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Build System Status Update 2013-05-14</title>
      <link>http://gregoryszorc.com/blog/2013/05/13/build-system-status-update-2013-05-14</link>
      <pubDate>Mon, 13 May 2013 19:35:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/05/13/build-system-status-update-2013-05-14</guid>
      <description>Build System Status Update 2013-05-14</description>
      <content:encoded><![CDATA[<p>I'd like to make an attempt at delivering regular status updates on the
Gecko/Firefox build system and related topics. Here we go with the
first instance. I'm sure I missed awesomeness. Ping me and I'll add it
to the next update.</p>
<h2>MozillaBuild Windows build environment updated</h2>
<p>Kyle Huey
<a href="https://groups.google.com/d/msg/mozilla.dev.platform/XRecAHF-H28/aSbrdKJLUNoJ">released version 1.7</a>
of our Windows build environment. It contains a newer version of Python
and a modern version of Mercurial among other features.</p>
<p><strong>I highly recommend every Windows developer update ASAP.</strong> Please note
that you will likely encounter Python errors unless you clobber your
build.</p>
<h2>New submodule and peers</h2>
<p>I used my power as module owner to create a submodule of the build
config module whose scope is the (largely mechanical) transition of
content from Makefile.in to moz.build files. I granted Joey Armstrong
and Mike Shal peer status for this module. I would like to eventually
see both elevated to build peers of the main build module.</p>
<h2>moz.build transition</h2>
<p>The following progress has been made:</p>
<ul>
<li>Mike Shal has converted variables related to defining XPIDL files in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=818246">bug 818246</a>.</li>
<li>Mike Shal converted MODULE in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844654">bug 844654</a>.</li>
<li>Mike Shal converted EXPORTS in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=846634">bug 846634</a>.</li>
<li>Joey Armstrong converted xpcshell test manifests in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844655">bug 844655</a>.</li>
<li>Brian O'Keefe converted PROGRAM in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=862986">bug 862986</a>.</li>
<li>Mike Shal is about to land conversion of CPPSRCS in
  <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=864774">bug 864774</a>.</li>
</ul>
<h2>Non-recursive XPIDL generation</h2>
<p>In <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=850380">bug 850380</a>
I'm trying to land non-recursive building of XPIDL files. As part of
this I'm trying to combine the generation of .xpt and .h for each input
.idl file into a single process call because profiling revealed that
parsing the IDL consumes most of the CPU time. This shaves a few dozen
seconds off of build times.</p>
<p>I have encounterd multiple pymake bugs when developing this patch, which
is the primary reason it hasn't landed yet.</p>
<h2>WebIDL refactoring</h2>
<p>I was looking at my build logs and noticed WebIDL generation was taking
longer than I thought it should. I filed
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=861587">bug 861587</a> to
investigate making it faster. While my initial profiling turned out to
be wrong, Boris Zbarsky looked into things and discovered that the
serialization and deserialization of the parser output was extremely
slow. He is currently trying to land a refactor of how WebIDL bindings
are handled. The early results look <strong>very</strong> promising.</p>
<p>I think the bug is a good example of the challenges we face improving
the build system, as Boris can surely attest.</p>
<h2>Test directory reorganization</h2>
<p>Joel Maher is injecting sanity into the naming scheme of test
directories in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=852065">bug 852065</a>.</p>
<h2>Manifests for mochitests</h2>
<p>Jeff Hammel, Joel Maher, Ted Mielczarek, and I are working out using
manifests for mochitests (like xpcshell tests) in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=852416">bug 852416</a>.</p>
<h2>Mach core is now a standalone package</h2>
<p>I extracted the mach core to a
<a href="https://github.com/indygreg/mach">standalone repository</a> and
<a href="https://pypi.python.org/pypi/mach/">added it to PyPI</a>.</p>
<p>Mach now <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=856392">categorizes</a>
commands in its help output.</p>
<h2>Requiring Python 2.7.3</h2>
<p>Now that the Windows build environment ships with Python 2.7.4, I've
filed <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=870420">bug 870420</a>
to require Python 2.7.3+ to build the tree. We already require
Python 2.7.0+. I want to bump the point release because there are
<a href="http://hg.python.org/cpython/file/d46c1973d3c4/Misc/NEWS">many</a> small
bug fixes in 2.7.3, especially around Python 3 compatibility.</p>
<p>This is currently blocked on RelEng rolling out 2.7.3 to all the
builders.</p>
<h2>Eliminating master xpcshell manifest</h2>
<p>Now that xpcshell test manifests are defined in moz.build files, we
theoretically don't need the master manifest. Joshua Cranmer is working
on removing them in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=869635">bug 869635</a>.</p>
<h2>Enabling GTests and dual linking libxul</h2>
<p>Benoit Gerard and Mike Hommey are working in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844288">bug 844288</a> to
dual link libxul so GTests can eventually be enabled and executed as
part of our automation.</p>
<p>This will regress build times since we need to link libxul twice. But,
giving C++ developers the ability to write unit tests with a real
testing framework is worth it, in my opinion.</p>
<h2>ICU landing</h2>
<p>ICU was briefly enabled in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=853301">bug 853301</a> but
then backed out because it broke cross-compiling. It should be on track
for enabling in Firefox 24.</p>
<h2>Resource monitoring in mozbase</h2>
<p>I <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=802420">gave mozbase</a>
a class to record system resource usage. I plan to eventually hook this
up to the build system so the build system records how long it took to
perform key events. This will give us better insight into slow and
inefficient parts of the build and will help us track build system speed
improvements over time.</p>
<h2>Sorted lists in moz.build files</h2>
<p>I'm working on requiring lists in moz.build be sorted. Work is happening
in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=863069">bug 863069</a>.</p>
<p>This idea started as a suggestion on the dev-platform list. If anyone
has more great ideas, don't hold them back!</p>
<h2>Smartmake added to mach</h2>
<p>Nicholas Alexander
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=677452">taught mach</a> how
to build intelligently by importing some of Josh Matthews' smartmake
tool's functionality into the tree.</p>
<h2>Source server fixed</h2>
<p>Kyle Huey and Ted Mielczarek
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=846864">collaborated</a> to
fix the source server.</p>
<h2>Auto clobber functionality</h2>
<p>Auto clobber functionality was added to the tree. After flirting briefly
with on-by-default, we changed it to opt-in. When you encounter it, it
will tell you how to enable it.</p>
<h2>Faster clobbers on automation</h2>
<p>I was looking at build logs and identified we were inefficiently
performing clobber.</p>
<p>Massimo Gervasini and Chris AtLee
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=851270">deployed changes</a>
to automation to make it more efficient. My measurements showed a
Windows try build that took 15 fewer minutes to start - a <em>huge</em>
improvement.</p>
<h2>Upgrading to Mercurial 2.5.4</h2>
<p>RelEng is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=741353">tracking</a>
the global deployment of Mercurial 2.5.4. hg.mozilla.org is
currently running 2.0.2 and automation is all over the map. The upgrade
should make Mercurial operations faster and more robust across the
board.</p>
<p>I'm considering adding code to mach or the build system that prompts the
user when her Mercurial is out of date (since an out of date Mercurial
can result in a sub-par user experience).</p>
<h2>Parallelize reftests</h2>
<p>Nathan Froyd is
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=813742">leading an effort</a>
to parallelize reftest execution. If he pulls this off, it could shave
hours off of the total automation load per checkin. Go Nathan!</p>
<h2>Overhaul of MozillaBuild in the works</h2>
<p>I am mentoring a pair of interns this summer. I'm still working out the
final set of goals, but I'm keen to have one of them overhaul the
MozillaBuild Windows development environment. Cross your fingers.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mozilla Build System Brain Dump</title>
      <link>http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump</link>
      <pubDate>Mon, 13 May 2013 17:25:00 PDT</pubDate>
      <category><![CDATA[build system]]></category>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[Firefox]]></category>
      <category><![CDATA[mach]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump</guid>
      <description>Mozilla Build System Brain Dump</description>
      <content:encoded><![CDATA[<p>I hold a lot of context in my head when it comes to the future of
Mozilla's build system and the interaction with it. I wanted to
perform a brain dump of sorts so people have an idea of where I'm
coming from when I inevitably propose radical changes.</p>
<h2>The sad state of build system interaction and the history of mach</h2>
<p>I believe that Mozilla's build system has had a poor developer
experience for as long as there has been a Mozilla build system.
Getting started with Firefox development was a right of passage. It
required following (often out-of-date) directions on MDN. It
required finding pages through MDN search or asking other people
for info over IRC. It was the kind of process that turned away
potential contributors because it was just too damn hard.</p>
<p>mach - while born out of my initial efforts to radically change
the build system proper - morphed into a generic command
dispatching framework by the time it landed in mozilla-central.
It has one overarching purpose: provide a single gateway point for
performing common developer tasks (such as building the tree and
running tests). The concept was nothing new - individual developers
had long coded up scripts and tools to streamline workflows. Some
even published these for others to use. What set mach apart was a
unified interface for these <em>commands</em> (the mach script in the
top directory of a checkout) and that these productivity gains
were <strong>in the tree</strong> and thus easily discoverable and usable by
<em>everybody</em> without significant effort (just run <em>mach help</em>).</p>
<p>While mach doesn't yet satisfy everyone's needs, it's slowly
growing new features and making developers' lives easier with
every one. All of this is happening despite that there
is not a single person tasked with working on mach full time.
Until a few months ago, mach was largely my work. Recently, Matt
Brubeck has been contributing a flury of enhancements - thanks
Matt! Ehsan Akhgari and Nicholas Alexander have contributed a
few commands as well! There are also a few people with a single
command to their name. This is fulfilling my original vision of
facilitating developers to scratch their own itches by
contributing mach commands.</p>
<p>I've noticed more people referencing mach in IRC channels. And,
more people get angry when a mach command breaks or changes
behavior. So, I consider the mach experiment a success. Is it
perfect, no. If it's not good enough for you, please file a bug
and/or code up a patch. If nothing else, please tell me: I love to
know about everyone's subtle requirements so I can keep them in
mind when refactoring the build system and hacking on mach.</p>
<h2>The object directory is a black box</h2>
<p>One of the ideas I'm trying to advance is that the object directory
should be considered a black box for the majority of developers. In
my ideal world, developers don't need to look inside the object
directory. Instead, they interact with it through condoned and
supported tools (like mach).</p>
<p>I say this for a few reasons. First, as the build config module owner
I would like the ability to massively refactor the <em>internals</em> of
the object directory without disrupting workflows. If people are
interacting directly with the object directory, I get significant
push back if things change. This inevitably holds back much-needed
improvements and triggers resentment towards me, build peers, and
the build system. Not a good situation. Whereas if people are
indirectly interacting with the object directory, we simply need to
maintain a consistent interface (like mach) and nobody should care
if things change.</p>
<p>Second, I believe that the methods used when directly interacting
with the object directory are often sub-par compared with going
through a more intelligent tool and that productivity suffers as a
result. For example, when you type <em>make</em> in inside the object
directory you need to know to pass <em>-j8</em>, use make vs pymake,
and that you also need to build <em>toolkit/library</em>, etc.
Also, by invoking make directory, you bypass other handy features,
such as automatic compiler warning aggregation (which only happens
if you invoke the build system through mach). If you go through a
tool like <em>mach</em>, you <em>should</em> automatically get the most ideal
experience possible.</p>
<p>In order for this vision to be realized, we need massive
improvements to tools like mach to cover the missing workflows that
still require direct object directory interaction. We also need people
to start using mach. I think increased mach usage comes after mach
has established itself as obviously superior to the alternatives
(I already believe it offers this for tasks like running tests).</p>
<h2>I don't want to force mach upon people but...</h2>
<p>Nobody likes when they are forced to change a process that has been
familiar for years. Developers especially. I get it. That's why
I've always attempted to position mach as an alternative to
existing workflows. If you don't like mach, you can always fall
back to the previous workflow. Or, you can improve mach (patches
more than welcome!). Having gone down the
please-use-this-tool-it's-better road before at other
organizations, I strongly believe that the best method to incur
adoption of a new tool is to gradually sway people through
obvious superiority and praise (as opposed to a mandate to switch).
I've been trying this approach with mach.</p>
<p>Lately, more and more people have been saying things like
<em>we should have the build infrastructure build through mach
instead of client.mk</em> and <em>why do we need testsuite-targets.mk when
we have mach commands.</em> While I personally feel that client.mk
and testsuite-targets.mk are antiquated as a developer-facing
interface compared to mach, I'm reluctant to eliminate them because
I don't like forcing change on others. That being said, there are
compelling reasons to eliminate or at least refactor how they work.</p>
<p>Let's take <em>testsuite-targets.mk</em> as an example. This is the make
file that provides the targets to run tests (like <em>make xpcshell-test</em>
and <em>make mochitest-browser-chrome</em>). What's interesting about this
file is that it's only used in local builds: our automation
infrastructure does not use <em>testsuite-targets.mk</em>! Instead,
<em>mozharness</em> and the old buildbot configs manually build up the
command used to invoke the test harnesses. Initially, the mach
commands for running tests simply invoked make targets defined
in <em>testsuite-targets.mk</em>. Lately, we've been converting the mach
commands to invoke the Python test runners directly. I'd argue that
the logic for <em>invoke the test runner</em> only needs to live in one
place in the tree. Furthermore as a build module peer, I have little
desire to support multiple implementations. Especially considering
how fragile they can be.</p>
<p>I think we're trending towards an outcome where mach (or the code
behind mach commands) transitions into the authoratitive invocation
method and <em>legacy</em> interfaces like <em>client.mk</em> and
<em>testsuite-targets.mk</em> are reimplemented to either call mach
commands or the same routine that powers them. Hopefully this
will be completely transparent to developers.</p>
<h2>The future of mozconfigs and environment configuration</h2>
<p><em>mozconfig</em> files are shell scripts used to define variables consumed
by the build system. They are the only officially supported mechanism
for configuring how the build system works.</p>
<p>I'd argue mozconfig files are a mediocre solution at best. First,
there's the issue of mozconfig statements that don't actually do
anything. I've seen no-op mozconfig content cargo culted into the
in-tree mozconfigs (used for the builder configurations)! Oops.
Second, doing things in mozconfig files is just awkward. Defining
the object directory requires <em>mk_add_options MOZ_OBJDIR=some-path</em>.
What's <em>mk_add_options</em>? If <em>some-path</em> is relative, what is it
relative <em>to</em>? While certainly addressable, the documentation on
how mozconfig files work is not terrific and fails to explain many
pitfalls. Even with proper documentation, there's still the issue
of the file format allowing no-op variable assignments to persist.</p>
<p>I'm very tempted to reinvent build configuration as something not
mozconfigs. What exactly, I don't know. mach has support for ini-like
configuration files. We could certainly have mach and the build
system pull configs from the same file.</p>
<p>I'm not sure what's going to happen here. But deprecating mozconfig
files as they are today is part of many of the options.</p>
<h2>Handling multiple mozconfig files</h2>
<p>A lot of developers only have a single mozconfig file (per source tree
at least). For these developers, life is easy. You simply install
your mozconfig in one of the default locations and it's automagically
used when you use mach or client.mk. Easy peasy.</p>
<p>I'm not sure what the relative numbers are, but many developers
maintain multiple mozconfig files per source tree. e.g. they'll
have one mozconfig to build desktop Firefox and another one for
Android. They may have debug variations of each.</p>
<p>Some developers even have a single mozconfig file but leverage the
fact that mozconfig files are shell scripts and have their
mozconfig dynamically do things depending on the current working
directory, value of an environment variable, etc.</p>
<p>I've also seen wrapper scripts that glorify setting environment
variables, changing directory, etc and invoke a command.</p>
<p>I've been thinking a lot about providing a common and well-supported
solution for switching between active build configurations.
<a href="https://developer.mozilla.org/en-US/docs/Developer_Guide/mach#Adding_mach_to_your_shell%27s_search_path">Installing mach on $PATH</a>
goes a long way to facilitate this. If you are in an object
directory, the mozconfig used when that object directory was
created is automatically applied. Simple enough. However, I want
people to start treating object directories as black boxes. So, I'd
rather not see people have their shell inside the object directory.</p>
<p>Whenever I think about solutions, I keep arriving at a
virtualenv-like solution. Developers would potentially need to
<em>activate</em> a Mozilla build environment (similar to how Windows
developers need to launch MozillaBuild). Inside this environment,
the shell prompt would contain the name of the current build
configuration. Users could switch between configurations using
<em>mach switch</em> or some other magic command on the $PATH.</p>
<p>Truth be told, I'm skeptical if people would find this useful. I'm
not sure it's that much better than exporting the MOZCONFIG
environment variable to define the active config. This one requires
more thought.</p>
<h2>The integration between the build environment and Python</h2>
<p>We use Python extensively in the build system and for common
developer tasks. mach is written in Python. moz.build processing
is implemented in Python. Most of the test harnesses are written in
Python.</p>
<p>Doing practically anything in the tree requires a Python
interpreter that knows about all the Python code in the tree and
how to load it.</p>
<p>Currently, we have two very similar Python environments. One is
a virtualenv created while running configure at the beginning of
a build. The other is essentially a cheap knock-off that mach
creates when it is launched.</p>
<p>At some point I'd like to consolidate these Python environments.
From any Python process we should have a way to automatically
bootstrap/activate into a well-defined Python environment. This
certainly sounds like establishing a unified Python virtualenv
used by both the build system and mach.</p>
<p>Unfortunately, things aren't straightforward. The virtualenv today
is constructed in the object directory. How do we determine the
current object directory? By loading the mozconfig file. How do we
do that? Well, if you are mach, we use Python. And, how does mach
know where to find the code to load the mozconfig file? You can
see the dilemma here.</p>
<p>A related issue is that of portable build environments. Currently, a
lot of our automation recreates the build system's virtualenv from
its own configuration (not that from the source tree). This has
and will continue to bite us. We'd <em>really</em> like to package up the
virtualenv (or at least its config) with tests so there is no
potential for discrepancy.</p>
<p>The inner workings of how we integrate with Python should be
invisible to most developers. But, I figured I'd capture it
here because it's an annoying problem. And, it's also related
to an <em>activated</em> build environment. What if we required all
developers to <em>activate</em> their shell with a Mozilla build
environment (like we do on Windows)? Not only would this solve
Python issues, but it would also facilitate simpler config
switching (outlined above). Hmmm...</p>
<h2>Direct interaction with the build system considered harmful</h2>
<p>Ever since there was a build system developers have been typing
<em>make</em> (or <em>make.py</em>) to build the tree. One of the goals of the
transition to <em>moz.build</em> files is to facilitate building the tree
with Tup. <em>make</em> will do nothing when you're not using Makefiles!
Another goal of the <em>moz.build</em> transition is to start
derecursifying the make build system such that we build things in
parallel. It's likely we'll produce monolithic make files and then
process <em>all</em> targets for a related class <em>IDLs</em>, <em>C++ compilation</em>,
etc in one invocation of <em>make</em>. So, uh, what happens during a partial
tree build? If a .cpp file from <em>/dom/src/storage</em> is being handled by
a monolithic make file invoked by the Makefile at the top of the
tree, how does a partial tree build pick that up? Does it build just
that target or every target in the monolithic/non-recursive make file?</p>
<p>Unless the build peers go out of our way to install redundant targets
in leaf Makefiles, directly invoking <em>make</em> from a subdirectory of
the tree won't do what it's done for years.</p>
<p>As I said above, I'm sympathetic to forced changes in procedure, so
it's likely we'll provide backwards-compatibile behavior. But, I'd
prefer to not do it. I'd first prefer partial-tree builds are not
necessary and a full tree build finishes quickly. But, we're not going
to get there for a bit. As an alternative, I'll take people building
through <em>mach build</em>. That way, we have an easily extensible interface
on which to build partial tree logic. We saw this recently when
dumbmake/smartmake landed. And, going through <em>mach</em> also reinforces my
ideal that the object directory is a black box.</p>
<h2>Semi-persistent state</h2>
<p>Currently, most state as it pertains to a checkout or build is in the
object directory. This is fine for artifacts from the build system.
However, there is a whole class of state that arguably shouldn't be in
the object directory. Specifically, it shouldn't be clobbered when you
rebuild. This includes logs from previous builds, the warnings database,
previously failing tests, etc. The list is only going to grow over time.</p>
<p>I'd like to establish a location for semi-persistant state related to
the tree and builds. Perhaps we change the clobber logic to ignore a
specific directory. Perhaps we start storing things in the user's home
directory. Perhaps we could establish a second <em>object directory</em> named
the <em>state directory</em>? How would this interact with <em>build environments</em>?</p>
<p>This will probably sit on the backburner until there is a compelling use
case for it.</p>
<h2>The battle against C++</h2>
<p>Compiling C++ consumes the bulk of our build time. Anything we can do to
speed up C++ compilation will work wonders for our build times.</p>
<p>I'm optimistic things like precompiled headers and compiling multiple
.cpp files with a single process invocation will drastically decrease
build times. However, no matter how much work we put in to make C++
compilation faster, we still have a giant issue: dependency hell.</p>
<p>As <a href="/presentations/2012-11-29-firefox-build-system/#34">shown</a> in my
build system presentation a few months back, we have dozens of header
files included by hundreds if not thousands of C++ files. If you change
one file: you invalidate build dependencies and trigger a rebuild. This
is why whenever files like mozilla-config.h change you are essentially
confronted with a full rebuild. ccache may help if you are lucky. But, I
fear that as long as headers proliferate the way they do, there is
little the build system by itself can do.</p>
<p>My attitude towards this is to wait and see what we can get out of
precompiled headers and the like. Maybe that makes it good enough. If
not, I'll likely be making a lot of noise at Platform meetings
requesting that C++ gurus brainstorm on a solution for reducing
header proliferation.</p>
<h2>Conclusion</h2>
<p>Belive it or not, these are only some of the topics floating around in
my head! But I've probably managed to bore everyone enough so I'll
call it a day.</p>
<p>I'm always interested in opinions and ideas, especially if they are
different from mine. I encourage you to leave a comment if you have
something to say.</p>]]></content:encoded>
    </item>
    <item>
      <title>moz.build Files and the Firefox Build System</title>
      <link>http://gregoryszorc.com/blog/2013/02/28/moz.build-files-and-the-firefox-build-system</link>
      <pubDate>Thu, 28 Feb 2013 19:45:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[Firefox]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2013/02/28/moz.build-files-and-the-firefox-build-system</guid>
      <description>moz.build Files and the Firefox Build System</description>
      <content:encoded><![CDATA[<p>The next time you update mozilla-central you may notice some significant
changes with the build system. That's because this morning we finally
landed the start of a massive overhaul of the build system! There are
many end goals to this effort. The important ones for most will be
faster build times and a build system that is friendlier to make changes
to.</p>
<h2>Introducing moz.build Files</h2>
<p>If you look in the tree, you'll notice that nearly every directory
now has a <em>moz.build</em> file.</p>
<p><em>moz.build</em> files are what we are using to define the build system. Think of
them each as a descriptor that describes how to build its own part of the
tree. An individual <em>moz.build</em> file will contain the C++ sources to
compile, the headers to export, the tests to run, etc. Eventually.
Currently, they are limited to directory traversal information.</p>
<p><em>moz.build</em> files essentially add a level of indirection between the
build system definition and how the tree is actually built. Before
<em>moz.build</em> files, the same metadata we are now capturing in <em>moz.build</em>
files (or plan to capture) was captured in <em>Makefile.in</em> files. We
performed simple variable substitution on these <em>Makefile.in</em> files to
produce <em>Makefile</em> files in the object directory. These <em>Makefile</em> files
were used by GNU Make (or Pymake on Windows) to build the tree.</p>
<p>As I outlined in <a href="/blog/2012/06/25/improving-mozilla's-build-system/">Improving Mozilla's Build System</a>,
<em>Makefile.in</em> are suboptimal for a number of reasons. The important
bit is they essentially tie us to the use of make (recursive or otherwise).
We are very interested in supporting modern build systems such as Tup
(the theory being they will build the tree faster).</p>
<p>Enter <em>moz.build</em> files. Storing our build configuration in
<em>moz.build</em> files allows us to decouple the definition of the build
system from the tool used to build it.</p>
<h2>How moz.build Files Work</h2>
<p>At the tail end of <em>configure</em>, the build system invokes the
<em>config.status</em> script in the object directory. The role of
<em>config.status</em> is to combine the information collected during
<em>configure</em> with the build configuration obtained from <em>moz.build</em> files
and take the necessary actions to ensure the build backend (make) can
build the tree.</p>
<p>Before today, <em>config.status</em> essentially iterated over the source tree
and converted <em>Makefile.in</em> files to <em>Makefile</em> in the object directory.
Things are now slightly more complicated with <em>moz.build</em> files.</p>
<p>When <em>config.status</em> runs, it starts with the
<a href="https://hg.mozilla.org/mozilla-central/file/87de54667483/moz.build">root moz.build</a>
from the source tree. It feeds this file into a Python interpreter. It
then looks for special variables like <em>DIRS</em> and <em>PARALLEL_DIRS</em> to determine
which directories contain additional <em>moz.build</em> files. It then descends
into all the referenced directories, reading their <em>moz.build</em> files.
While this is happening, we are converting the results of each
<em>moz.build</em> file execution into <em>backend.mk</em> files that make knows how
to build. It also performs the <em>Makefile.in</em> to <em>Makefile</em> conversion
like it always has. When the whole process has finished, the object
directory contains a bunch of <em>Makefile</em> and <em>backend.mk</em> files. make
runs like it always has. The only real difference is some variables are
coming from the <em>moz.build</em>-derived <em>backend.mk</em> files instead of
<em>Makefile</em>.</p>
<p>This is just a brief overview, of course. If you want to know more,
see the code in <em>/python/mozbuild/mozbuild/frontend</em> and
<em>/python/mozbuild/mozbuild/backend</em>.</p>
<h2>Build System Future</h2>
<p>With the introduction of <em>moz.build</em> files, the intent is to <strong>eventually
completely eliminate Makefile.in and have all the build definition live
in moz.build files.</strong></p>
<p>Doing this all at once would have been next to impossible. So, we
decided to eliminate <em>Makefile.in</em> gradually. The first step is what
landed today: essentially moving <em>DIRS</em> variables out of <em>Makefile.in</em>
and into <em>moz.build</em> files. Next, we will be eliminating empty
<em>Makefile.in</em> (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=844635">bug 844635</a>)
and will be moving more parts of the build definition from <em>Makefile.in</em>
to <em>moz.build</em> files. The next part to move over will likely be IDLs
(<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=818246">bug 818246</a>).
After that, it may be exported files (<em>EXPORTS</em> in <em>Makefile.in</em>
parlance). And repeat until we have no more <em>Makefile.in</em> in the tree.</p>
<p>Each migration of build definition data to <em>moz.build</em> files will likely
occur in two phases:</p>
<ol>
<li>A largely mechanical move of the variables from <em>Makefile.in</em> to
   <em>moz.build</em>.</li>
<li>Better build backend integration resulting from the move.</li>
</ol>
<p>In phase #1, we will essentially cut and paste variable assignments to
<em>moz.build</em> files. make will read the same variables it does today and
perform the same actions. The only difference is the values in these
variables will be defined in <em>moz.build</em> files.</p>
<p>In phase #2, we will leverage the fact that our build definition now has
an API. We will change our existing make backend to be more efficient.
For example, we should soon be able to compile IDLs and copy exported
headers without make traversing through the directory tree at build time.
We will be able to do this because the <em>moz.build</em> traversal at
pre-build time sees data from all <em>moz.build</em> files and with this
<em>complete world view</em> is able to produce more optimal make files than
what you would get if you recursed into multiple directories. In short:
it will make the build faster.</p>
<p>Once we have a sufficient portion of the build definition moved to
<em>moz.build</em> files we will be able to experiment with new build backends
(like Tup), look into automatic Visual Studio project generation, and
more easily experiment with different ways of building (such as
precompiled headers, fewer compiler process invocations, etc). These
should all contribute to faster build times.</p>
<h2>Frequently Asked Questions</h2>
<h4>What impact will I see from this change?</h4>
<p>If you never touched <em>Makefile.in</em> files in the tree, you should not
notice anything different about how the tree builds or how the build
system works. You should have nothing to fear.</p>
<p>The most obvious changes to the source tree are:</p>
<ol>
<li>There is a <em>moz.build</em> file in almost every directory now.</li>
<li>The variables related to directory traversal (those containing <em>DIRS</em>
   in their name) are now defined in <em>moz.build</em> files instead of
   <em>Makefile.in</em>.</li>
<li>If your <em>Makefile.in</em> contains a variable that has been moved to
   <em>moz.build</em> files, make will spew an error when processing that file
   and the build will fail.</li>
</ol>
<h4>Will this change how I build?</h4>
<p>It shouldn't. You should build the tree just like you always have. Most
of you won't notice any differences.</p>
<p>If you see something weird, speak up in #build or file a bug if you are
really confident it is wrong.</p>
<h4>What are the risks to this change?</h4>
<p>The migration of variables from <em>Makefile.in</em> to <em>moz.build</em> files is
largely mechanical and significant portions are done manually. This can
be a mind-numbing and tedious process. Not helping things is the fact
that Splinter's review interface for these kinds of patches is hard to
read.</p>
<p>This all means that there is a non-trivial risk for <em>transcription</em>
errors. All it takes is an inverted conditional block and all of a
sudden large parts of the tree are no longer built, for example.</p>
<p>We have established <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=846425">bug 846825</a>
to investigate any oddities from the initial transfer. Developers are
encouraged to help with the effort. Please spot check that your
directories are still being built, tests run, etc. Pay special attention
to changes made in the last 4 months as these parts of <em>Makefile.in</em>
would have been bit rotted and more prone to data loss.</p>
<p>Parts of the tree not enabled in standard configurations are more prone
to breakage due to less testing. i.e. build configurations not captured
by TBPL have a higher chance of breaking.</p>
<h4>Will this make the tree build faster?</h4>
<p>Not yet. But eventually it will. This initial landing paves the
groundwork to making the tree build faster (see the <em>Future</em> section
above).</p>
<h4>I see a lot of empty moz.build files!</h4>
<p>Yes. Sorry about that. The good news is they shouldn't be empty for
long. As things move from <em>Makefile.in</em> to <em>moz.build</em> we'll see fewer
and fewer empty <em>moz.build</em> files. We'll also see fewer and fewer
<em>Makefile.in</em> files once we start deleting empty <em>Makefile.in</em>.</p>
<p>If you want to know why we must have empty files, it's mainly for
validation. If we allowed <em>moz.build</em> files to be optional, how would
you detect a typo in a directory name? Directory exists? What if that
directory exists but isn't supposed to have a <em>moz.build</em> file?</p>
<h4>You bitrotted my patches!</h4>
<p>Yes. I'm sorry. The transition period to <em>moz.build</em> files could be a
little messy. There will be lots of changes to <em>Makefile.in</em> and
<em>moz.build</em> files and lots of chances for bit rot. Uplifts could be
especially nasty. (Although I don't believe many uplifts involve
significant changes to the build configuration.)</p>
<p>This all means there is a strong incentive for us to complete the
transition as quickly as possible.</p>
<h4>Can I help with the transition to moz.build files?</h4>
<p>Yes!</p>
<p>The transition is largely mechanical (at least phase #1). If you are
interested in moving a variable or set of variables, hop in #build on
IRC and speak up!</p>
<h4>You said moz.build files are actually Python files?!</h4>
<p>Yes they are! However, they are executed in a very tightly controlled
sandbox. You can't import modules, open files, etc. UPPERCASE variable
names are reserved and only a few functions are exposed. If you attempt
to assign to an unknown UPPERCASE variable or assign an invalid value,
an error will occur. This is already much better than Makefile because
we can now detect errors earlier in the build process (rather than 15
minutes into a build).</p>
<h4>What variables and functions are available in moz.build files?</h4>
<p>If you run |./mach mozbuild-reference| you will see a print-out of
all the variables, functions, and symbols that are exposed to the Python
sandbox that moz.build files execute in. There are even tests that will
fail the build if the sandbox contains symbols not in this output!</p>
<p>The output should be valid reSTructuredText (in case you want to convert
to HTML for reading in your browser).</p>
<h4>What if a moz.build file contains an error?</h4>
<p>The build will break.</p>
<p>A lot of work has gone into making the output of moz.build errors human
friendly and actionable. If you do something wrong, it won't just
complain: it will tell you how to fix it!</p>
<h4>Besides build times, how else will this improve the build system?</h4>
<p>There are several ways!</p>
<p>As mentioned above, moz.build are more strict about what data is allowed
to be defined. If you assign to an UPPERCASE variable, that variable
must be known to the sandbox or else the assignment will error. This
means that if you assign to an UPPERCASE variable, you know it has a
side-effect. No more cargo culting of old, meaningless variables!</p>
<p>To change the behavior of moz.build files (add new variables or
functions, change how makefile generation works, etc) will require
changes to the code in /python/mozbuild. This code belongs squarely to
the build module and requires appropriate review. A problem with
Makefiles is that they have lots of foot guns by default and its easy
for self-inflicted wounds to land in the tree without explicit build
peer review. This problem largely goes away with moz.build files because
the sandbox takes away all of make's foot guns.</p>
<p>The output of a moz.build execution is essentially a static data
structure. It's easy to validate them for conformance. If we discover
bad practices in our build definition, we can centrally add tests for
them and enforce best practices.</p>
<p>We will also see user experience wins by moving data to moz.build files.
Take mochitests for an example. We currently have several flavors
(plain, browser, chrome, etc). Sometimes you cannot distinguish the
flavor by the filename alone. With moz.build files, it will be easier to
answer questions like "what mochitest flavor is this file?" mach could
hook into this so you can type |mach mochitest path/to/file.html|
instead of |mach mochitest-plain path/to/file.html|. Even better, you
should just be able to type |mach path/to/test.html| and mach knows from
the build definition that path/to/test.html is a plain mochitest file
and assumes you want to run it. There are dozens of small development
workflow wins to be gained here!</p>
<h4>If I change a moz.build file, what happens?</h4>
<p>If you change a moz.build file, then make should detect that it
has changed and it will update the dynamically generated <em>backend.mk</em>
file and reinvoke the requested build action. This should all happen
automatically (just like <em>Makefile.in</em> to <em>Makefile</em> conversion works
automatically).</p>
<h4>My build seems to pause for a few seconds before starting!</h4>
<p>A change to <em>any</em> moz.build file will cause a full traversal of the
entire moz.build tree. On modern machines, this should only take 1-3
seconds. If your source tree is not in the page cache (and you need
to load moz.build files from disk) or if you are on older hardware, this
could be a little slower.</p>
<p>This is an unfortunate side-effect of having a whole world view of the
build definition. The build delay incurred by these full scans should
eventually be cancelled out by build backend optimizations resulting
from having this whole world view, however.</p>
<p>The good news is this full scan should only occur if a mozbuild file
changes. And, if you are performing make recursion, it should only
happen once (not in every directory). If you notice multiple moz.build
scanning-related pauses during builds, please file a bug in Core ::
Build Config!</p>
<p>Finally, we are performing the reads on a single thread currently. We
can throw more cores at the task if someone codes up a patch.</p>
<h4>What happened to allmakefiles.sh?</h4>
<p>It has been sacked. allmakefiles.sh was an optimization to perform all
the Makefile.in to Makefile conversion in one go. The directory
traversal performed by moz.build reading effectively replaces the role
of allmakefiles.sh. Not only that, but the moz.build build definition is
always up to date! allmakefiles.sh was typically out of sync with
reality and was a burden to maintain.</p>
<h4>Did we just invent our own build system?</h4>
<p>Kinda. We invented a generic Python sandboxing infrastructure. Then we
hooked up code to populate it with variables from our build system and
told it how to perform file traversal by reading specific variables set
during file execution. Then we hooked up code for taking the evaluated
results of all those sandboxes and convert them into make files.</p>
<p>Conceptually, what we invented is like GYP but with a different config
file format. We have dabbled with the idea of converting the parsed
build definition into GYP classes and then leveraging GYP to produce
Makefiles, Ninja files, Visual Studio Projects, etc. This would an
interesting experiment!</p>
<p>If you want to call it a build system, call it a build system. However,
it is currently tightly coupled to Mozilla's needs, so you can't just
use it anywhere. The concept might be worth exploring, however.</p>
<h4>Is there anything else you'd like to share?</h4>
<p>I think we set the record for most parts in a bug: 61. Although, they
are numbered 1-17, 19-20. Part 18 has 30+ sub-parts using letters from
the English and Greek alphabet for identifiers. Part 61 uses the
infinity symbol as its number. See the
<a href="https://hg.mozilla.org/mozilla-central/pushloghtml?changeset=c65d59d33aa8">pushlog</a>.</p>
<p>Finally, I'd like to thank everyone who helped with this effort. The bug
itself was <em>only</em> 6 months old and had active development off and on for
a lot of it. Ted Mielczarek and Mike Hommey provided invaluable feedback
on the core build system patches. A number of module owners stepped in
to lend eyes to the mechanical conversion of their files. Last but not
least, Ms2ger provided invaluable review aid on many of the patches. The
work was so good that we all agreed that an Ms2ger f+ was good enough
for a build peer rs! If reviewing the patches wasn't enough, Ms2ger
also oversaw the tree closure and merging of the landing. I don't know
how I will repay this debt.</p>
<h4>Any more questions?</h4>
<p>If you have more questions, drop in #build on irc.mozilla.org and ask
away.</p>]]></content:encoded>
    </item>
    <item>
      <title>Firefox Build System Presentation</title>
      <link>http://gregoryszorc.com/blog/2012/11/30/firefox-build-system-presentation</link>
      <pubDate>Fri, 30 Nov 2012 14:00:00 PST</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[Firefox]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/11/30/firefox-build-system-presentation</guid>
      <description>Firefox Build System Presentation</description>
      <content:encoded><![CDATA[<p>In case you missed it, I gave a presentation on the state of Firefox's
build system yesterday.</p>
<p>You can <a href="https://air.mozilla.org/the-future-of-the-firefox-build-system/">watch</a>
it and <a href="http://gregoryszorc.com/presentations/2012-11-29-firefox-build-system/#1">view</a>
the slides online.</p>
<p>If you build Firefox from source regularly, you should definitely at
least skim through the slide deck.</p>
<p>I'm not an HTML expert, so my apogolies for bad UI on the interactive
slides. You may need to press <strong>enter</strong> to select items in
dropdown menus. Also, the interactive slides are a bit resource
intensive. If the slide deck is really slow, turn off those elements.
I've also only tested the slides in Firefox 19 and 20. My apologies if
they don't work everywhere.</p>]]></content:encoded>
    </item>
    <item>
      <title>Visual Studio Project Generation for mozilla-central</title>
      <link>http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central</link>
      <pubDate>Tue, 28 Aug 2012 12:00:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[Firefox]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/08/28/visual-studio-project-generation-for-mozilla-central</guid>
      <description>Visual Studio Project Generation for mozilla-central</description>
      <content:encoded><![CDATA[<p>I have very alpha support for Visual Studio project generation for
mozilla-central that daring people can dogfood.</p>
<p>I want to emphasize that this is extremely alpha. Normally, I wouldn't
release things as fragile as they are. But, I know Windows developers
sorely miss Visual Studio, especially IntelliSense. The current Visual
Studio projects support IntelliSense, so I want to get this in the hands
of Windows developers ASAP.</p>
<p>The current directions for making this all work are a bit hacky. Things
will change once things have matured. For now, please excuse the mess.</p>
<p>First, you will need to grab the code. If you use Git, set up a remote
to my repository:</p>
<pre><code>git remote add indygreg git://github.com/indygreg/mozilla-central.git
git fetch indygreg
</code></pre>
<p>The branch of interest is <em>build-splendid</em>. I periodically rebase this
branch on top of master. You have been warned.</p>
<p>You can switch to this branch:</p>
<pre><code>git checkout -b build-splendid indygreg/build-splendid
</code></pre>
<p>Alternatively, you can squash it down to a single commit and merge it
into your local branch. Once you've done that, you can record the SHA-1
of the commit and cherry-pick that wherever you like!</p>
<pre><code>git merge --squash indygreg/build-splendid
git commit
</code></pre>
<p>In the current state, you need to build the tree or the Visual Studio
projects will complain about missing files. It doesn't matter if you
build the tree before or after Visual Studio projects are generated.
But, we might as well get it out of the way. From your MozillaBuild
environment, run:</p>
<pre><code>./mach build
</code></pre>
<p>That should <em>just work</em>. If it doesn't, you may need to configure
mach.ini. See my <a href="http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid/">previous post</a>
on how to configure mach.ini. As a reference, my Windows config is:</p>
<pre><code>[build]

configure_extra = --disable-webgl

[compiler]

[paths]
source_directory = c:\dev\src\mozilla-central-git
object_directory = c:\dev\src\mozilla-central-git\objdir
</code></pre>
<p>Now, to generate Visual Studio project files:</p>
<pre><code>./mach backendconfig visualstudio
</code></pre>
<p>That should take about a minute to finish. When it's done, it should
have created <em>objdir/msvc/mozilla.sln</em>. You should be able to load that
in Visual Studio!</p>
<p>You will need to regenerate Visual Studio project files when the build
config changes. As a rule of thumb, do this every time you pull source.
You don't need to perform a full build before you generate Visual Studio
files (you do need to perform configure, however). However, if you have
not performed a full build, Visual Studio may not be able to find some
files, like headers generated from IDLs.</p>
<p><strong>Please close the solution before regenerating the project files.</strong> If
you don't, Visual Studio puts up a modal dialog for each project file
that changed and you have to click through over a hundred of these. It's
extremely frustrating. I'm investigating workarounds.</p>
<h2>Current State</h2>
<p>Currently, it only generates projects for C/C++ compilation (libraries).
I still need to add support for IDL, headers, etc. However, each
project has proper compiler flags, header search paths, etc. So,
IntelliSense is happy and some things do manage to compile!</p>
<p>Many parts are broken and sub-par.</p>
<p>I've only tested on Visual Studio 2008. If you are running Visual Studio
\2010, you can try to upgrade the solution. This <em>may</em> work. The backend
supports generating solutions for different versions. But, I haven't
tested things work on non-2008 and I don't want to expose untested behavior.</p>
<p>Compiling within Visual Studio works for some things. On my system, I
get a lot of <em>nullptr not defined</em> errors. I'm not sure why. This will
hopefully be worked out soon.</p>
<p>If you do manager to compile within Visual Studio, the output files
don't go in the right places. So, if you do a build from the
command-line, it will have to re-compile to pick up changes.</p>
<p>Project names are based on the name of the library they produce. I'm not
sure if this is the best solution.</p>
<p>Project dependencies are not set up. They will be added later.</p>
<p>Projects for linking libxul or building firefox.exe are not yet
provided. Along the same vein, debugging support is not built-in. I'm
working on it.</p>
<p>Basically, IntelliSense works. You can now use Visual Studio as a rich
editor. Hopefully this is a step in the right direction.</p>
<p>I'm anxious to hear if this works for other people. Please leave
comments!</p>]]></content:encoded>
    </item>
    <item>
      <title>Build Firefox Faster with Build Splendid</title>
      <link>http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid</link>
      <pubDate>Wed, 15 Aug 2012 14:30:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[Firefox]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/08/15/build-firefox-faster-with-build-splendid</guid>
      <description>Build Firefox Faster with Build Splendid</description>
      <content:encoded><![CDATA[<p>Would you like to build Firefox faster? If so, do the following:</p>
<pre><code>hg qimport http://people.mozilla.org/~gszorc/build-splendid.patch
hg qpush
rm .mozconfig* (you may want to create a backup first)
./mach build
</code></pre>
<p>This should <em>just work</em> on OS X, Linux, and other Unix-style systems.
<strong>Windows support is currently broken, sorry.</strong></p>
<p><em>mach</em> can do much more than build. Run the following to see what:</p>
<pre><code>./mach --help
</code></pre>
<h2>Important Info</h2>
<p><em>mach</em> replaces client.mk. <em>mach</em> has its own configuration file. The
first time you run <em>mach</em>, it will create the file <em>mach.ini</em> in the
same directory as the <em>mach</em> script. This is your new <em>mozconfig</em> file.</p>
<p>The default <em>mach.ini</em> places the object directory into the directory
<em>objdir</em> under the top source directory. It also builds an optimized
binary without debug info.</p>
<p>Run the following to see which config settings you can add to
<em>mach.ini</em>:</p>
<pre><code>./mach settings-create
./mach settings-list
</code></pre>
<p>This <em>may</em> fail because I'm still working out the kinks with <em>gettext</em>.
If it doesn't work, open <em>python/mozbuild-bs/mozbuild/base.py</em> and search
for <em>_register_settings</em>. Open
<em>python/mozbuild-bs/mozbuild/locale/en-US/LC_MESSAGES/mozbuild.po</em> for
the help messages.</p>
<p>As a point of reference, my <em>mach.ini</em> looks like the following:</p>
<pre><code>[build]
application = browser

configure_extra = --enable-dtrace --enable-tests

[compiler]
cc = /usr/local/llvm/bin/clang
cxx = /usr/local/llvm/bin/clang++

cflags = -fcolor-diagnostics
cxxflags = -fcolor-diagnostics

[paths]
source_directory = /Users/gps/src/mozilla-central-git
object_directory = /Users/gps/src/mozilla-central-git/objdir
</code></pre>
<p>I am on OS X and am using a locally-built version of LLVM/Clang, which I
have installed to <em>/usr/local/llvm</em>.</p>
<p>You'll notice there are no options to configure make. The patch
automatically selects optimal settings for your platform!</p>
<h2>Known Issues and Caveats</h2>
<p>This is alpha. It works in scenarios in which I have tested it, mainly
building the <em>browser</em> application on OS X and Linux. There are many
features missing and likely many bugs.</p>
<p>I have been using this as part of my day-to-day development for weeks.
However, your mileage may vary.</p>
<p>As stated above, Windows support is lacking. It will appear to work, but
things will blow up during building. Don't even try to use it on
Windows.</p>
<p>There are likely many bugs. Please don't file Bugzilla bugs, as this
isn't part of the build system just yet.</p>
<p><strong>This patch takes over the build system. Do not attempt to use
client.mk or run make directly with this patch applied.</strong></p>
<p>If you encounter an issue, your methods of recourse are:</p>
<ol>
<li>Post a comment on this blog post</li>
<li>Ping me on irc.mozilla.org. My nick is <em>gps</em>. Try the #buildfaster
   channel.</li>
<li>Send an email to gps@mozilla.com</li>
</ol>
<p>I am particularly interested in exceptions and build failures.</p>
<p>If you encounter an issue building with this, just reverse the patch and
build like you have always done (don't forget to restore your mozconfig
file).</p>
<p>If <em>mach.ini</em> does not support everything you were doing in your
mozconfig, please send me a copy of your mozconfig so I can implement
whatever you need.</p>
<h2>Other Info</h2>
<p>I will likely write a follow-up post detailing what's going on. If you
are curious, the code lives in <em>python/mozbuild-bs</em>. The <em>backend</em> and
<em>frontend</em> sub-packages are where the magic is at. Once the backend has
been configured, check out <em>hybridmake.mk</em> and all of the <em>splendid.mk</em>
files in the object directory.</p>
<p>I am particularly interested in the real-world impact of this patch on
people's build times. In this early version of the patch, you likely
won't see drastic speed increases. On my MacBook Pro with an SSD, I see
end-to-end clobber build times decrease by over a minute. With a little
more work, I should be able to shave another minute or two off of that.</p>
<p>I will try to keep the patch up-to-date as I improve the build system.
Refresh early and often.</p>]]></content:encoded>
    </item>
    <item>
      <title>mozilla-central Build Times</title>
      <link>http://gregoryszorc.com/blog/2012/07/29/mozilla-central-build-times</link>
      <pubDate>Sun, 29 Jul 2012 13:20:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/07/29/mozilla-central-build-times</guid>
      <description>mozilla-central Build Times</description>
      <content:encoded><![CDATA[<p>In my previous post, I
<a href="http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview/">explained how Mozilla's build system works</a>.
In this post, I want to give people a feel for where time is spent and to
identify obvious areas that need improvement.</p>
<p>To my knowledge, nobody has provided such a comprehensive collection of
measurements before. Thus, most of our thoughts on where build time goes
have been largely lacking scientific rigor. I hope this post changes
matters and injects some much-needed quantitative figures into the
discussion.</p>
<h2>Methodology</h2>
<p>All the times reported in this post were obtained from my 2011
generation MacBook Pro. It has 8 GB of RAM and a magnetic hard drive. It
is not an ultimate build rig by any stretch of the imagination. However,
it's no slouch either. The machine has 1 physical Core i7 processor with
4 cores, each clocked at 2.3GHz. Each core has hyperthreading, so to the
OS there appears to be 8 cores. For the remainder of this post, I'll
simply state that my machine has 8 cores.</p>
<p>When I obtained measurements, I tried to limit the number of processes
running elsewhere on the machine. I also performed multiple runs and
reported the best timings. This means that the results are likely
synthetic and highly influenced by the page cache. More on that later.</p>
<p>I configured make to use up to 8 parallel processes (adding -j8 to the
make flags). I also used silent builds (the -s flag to make). Silent
builds are important because terminal rendering can add many seconds of
wall time to builds, especially on slow terminals (like Windows). I
measured results with make output being written to the terminal. In
hindsight, I wish I hadn't done this. Next time.</p>
<p>To obtain the times, I used the ubiquitous <em>time</em> utility. Wall times
are the <em>real</em> times from <em>time</em>. CPU time is the sum of the <em>user</em> and
<em>sys</em> times.</p>
<p>CPU utilization is the percentage of CPU cores busy during the wall time
of execution. In other words, I divided the CPU time by 8 times the wall
time (8 for the number of cores in my machine). 100% is impossible to
obtain, as obviously the CPU on my machine is doing other things during
measurement. But, I tried to limit the number of background processes
running, so there shouldn't have been that much noise.</p>
<p>I built a debug version of Firefox (the <em>browser</em> app in
mozilla-central) using r160922 of the Clang compiler (pulled and built
the day I did this measurement). The revision of mozilla-central being
built was <a href="https://hg.mozilla.org/mozilla-central/rev/08428deb1e89">08428edb1e89</a>.
I also had <em>--enable-tests</em>, which adds a significant amount of extra
work to builds.</p>
<h2>Configure</h2>
<p><em>time</em> reported the following for running <em>configure</em>:</p>
<pre><code>real 0m25.927s
user 0m9.595s
sys  0m8.729s
</code></pre>
<p>This is a one-time cost. Unless you are hacking on the build system or
pull down a tree change that modified the build system, you typically
don't need to worry about this.</p>
<h2>Clobber Builds with Empty ccache</h2>
<p>I built each tier separately with an empty ccache on a
recently-configured object directory. This measures the optimal worst
case time for building mozilla-central. In other words, we have nothing
cached in the object directory, so the maximum amount of work needs to
be performed. Since I measured multiple times and used the best results,
this is what I mean by <em>optimal</em>.</p>
<p>The table below contains the measurements. I omitted CPU utilization
calculation for small time values because I don't feel it is relevant.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Utilization</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.714</td>
    <td>0.774</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>5.081</td>
    <td>8.620</td>
    <td>21%</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.453</td>
    <td>0.444</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>base (total)</td>
    <td>6.248</td>
    <td>9.838</td>
    <td>19.7%</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>9.309</td>
    <td>8.404</td>
    <td>11.3%</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>1.030</td>
    <td>1.877</td>
    <td>22.8%</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>71.450</td>
    <td>416.718</td>
    <td>52%</td>
  </tr>
  <tr>
    <td>js tools</td>
    <td>0.324</td>
    <td>0.246</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>js (total)</td>
    <td>72.804</td>
    <td>418.841</td>
    <td>71.9%</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>40.487</td>
    <td>141.704</td>
    <td>43.7%</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>1211</td>
    <td>4896</td>
    <td>50.5%</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>70.416</td>
    <td>90.917</td>
    <td>16.1%</td>
  </tr>
  <tr>
    <td>platform (total)</td>
    <td>1312</td>
    <td>5129</td>
    <td>48.9%</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>4.383</td>
    <td>3.059</td>
    <td>8.7%</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>18.727</td>
    <td>18.976</td>
    <td>12.7%</td>
  </tr>
  <tr>
    <td>app tools (no-op)</td>
    <td>0.519s</td>
    <td>0.968</td>
    <td>N/A</td>
  </tr>
  <tr>
    <td>app (total)</td>
    <td>23.629</td>
    <td>23.003</td>
    <td>12.2%</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>1424 (23:44)</td>
    <td>5589 (93:15)</td>
    <td>49.1%</td>
  </tr>
</table>

<p>It's worth mentioning that linking libxul is part of the platform libs
tier. libxul linking should be called out because it is unlike other
parts of the build in that it is more I/O bound and can't use multiple
cores. On my machine, libxul linking (not using gold) takes ~61s. During
this time, only 1 CPU core is in use. The ~61s wall time corresponds to
roughly 5% of platform libs' wall time. Yet, even if we subtract this ~61s
from the effective CPU calculation, the percentage doesn't change much.</p>
<h2>Clobber with Populated ccache</h2>
<p>Using the ccache from a recently built tree to make C/C++ compilation
faster, I measured how long it took each tier to build on a clobber
build.</p>
<p>This measurement can be used to estimate the overhead of C/C++ compilation
during builds. In theory, the difference between CPU times between this
and the former measurement will be the amount of CPU time spent in the
C/C++ compiler.</p>
<p>This will also isolate how much time we spend <em>not</em> in the C/C++
compiler. It will arguably be very difficult to
make the C/C++ compiler faster (although things like reducing the abuse
of templates can have a measureable impact). However, we do have control
over many of the other things we do. If we find that CPU time spent
outside the C/C++ compiler is large, we can look for pieces to optimize.</p>
<p>Tiers not containing compiled files are omitted from the data.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
    <th>ccache savings (s) (Time in Compiler)</th>
  </tr>
  <tr>
    <td>base libs</td>
    <td>1.075</td>
    <td>1.525</td>
    <td>7.095</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>1.957</td>
    <td>0.933</td>
    <td>1.522</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>5.582</td>
    <td>1.688</td>
    <td>6.716</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>22.829</td>
    <td>9.529</td>
    <td>407.189</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>431</td>
    <td>328</td>
    <td>4568</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>14.498</td>
    <td>25.744</td>
    <td>65.173</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>10.193</td>
    <td>15.809</td>
    <td>3.167</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>487.134 (6:07)</td>
    <td>383.229 (6:23)</td>
    <td>5059 (84:19)</td>
  </tr>
</table>

<h2>No-op Build</h2>
<p>A <em>no-op</em> build is a build performed in an object directory that was
just built. Nothing changed in the source repository nor object
directory, so theoretically the build should do nothing. And, it should
be fast.</p>
<p>In reality, our build system isn't smart and performs some redundant
work. One part of redundant work is because one of the first things the
main Makefile does before invoking the tiers is delete a large chunk of
the <em>dist/</em> directory and the entirety of the <em>_tests/</em> directory from
the object directory.</p>
<p>In these measurements, I bypassed the deletion of these directories. In
other words, I measure what <em>no-op</em> builds are if we eliminate the
clown shoes around blowing away large parts of the object directory.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>CPU Time (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.524</td>
    <td>0.537</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.625</td>
    <td>0.599</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.447</td>
    <td>0.437</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.809</td>
    <td>0.752</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.334</td>
    <td>0.324</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.375</td>
    <td>0.361</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>10.904</td>
    <td>13.136</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>30.969</td>
    <td>44.25</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>8.213</td>
    <td>10.737</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.524</td>
    <td>1.006</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>6.090</td>
    <td>13.753</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>59.814</td>
    <td>85.892</td>
  </tr>
</table>

<p>So, no-op builds use ~60s of wall time and only make use of 17.9% of
available CPU resources.</p>
<h2>No-op Build With Directory Removal Silliness</h2>
<p>As mentioned above, before the tiers are iterated, the top-level
Makefile blows away large parts of <em>dist/</em> and the entirety of
<em>_tests/</em>. What impact does this have?</p>
<p>In this section, I try to isolate how much time was thrown away by doing
this.</p>
<p>First, we have to account for the deletion of these directories. On my
test build, deleting 15,005 files in these directories took ~3 seconds.</p>
<p>The table below contains my results. This is a more accurate reading
than the above on how long no-op builds takes because this is actually
what we do during normal builds. The time delta column contains the
difference between this build and a build without the removal silliness.
Positive times can be attributes to overhead associated with
repopulating <em>dist/</em> and <em>_tests/</em>.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>Wall Time Delta (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Time Delta (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.544</td>
    <td>Negligible</td>
    <td>0.559</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.616</td>
    <td>Negligible</td>
    <td>0.594</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.447</td>
    <td>Negligible</td>
    <td>0.436</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.803</td>
    <td>Negligible</td>
    <td>0.743</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.338</td>
    <td>Negligible</td>
    <td>0.329</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.378</td>
    <td>Negligible</td>
    <td>0.363</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>13.140</td>
    <td>2.236</td>
    <td>13.314</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>35.290</td>
    <td>4.329</td>
    <td>43.059</td>
    <td>-1.191 (normal variance?)</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>8.819</td>
    <td>0.606</td>
    <td>10.983</td>
    <td>0.246</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.525</td>
    <td>Negligible</td>
    <td>1.012</td>
    <td>Negligible</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>8.876</td>
    <td>2.786</td>
    <td>13.527</td>
    <td>-0.226</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>69.776</td>
    <td>9.962</td>
    <td>84.919</td>
    <td>-0.973 (normal variance)</td>
  </tr>
</table>

<p>If a delta is listed as negligible, it was within 100ms of the original
value and I figured this was either due to expected variance between
runs or below our threshold for caring. In the case of base, nspr, and
js tiers, the delta was actually much smaller than 100ms, often less
then 10ms.</p>
<p>It certainly appears that the penalty for deleting large parts of
<em>dist/</em> and the entirety of <em>_tests/</em> is about 10 seconds.</p>
<h2>The Overhead of Make</h2>
<p>We've measured supposed no-op build times. As I stated above, our no-op
builds actually aren't no-op builds. Even if we bypass the deletion of
<em>dist/</em> and <em>_tests/</em> we always evaluate some make rules. Can we measure how
much work it takes to just load the make files without actually doing
anything? This would allow us to get a rough estimate of how much we are
wasting by doing redundant work. It will also help us establish a
baseline for make overhead.</p>
<p>Turns out we can! Make has a <em>--dry-run</em> argument which evaluates the make
file but doesn't actually do anything. It simply prints what would have
been done.</p>
<p>Using <em>--dry-run</em>, I timed the different tiers. The difference from a no-op
build should roughly be the overhead associated with make itself. It is
possible that <em>--dry-run</em> adds a little overhead because it prints the
commands that would have been executed. (Previous timings were using
<em>-s</em>, which suppresses this.)</p>
<p>The delta times in the following table are the difference in times
between the true no-op build from above (the one where we don't delete
<em>dist/</em> and <em>_tests/</em>) and the times measured here. It roughly isolates
the amount of time spent outside of make, doing redundant work.</p>
<table border="1">
  <tr>
    <th>Tier - Sub-tier</th>
    <th>Wall Time (s)</th>
    <th>Wall Time Delta (s)</th>
    <th>CPU Time (s)</th>
    <th>CPU Time Delta (s)</th>
  </tr>
  <tr>
    <td>base export</td>
    <td>0.369</td>
    <td>0.155</td>
    <td>0.365</td>
    <td>0.172</td>
  </tr>
  <tr>
    <td>base libs</td>
    <td>0.441</td>
    <td>0.184</td>
    <td>0.431</td>
    <td>0.168</td>
  </tr>
  <tr>
    <td>base tools</td>
    <td>0.368</td>
    <td>0.079</td>
    <td>0.364</td>
    <td>0.073</td>
  </tr>
  <tr>
    <td>nspr</td>
    <td>0.636</td>
    <td>0.173</td>
    <td>0.591</td>
    <td>0.161</td>
  </tr>
  <tr>
    <td>js export</td>
    <td>0.225</td>
    <td>0.109</td>
    <td>0.225</td>
    <td>0.099</td>
  </tr>
  <tr>
    <td>js libs</td>
    <td>0.278</td>
    <td>0.097</td>
    <td>0.273</td>
    <td>0.088</td>
  </tr>
  <tr>
    <td>platform export</td>
    <td>3.841</td>
    <td>7.063</td>
    <td>6.108</td>
    <td>7.028</td>
  </tr>
  <tr>
    <td>platform libs</td>
    <td>8.938</td>
    <td>22.031</td>
    <td>14.723</td>
    <td>29.527</td>
  </tr>
  <tr>
    <td>platform tools</td>
    <td>3.962</td>
    <td>4.251</td>
    <td>6.185</td>
    <td>4.552</td>
  </tr>
  <tr>
    <td>app export</td>
    <td>0.422</td>
    <td>0.102</td>
    <td>0.865</td>
    <td>0.141</td>
  </tr>
  <tr>
    <td>app libs</td>
    <td>0.536</td>
    <td>5.554</td>
    <td>1.148</td>
    <td>12.605</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>20.016</td>
    <td>39.798</td>
    <td>31.278</td>
    <td>54.614</td>
  </tr>
</table>

<h2>Observations</h2>
<p>The numbers say a lot. I'll get to key takeaways in a bit.</p>
<p>First, what the numbers don't show is the variance between runs.
Subsequent runs are almost always <em>significantly</em> faster than the
initial, even on no-op builds. I suspect this is due mostly to
I/O wait. In the initial tier run, files are loaded into the page cache.
Then, in subsequent runs, all I/O comes from physical memory rather than
waiting on a magnetic hard drive.</p>
<p>Because of the suspected I/O related variance, I fear that the numbers I
obtained are highly synthetic, at least for my machine. It is unlikely
I'll ever see all these numbers in one mozilla-central build. Instead,
it requires a specific sequence of events to obtain the best times
possible. And, this sequence of events is not likely to correspond with
real-world usage.</p>
<p>That being said, I think these numbers are important. If you remove I/O
from the equation - say you have an SSD with near 0 service times or
have enough memory so you don't need a hard drive - these numbers will
tell what limits you are brushing up against. And, as computers get more
powerful, I think more and more people will cross this threshold and
will be more limited by the build system than the capabilities of their
hardware. (A few months ago, I
<a href="https://groups.google.com/forum/#!topic/mozilla.dev.builds/FJclsTA_OBQ/discussion">measured resource usage</a>
when compiling mozilla-central on Linux and concluded you need roughly
9GB of dedicated memory to compile and link mozilla-central without page
cache eviction. In other words, if building on a machine with only 8GB
of RAM, your hard drive will play a role.)</p>
<p>Anyway, to the numbers.</p>
<p>I think the most important number in the above tables is <strong>49.1%</strong>. That
is the effective CPU utilization during a clobber build. This means that
<strong>during a build, on average half of the available CPU cores are
unused.</strong> Now, I could be generous and bump this number to 50.7%. That's
what the effective CPU utilization is if you remove the ~60s of libxul
linking from the calculation.</p>
<p>The 49.1% has me reaching the following conclusions:</p>
<ol>
<li>I/O wait really matters.</li>
<li>Our recursive use of make is incapable of executing more than 4 items
   at a time on average (assuming 8 cores).</li>
<li>My test machine had more CPU wait than I think.</li>
</ol>
<p>I/O wait is easy to prove: compare times on an SSD or with a similar I/O
bus with near zero service times (e.g. a filled page cache with no
eviction - like a machine with 16+ GB of memory that has built
mozilla-central recently).</p>
<p>A derived time not captured in any table is 11:39. This is the total
CPU time of a clobber build (93:15) divided by the number of cores (8).
<strong>If we had 100% CPU utilization across all cores during builds, we should
be able to build mozilla-central in 11:39.</strong> This is an ideal figure and
won't be reached. As mentioned above, libxul linking takes ~60s itself! I
think 13:00 is a more realistic optimal compilation time for a modern 8
core machine. This points out a startling number: <strong>we are wasting
~12 minutes of wall time due to not fully utilizing CPU cores during
clobber builds.</strong></p>
<p>Another important number is 5059 out of 5589, or 90.5%. That is the CPU
time in a clobber build spent in the C/C++ compiler, as measured by the
speedup of using ccache. It's unlikely we are going to make the C/C++
compiler go much faster (short of not compiling things). So, this is a
big fat block of time we will never be able to optimize. On my machine
<strong>compiling mozilla-central will always take at least ~10:30 wall time,
just in compiling C/C++.</strong></p>
<p>A clobber build with a saturated ccache took 487s wall time but only 383s
CPU time. That's only about 10% total CPU utilization. And, this
represents only 6.8% of total CPU time from the original clobber build.
Although, it is 34.2% of total wall time.</p>
<p>The above means that everything not the C/C++ compiler is horribly
inefficient. These are clown shoes of epic proportions. We're not even
using 1 full core doing build actions outside of the C/C++ compiler!</p>
<p>Because we are inefficient when it comes to core usage, I
think a key takeaway is that throwing more cores at the existing build
system will have diminishing returns. Sure, some parts of the build system
today could benefit from it (mainly js, layout, and dom, as they have
Makefile's with large numbers of source files). But, most of the build
system won't take advantage of many cores. <strong>If you want to throw money
at a build machine, I think your first choice should be an SSD. If you
can't do that, have as much memory as you can so most of your filesystem
I/O is serviced by the page cache, not your disk drive.</strong></p>
<p>In the final table, we isolated how much time <em>make</em> is spending to
just to figure out what to do. That amounts to ~20 seconds wall
time and ~31s CPU time. That leaves ~40s wall and ~55s CPU for non-make
work during no-op builds. Translation: we are doing 40s of wall time work
during no-op builds. Nothing changed. <strong>We are throwing 40s of wall time
away because the build system isn't using proper dependencies and is
doing redundant work.</strong></p>
<p>I've long been a critic of us blowing away parts of <em>dist/</em> and
<em>_tests/</em> at the top of builds. Well, after measuring it, I have mixed
reactions. It only amounts to about ~10s of added time to builds. This
doesn't seem like a lot in the grand scheme of things. However, this is
~10s on top of the ~60s it actually takes to iterate through the tiers.
So, in terms of percentages for no-op builds, it is actually quite
significant.</p>
<p>No-op builds with the existing build system take ~70s under ideal
conditions. In order of time, the breakdown is roughly:</p>
<ul>
<li>~40s for doing redundant work in Makefiles</li>
<li>~20s for make traversal and loading overhead</li>
<li>~10s for repopulating deleted content from <em>dist/</em> and <em>_tests/</em></li>
</ul>
<p>In other words, <strong>~50s of ~70s no-op build times are spent doing work
we have already done.</strong> This is almost purely clown shoes. Assuming we
can't make make traversal and loading faster, the shortest possible
no-op build time will be ~20s.</p>
<p>Splitting things up a bit more:</p>
<ul>
<li>~22s - platform libs make evaluation</li>
<li>~20s - make file traversal and loading (readying for evaluation)</li>
<li>~10s - repopulating deleted content from <em>dist/</em> and <em>_tests/</em></li>
<li>~7s - platform export make evaluation</li>
<li>~5.5 - app libs make evaluation</li>
<li>~4s - platform tools</li>
</ul>
<p>The ~20s for make file traversal and loading is interesting. I suspect
(although I haven't yet measured) that a lot of this is due to the sheer
size of rules.mk. As I
<a href="http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times/">measured</a>
on Friday, the overhead of rules.mk with pymake is significant. I
hypothesized that it would have a similar impact on GNU make. I think a
good amount of this ~20s is similar overhead. I need to isolate,
however. I am tempted to say that if we truly did no-op builds and make
Makefile's load into make faster, we could attain no-op build times in
the ~10s range. I think this is pretty damn good! Even ~20s isn't too
bad. As surprising as it is for me to say it, <strong>recursive make is not
(a significant) part of our no-op build problem</strong>.</p>
<h2>Why is the Build System Slow?</h2>
<p>People often ask the question above. As the data has told me, the
answer, like many to complicated problems, is nuanced.</p>
<p>If you are doing a clobber build on a fresh machine, the build system is
slow because 1) compiling all the C/C++ takes a lot of time (84:19 CPU
time actually) 2) we don't make efficient use of all available cores
when building. Half of the CPU horsepower during a fresh build is
unharnessed.</p>
<p>If you are doing a no-op build, the build system is slow mainly because
it is performing a lot of needless and redundant work. A significant
contributor is the overhead of make, probably due to rules.mk being
large.</p>
<p>If you are doing an incremental build, you will fall somewhere between
either extreme. You will likely get nipped by both inefficient core
usage as well as redundant work. Which one hurts the most depends on the
scope of the incremental change.</p>
<p>If you are building on a machine with a magnetic hard drive (not an
SSD), your builds are slow because you are waiting on I/O. You can
combat this by putting 8+GB of memory in your system and doing your best
to ensure that building mozilla-central can use as much of it as
possible. I highly recommend 12GB, if not 16GB.</p>
<h2>Follow-ups</h2>
<p>The measurements reported in this post are only the tip of the iceberg.
If I had infinite time, I would:</p>
<ul>
<li>Measure other applications, not just browser/Firefox. I've heard that
  mobile/Fennec's build config is far from optimal, for example. I would
  love to quantify that.</li>
<li>Set up buildbot to record and post measurements so we have a dashboard
  of build times. We have some of this today, but the granularity isn't
  as fine as what I captured.</li>
<li>Record per-directory times.</li>
<li>Isolate time spent in different processes (DTrace could be used here).</li>
<li>Capture I/O numbers.</li>
<li>Correlate the impact of I/O service times on build times.</li>
<li>Isolate the overhead of ccache (mainly in terms of I/O).</li>
<li>Obtain numbers on other platforms and systems. Ensure results can be
  reproduced.</li>
</ul>
<h2>Next Steps</h2>
<p>If we want to make our existing recursive make build backend faster, I
recommend the following actions (in no particular order):</p>
<ol>
<li>Factor pieces out of rules.mk into separate .mk files and
   conditionally load based on presence of specific variables. In other
   words, finish what we have started. This definitely cuts down on the
   overhead with pymake (as measured on Friday) and <em>likely</em> makes GNU
   make faster as well.</li>
<li>Don't blow away parts of <em>dist/</em> and <em>_tests/</em> at the top of builds.
   I know this introduces a problem where we could leave orphaned files
   in the object directory. We should solve this problem by having
   proper manifests for everything so we can detect and delete orphans.
   The cheap man's solution is to periodically clobber these
   directories.</li>
<li>Don't perform unnecessary work during no-op builds. I suspect a lot
   of redundant work is due to rules in Makefile's not the rules in
   rules.mk. As we eliminate rules from Makefile's, this problem should
   gradually go away since rules.mk is generally intelligent about these
   things.</li>
<li>More parallelism. I'm not sure how we're going to solve this with
   recursive make short of using PARALLEL_DIRS more and/or consolidating
   Makefile's together.</li>
</ol>
<p>Again, these steps apply to our current recursive make build backend.</p>
<p>Because the most significant losses are due to ungained parallelism, <strong>our
focus should be on increasing parallelism.</strong> We can only do this so much
with recursive make. It is clear now more than ever that recursive make
needs to be replaced with something that can fully realize the potential
of multiple CPU cores. That could be non-recursive make or a separate
build backend altogether.</p>
<p>We will likely not have an official alternate build backend soon. Until
then, there are no shortage of clown shoes that can be looked at.</p>
<p>The redundant work during no-op builds is definitely tempting to
address, as I think that has significant impact to most developers.
Eliminating the absurdly long no-op build times removes the needs for
hacks like <em>smart-make</em> and instills a culture of <em>trust the build
system.</em></p>
<p>I suspect a lot of the redundant work during no-op builds is due to
poorly implemented rules in individual Makefiles rather than on
silliness in rules.mk. Therefore,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">removing rules from Makefile's</a>
again seems to be one of the most important things we can do to make the
build system faster. It also prepares us for implementing newer build
backends, so it is a win-win!</p>]]></content:encoded>
    </item>
    <item>
      <title>Mozilla Build System Overview</title>
      <link>http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview</link>
      <pubDate>Sun, 29 Jul 2012 13:15:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/07/29/mozilla-build-system-overview</guid>
      <description>Mozilla Build System Overview</description>
      <content:encoded><![CDATA[<p>Mozilla's build system is a black box to many. This post attempts to
shed some light onto how it works.</p>
<h2>Configuration File</h2>
<p>The first part of building is creating a configuration file. This
defines what application to build (Firefox, Firefox OS, Fennec, etc) as
well as build options, like to create a release or debug build. This
step isn't technically required, but most people do it.</p>
<p>Configuration files currently exist as <em>mozconfig</em> files. By default,
most people create a <em>.mozconfig</em> file in the root directory of
mozilla-central.</p>
<h2>Interaction</h2>
<p>All interaction with the build system is currently gated through the
<em>client.mk</em> file in the root directory of mozilla-central. Although, I'm
trying to land an alternate (and eventual replacement) to <em>client.mk</em>
called <em>mach</em>. You can read about it in previous posts on this blog.</p>
<p>When you run <em>make -f client.mk</em>, you are invoking the build system and
telling it to do whatever it needs to do build the tree.</p>
<h2>Running Configure</h2>
<p>The first thing <em>client.mk</em> does to a fresh tree is invoke <em>configure</em>.
<em>configure</em> is a shell script in the root directory of the repository.
It is generated from the checked-in <em>configure.in</em> file using the GNU
<em>autoconf</em> utility. I won't go into detail on how autoconf works because
I don't have a beard.</p>
<p><em>configure</em> accomplishes some important tasks.</p>
<p>First, it validates that the build environment is sane. It performs some
sanity testing on the directory tree then looks at the system and build
configuration to make sure everything should work.</p>
<p>It identifies the active compiler, locations of common tools and
utilities, and ensures everything works as needed. It figures out how to
convert desired traits into system-specific options. e.g. the exact
argument to pass to the compiler to enable warnings.</p>
<p>Once <em>configure</em> determines the environment is sane, it writes out what
it learned.</p>
<p>Currently, <em>configure</em> takes what it has learned and invokes the
<em>allmakefiles.sh</em> script in the root directory. This script prints out
the set of Makefile's that will be used to build the tree for the
current configuration. <em>configure</em> takes the output of filenames and
then procedes to generate those files.</p>
<p>Generation of Makefile's is rather simple. In the source tree are a
bunch of <em>.in</em> files, typically <em>Makefile.in</em>. These contain special
markers. <em>configure</em> takes the set of determined configuration variables
and performs substitution of the variable markers in the <em>.in</em> files with
them. The <em>.in</em> files with variables substitutes are written out in the
object directory. There are also some GYP files in the source tree.
<em>configure</em> invokes a tool to convert these into Mozilla-style
Makefile's.</p>
<p><em>configure</em> also invokes <em>configure</em> for other managed projects
in mozilla-central, such as the SpiderMonkey source in <em>js/src</em>.</p>
<p><em>configure</em> finishes by writing out other miscellaneous files in the
object directory.</p>
<h2>Running Make</h2>
<p>The next step of the build is running make. <em>client.mk</em> simply points
GNU make (or pymake) at the <em>Makefile</em> in the top-level directory of the
object directory and essentially says <em>evaluate</em>.</p>
<h3>Build System Tiers</h3>
<p>The build system is broken up into different tiers. Each tier represents
a major phase or product in the build system. Most builds have the
following tiers:</p>
<ol>
<li>base - Builds global dependencies</li>
<li>nspr - Builds NSPR</li>
<li>js - Builds SpiderMonkey</li>
<li>platform - Builds the Gecko platform</li>
<li>app - Builds the configured application (e.g. Firefox, Fennec,
   Firefox OS)</li>
</ol>
<p>Inside each tier are the distinct sub-tiers:</p>
<ol>
<li>export</li>
<li>libs</li>
<li>tools</li>
</ol>
<p>A Makefile generally belongs to 1 main tier. Inside Makefile's or in
other included .mk files (make files that are not typically called
directly by make) are statements which define which directories
belong to which tiers. See
<a href="https://mxr.mozilla.org/mozilla-central/source/toolkit/toolkit-tiers.mk">toolkit-tiers.mk</a>
for an example.</p>
<p>When the top-level Makefile is invoked, it iterates through every tier
and every sub-tier within it. It starts at the first tier and evaluates
the <em>export</em> target on every Makefile/directory defined in it. It then
moves on to the <em>libs</em> target then finally the <em>tools</em> target. When it's
done with the <em>tools</em> target, it moves on to the next tier and does the
same iteration.</p>
<p>For example, we first start by evaluating the <em>export</em> target of the
<em>base</em> tier. Then we evaluate <em>base</em>'s <em>libs</em> and <em>tools</em> tiers. We then
move on to <em>nspr</em> and do the same. And, we keep going. In other words,
the build system makes 3 passes through each tier.</p>
<p>Tiers are composed of directory members. e.g. <em>dom</em> or <em>layout</em>. When
make descends into a tier member directory, it looks for specially named
variables that tell it what sub-directories are also part of this
directory. The <em>DIRS</em> variable is the most common. But, we also use
<em>TEST_DIRS</em>, <em>PARALLEL_DIRS</em>, <em>TOOL_DIRS</em>, and a few others. make will
invoke make for all defined child directories and for the children of
the children, and so on. This is what we mean by <em>recursive make</em>. make
essentially recurses into directory trees, evaluating all the
directories linearly.</p>
<p>Getting back to the tiers, the sub-tiers <em>export</em>, <em>libs</em>, and <em>tools</em>
can be thought of as <em>pre-build</em>, <em>build</em>, and <em>post-build</em> events.
Although, this analogy is far from perfect.</p>
<p><em>export</em> generally prepares the object directory for more comprehensive
building. It copies C/C++ header files into a unified object directory,
generates header files from IDLs files, etc.</p>
<p><em>libs</em> does most of the work. It compiles C++ code and performs lots of
other main work, such as Jar manifest creation.</p>
<p><em>tools</em> does a lot of miscellaneous work. If you have tests enabled,
this is where tests are typically compiled and/or installed, for
example.</p>
<h3>Processing a Makefile</h3>
<p>For each directory inside a tier, make evaluates the Makefile in that
directory for the target/sub-tier specified.</p>
<p>The basic gist of Makefile execution is actually pretty simple.</p>
<p>Mozilla's Makefiles typically look like:</p>
<pre><code>DEPTH := .
topsrcdir := @top_srcdir@
srcdir := @srcdir@
VPATH := @srcdir@

include $(DEPTH)/config/autoconf.mk

IDLSRCS := foo.idl bar.idl
CPPSRCS := hello.cpp world.cpp

include $(topsrcdir)/config/rules.mk
</code></pre>
<p>All the magic in Makefile processing happens in <em>rules.mk</em>. This make file
simply looks for specially named variables (like <em>IDLSRCS</em> or <em>CPPSRCS</em>)
and magically converts them into targets for make to evaluate.</p>
<p>In the above sample Makefile, the <em>IDLSRCS</em> variable will result in an
implicit <em>export</em> target which copies IDLs into the object directory and
compiles them to .h files. <em>CPPSRCS</em> will result in a <em>libs</em> target that
results in each .cpp file being compiled into a .o file.</p>
<p>Of course, there is nothing stopping you from defining targets/rules in
Makefile's themselves. This practice is actually quite widespread.
Unfortunately, it is a bad practice, so you shouldn't do it. The
preferred behavior is to define variables in a Makefile and have
rules.mk magically provide the make targets/rules to do stuff with them.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">Bug 769378</a> tracks
fixing this bad practice.</p>
<h2>Conclusion</h2>
<p>So, there you have it: a very brief overview of how Mozilla's build
system works!</p>
<p>In my next post, I will shed some light onto how much times goes into
different parts of the build system.</p>]]></content:encoded>
    </item>
    <item>
      <title>Makefile Execution Times</title>
      <link>http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times</link>
      <pubDate>Sat, 28 Jul 2012 00:45:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[pymake]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/07/28/makefile-execution-times</guid>
      <description>Makefile Execution Times</description>
      <content:encoded><![CDATA[<p>In my course of hacking about with Mozilla's build system, I've been
using pymake (a Python implementation of GNU make) to parse, examine,
and manipulate make files. In doing so, I've learned some interesting
things, dispelling myths in the process.</p>
<p>People often say that parsing make files is slow and that the sheer
number of Makefile.in's in mozilla-central (Firefox's source tree) is
leading to lots of overhead in make execution. This statement is only
partially correct.</p>
<p><em>Parsing</em> make files is actually pretty fast. Using pymake's parser API,
I'm able to parse every Makefile.in in mozilla-central in under 5
seconds on my 2011 generation MacBook Pro using a single core. Not too
shabby, especially considering that there are about 82,500 lines in all
the Makefile.in's.</p>
<p>Evaluation of make files, however, is a completely different story. You
see, parsing a string containing make file directives is only part of
what needs to be done. Once you've parsed a make file into a statement
list (essentially an AST), you need to load that into a data structure
fit for evaluation. Because of the way make files are evaluated,
you need to iterate through every parsed statement and evaluate it
for side-effects. This occurs before you actually evaluate specific
targets in the make file itself. As I found out, this process can be
time-consuming.</p>
<p>For mozilla-central, the cost of loading the statement list into a data
structure ready for target evaluation takes about 1 minute in aggregate.
And, considering we effectively iterate through every Makefile in
mozilla-central 3 times when building (once for every tier state of
export, libs, and tools), you can multiply this figure by 3.</p>
<p>Put another way, <em>parsing</em> Makefile's is fast: loading them for
target evaluation is slow.</p>
<p>Digging deeper, I uncovered the main source of the additional overhead:
<em>rules.mk</em>.</p>
<p>Nearly every Makefile in mozilla-central has a pattern that looks like:</p>
<pre><code>DEPTH = ../..
topsrcdir = @top_srcdir@
srcdir = @srcdir@
VPATH = @srcdir@

include $(DEPTH)/config/autoconf.mk

&lt;LOCAL MAKE FILE DECLARATIONS&gt;

include $(topsrcdir)/config/rules.mk
</code></pre>
<p>We have a header boilerplate, followed by a bunch of Makefile-specific
variables definitions and rules. Finally, we include the <em>rules.mk</em>
file. This is the make file that takes specially-named variables and
converts them to rules (actions) for make to perform.</p>
<p>A typical Makefile.in is a few dozen lines or so. This often reduces to
maybe a dozen parsed statements. By contrast, <em>rules.mk</em> is massive. It
is currently 1770 lines and may include other make files, bringing the
total to ~3000 lines.</p>
<p>Pymake has an LRU cache that caches the results of <em>parsing</em> make files.
This means it only has to parse a single make file into a statement list
once (assuming no cache eviction). <em>rules.mk</em> is frequently used, so it
should have no eviction. Even if it were evicted, I've measured that
<em>parsing</em> is pretty fast.</p>
<p>Unfortunately, the cache doesn't help with evaluation. For every
Makefile in mozilla-central, pymake will need to evaluate rules.mk
within the context of that specific Makefile. It's impossible to cache
the results of a previous evaluation because the side-effects of rules.mk
are determined by what is defined in the Makefile that includes it.</p>
<p>I performed an experiment where I stripped the <em>include rules.mk</em>
statement from all parsed Makefile.in's. This essentially isolates the
overhead of loading <em>rules.mk</em>. It turns out that all but ~2 seconds
of evaluation time is spent in <em>rules.mk</em>. In other words,
without <em>rules.mk</em>, the Makefile.in's are loaded and ready for evaluation
in just a few seconds (over parsing time), not ~1 minute!</p>
<p>What does this all mean?</p>
<p>Is <em>parsing</em> make files slow? Technically no. <em>Parsing</em> itself is not slow.
It is actually quite fast! Pymake even surprised me at how fast it can
parse all the Makefile.in's in mozilla-central.</p>
<p><em>Loading</em> parsed make file statements to be ready for evaluation is
actually the bit that is slow - at least in the case of mozilla-central.
Specifically, the loading of <em>rules.mk</em> is what constitutes the
overwhelming majority of the time spent loading Makefile's.</p>
<p>That being said, <em>parsing</em> and <em>loading</em> go hand in hand. You almost
never parse a make file without loading and evaluating it. So, if you
consider <em>parsing</em> to include parsing <em>and</em> readying the make file for
execution, there is some truth to the statement that parsing make files
is slow. Someone splitting hairs may say differently.</p>
<p>Is there anything we can do? Good question.</p>
<p>I believe that build times of mozilla-central can be reduced by reducing
the size of <em>rules.mk</em>. Obviously, the content of <em>rules.mk</em> is
important, so we can't just delete content. But, we can be more
intelligent about how it is loaded. For example, we can move pieces of
<em>rules.mk</em> into separate <em>.mk</em> files and conditionally include these
files based on the presence of specific variables. We already do this
today, but only partially: there are still a number of bits of rules.mk
that could be factored out into separate files. By conditionally loading
make file content from <em>rules.mk</em>, we would be reducing the number of
statements that need to be loaded before evaluating each Makefile. And,
this should, in turn, make build times faster. Keep in mind that any
savings will be multiplied by roughly 3 since we do 3 passes over
Makefile's during a build.</p>
<p>To my knowledge, there aren't any bugs yet on file to do this. Given the
measurements I've obtained, I encourage somebody to do this work. Even
if it doesn't reduce build times, I think it will be a win since it will
make the make rules easier to understand since they will be contained in
function-specific files rather than one monolithic file. At worse, we
have better readability. At best, we have better readability and faster
build times. Win!</p>
<p>Finally, I don't know what the impact on GNU make is. Presumably, GNU
make evaluates make files faster than pymake (C is generally faster than
python). Therefore, reducing the size of <em>rules.mk</em> should make GNU make
faster. By how much, I have no clue.</p>]]></content:encoded>
    </item>
    <item>
      <title>Mozilla Build System Plan of Attack</title>
      <link>http://gregoryszorc.com/blog/2012/07/25/mozilla-build-system-plan-of-attack</link>
      <pubDate>Wed, 25 Jul 2012 23:30:00 PDT</pubDate>
      <category><![CDATA[Mozilla]]></category>
      <category><![CDATA[build system]]></category>
      <guid isPermaLink="true">http://gregoryszorc.com/blog/2012/07/25/mozilla-build-system-plan-of-attack</guid>
      <description>Mozilla Build System Plan of Attack</description>
      <content:encoded><![CDATA[<p>Since I published my <a href="http://gregoryszorc.com/blog/2012/06/25/improving-mozilla%27s-build-system/">brain dump
post</a>
on improving Mozilla's build system for Gecko applications (including
Firefox and Firefox OS), there has been some exciting progress.</p>
<p>It wasn't stated in that original post, but the context for that post
was to propose a plan in preparation of a meeting between the core
contributors to the build system at Mozilla. I'm pleased to report that
the plan was generally well-received.</p>
<p>We pretty much all agreed that parts 1, 2, and 3 are all important and
we should actively work towards them. Parts 4, 5, and 6 were a bit more
contentious. There are some good parts and some bad parts. We're not
ready to adopt them just quite yet. (Don't bother reading the original
post to look up what these parts corresponded to - I'll cover that
later.)</p>
<p>Since that post and meeting, there has also been additional discussion
around more specifics. I am going to share with you now where we stand.</p>
<h2>BuildSplendid</h2>
<p><strong>BuildSplendid</strong> is an umbrella term associated with projects/goals to
make the developer experience (including building) better - more
splendid if you will.</p>
<p><strong>BuildSplendid</strong> started as the name of my personal Git branch for
hacking on the build system. I'm encouraging others to adopt the term
because, well, it is easier to refer to (people like project codenames).
If it doesn't stick, that's fine by me - there are other terms that
will.</p>
<h2>BuildFaster</h2>
<p>An important project inside <em>BuildSplendid</em> is <strong>BuildFaster</strong>.</p>
<p><em>BuildFaster</em> focuses on the following goals:</p>
<ol>
<li>Making the <em>existing</em> build system faster, better, stronger (but not
   harder).</li>
<li>Making changes to the build system to facilitate the <em>future</em> use of
   alternate build backends (like Tup or Ninja). Work to enable Visual
   Studio, Xcode, etc project generation also falls here.</li>
</ol>
<p>The distinction between these goals can be murky. But, I'll try.</p>
<p>Falling squarely in #1 are:</p>
<ul>
<li>Switching the buildbot infrastructure to use pymake on Windows</li>
</ul>
<p>Falling in #2 are:</p>
<ul>
<li>Making Makefile.in's data-centric</li>
<li>Supporting multiple build backends</li>
</ul>
<p>Conflated between the two are:</p>
<ul>
<li>Ensuring Makefile's no-op if nothing has changed</li>
<li>Optimizing existing make rules. This involves merging related
  functionality as well as eliminating clown shoes in existing rules.</li>
</ul>
<p>The two goals of <em>BuildFaster</em> roughly map to the short-term and long-term
strategies, respectively. There is consensus that recursive make (our
existing build backend) does not scale and we will plateau in terms of
performance no matter how optimal we make it. That doesn't mean we are
giving up on it: there are things we can and should do so our existing
non-recursive make backend builds faster.</p>
<p>In parallel, we will also work towards the longer-term solution of
supporting alternate build backends. <strong>This includes non-recursive
make</strong> as well as things like Tup, Ninja, and even Visual Studio and
Xcode. (I consider non-recursive make to be a separate build backend
because changing our existing Makefile.in's to support non-recursive
execution effectively means rewriting the input files (Makefile.in's).
At that point, you've invented a new build backend.)</p>
<p>For people who casually interact with the build system, these two goals
will blend together. It is not important for most to know what bucket
something falls under.</p>
<h3>BuildFaster Action Items</h3>
<p><em>BuildFaster</em> action items are being tracked in Bugzilla using the
[BuildFaster:*] whiteboard annotation.</p>
<p>There is no explicit tracking bug for the short-term goal (#1). Instead,
we are relying on the whiteboard annotation.</p>
<p>We are tracking the longer-term goal of supporting alternate build
backends at <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774049">bug 774049</a>.</p>
<p>The most important task to help us reach the goals is to make our
Makefile.in's data centric. This means:</p>
<ul>
<li>Makefile.in's <strong>must</strong> consist of only simple variable assignment</li>
<li>Makefile.in's <strong>must</strong> not rely on being evaluated to perform variable
  assignment.</li>
</ul>
<p>Basically, our build config should be defined by static key-value pairs.</p>
<p>This translates to:</p>
<ul>
<li>Move all rules out of Makefile.in's <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769378">bug 769378</a></li>
<li>Remove use of $(shell) from Makefile.in's <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769390">bug 769390</a></li>
<li>Remove filesystem functions from Makefile.in's <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=769407">bug 769407</a></li>
<li>And more, as we identify the need</li>
</ul>
<p>While we have these tracking bugs on file, we still don't have bugs
filed that track individual Makefile.in's that need updated. <strong>If you
are a contributor, you can help by doing your part to file bugs for your
Makefile.in's.</strong> If your Makefile.in violates the above rules, please
file a bug in the <strong>Build Config</strong> component of the product it is under
(typically <strong>Core</strong>). See the tree of the above bugs for examples.</p>
<p>Also part of <em>BuildFaster</em> (but not relevant to most) is the task of
changing the build system to support multiple backends. Currently,
pieces like <em>configure</em> assume the Makefile.in to Makefile conversion is
always what is wanted. These parts will be worked on by core
contributors to the build system and thus aren't of concern to most.</p>
<p>I will be the first to admit that a lot of the work to <em>purify</em>
Makefile.in's to be data centric will look like a lot of busy work with
little immediate gain. The real benefits to this work will manifest
down the road. That being said, removing rules from Makefile.in's and
implementing things as rules in rules.mk helps ensure that the
implementation is proper (rules.mk is coded by make ninjas and thus
probably does things <em>right</em>). This can lead to faster build times.</p>
<h2>mozbuild</h2>
<p><strong>mozbuild</strong> is a Python package that provides an API to the build system.</p>
<p>What <em>mozbuild</em> will contain is still up in the air because it hasn't
landed in mozilla-central yet. In the code I'm waiting on review to
uplift to mozilla-central, <em>mozbuild</em> contains:</p>
<ul>
<li>An API for invoking the build system backend (e.g. launching make). It
  basically reimplements client.mk because client.mk sucks and needs to
  be replaced.</li>
<li>An API for launching tests easily. This reimplements functionality in
  testsuite-targets.mk, but in a much cleaner way. Running a single test
  can now be done with a single Python function call. This may sound
  boring, but it is very useful. You just import a module and pass a
  filesystem path to a test file to a function and a test runs. Boom!</li>
<li>Module for extracting compiler warnings from build output and storing
  in a persisted database for post-build retrieval. Compiler warning
  tracking \o/</li>
<li>Module for converting build system output into structured logs. It
  records things like time spent in different directories, etc. We could
  use this for tracking build performance regressions. We just need a
  arewe*yet.com domain...</li>
<li>A replacement for .mozconfig's that sucks less (stronger validation,
  settings for not just build config, convenient Python API, etc).</li>
</ul>
<p>And, upcoming features which I haven't yet tried to land in
mozilla-central include:</p>
<ul>
<li>API for extracting metadata from Makefile.in's and other frontend
  files. Want a Python class instance describing the IDLs defined in an
  individual Makefile.in or across the entire tree? <em>mozbuild</em> can provide
  that. This functionality will be used to configure alternate build
  backends.</li>
<li>Build backend API which allows for different build backends to be
  configured (e.g. recursive make, Tup, Ninja, etc). When we support
  multiple build backends, they'll live in <em>mozbuild</em>.</li>
</ul>
<p><em>mozbuild</em> can really be thought of as a clean backend to the build
system and related functionality (like running tests). Everything in
<em>mozbuild</em> could exist in make files or in .py files littered in
<em>build/</em>, <em>config/</em>, etc. But, that would involve maintaining make files
and/or not having a cohesive API. I wanted a clean slate that was free
from the burdens of the existing world. <em>mozbuild</em> was born.</p>
<p>I concede that there will be non-clear lines of division between
<em>mozbuild</em> and other Python packages and/or Mozilla modules. For
example, is <em>mozbuild</em> the appropriate location to define an API for
taking the existing build configuration and launching a Mochitest? I'm
not sure. For now, I'm stuffing functionality inside <em>mozbuild</em> unless
there is a clear reason for it to exist elsewhere. If we want to
separate (because of module ownership issues, for example), we can do
that.</p>
<p>My vision for <em>mozbuild</em> is for it to be the answer to the question
<em>how does the Mozilla build system work?</em> You should be able to say,
<em>look at the code in python/mozbuild and you will have all the answers.</em></p>
<h3>mozbuild Action Items</h3>
<p>The single action item for <em>mozbuild</em> is getting it landed. I have code
written that I think is good enough for an initial landing (with obvious
shortcomings being addressed in follow-up bugs). It just needs some love
from reviewers.</p>
<p>Landing <em>mozbuild</em> is tracked in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=751795">bug 751795</a>. I
initially dropped a monolithic patch. I have since started splitting
bits up into bite-sized patches to facilitate faster, smaller reviews.
(See the blocking bugs.)</p>
<h2>mach</h2>
<p><em>mozbuild</em> is just a Python package - an API. It has no frontend.</p>
<p>Enter <strong>mach</strong>.</p>
<p><strong>mach</strong> is a command-line frontend to <em>mozbuild</em> and beyond.</p>
<p>Currently, <em>mach</em> provides some convenient shortcuts for performing
common tasks. e.g. you can run a test by tab-completing to its filename
using your shell. It also provides nifty output in supported terminals,
including colorizing and a basic progress indicator during building.</p>
<p>You can think of <em>mach</em> as a replacement for <em>client.mk</em> and other make
targets. But, <em>mach</em>'s purpose doesn't end there. My vision for <em>mach</em>
is for it to be the one-stop shop for all your mozilla-central
interaction needs.</p>
<p>From a mozilla-central tree, you should be able to type
<strong>./mach <action></strong> and do whatever you need to do. This could be
building Firefox, running tests, uploading a patch to Bugzilla, etc.</p>
<p>I'm capturing ideas for <em>mach</em> features in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=774108">bug 774108</a>.</p>
<h3>mach Action Items</h3>
<p><em>mach</em> is in the same boat as <em>mozbuild</em>: it's waiting for reviewer
love. If you are interested in reviewing it, please let me know.</p>
<p>Once <em>mach</em> lands, I will be looking to the larger community to improve
it. I want people to go wild implementing features. I believe that
<em>mach</em> will have a significant positive impact on driving contributions
to Mozilla because it will make the process much more streamlined and
less prone to error. I think it is a no-brainer to check in <em>mach</em> as
soon as possible so these wins can be realized.</p>
<p>There is an open question of who will own <em>mach</em> in terms of module
ownership. <em>mach</em> isn't really part of anything. Sure, it interacts with
the build system, testing code, tools, etc. But, it isn't actually part
of any of that. Maybe a new module will be created for it. I'm not
familiar with how the modules system works and I would love to chat with
someone about options here.</p>
<h2>Project Interaction</h2>
<p>How are all of these projects related?</p>
<p><em>BuildFaster</em> is what everyone is working on today. It currently focuses
on making the existing recursive make based build backend faster using
whatever means necessary. <em>BuildFaster</em> could theoretically evolve to
cover other build backends (like non-recursive make). Time will tell
what falls under the <em>BuildFaster</em> banner.</p>
<p><em>mozbuild</em> is immediately focused on providing the functionality to
enable <em>mach</em> to land.</p>
<p><em>mach</em> is about improving the overall developer experience when
it comes to contributing to Firefox and other in-tree applications (like
Firefox OS). It's related to the build system in that it provides a nice
frontend to it. That's the only relationship. <em>mach</em> isn't part of the
build system (at least not yet - it may eventually be used to perform
actions on buildbot machines).</p>
<p>Down the road, <em>mozbuild</em> will gain lots of new features core to the
build system. It will learn how to extract metadata from Makefile.in's
which can be used by other build backends. It will define a build
backend interface and the various build backends will be implemented
in mozbuild. Aspects of the existing build system currently implemented in
make files or in various Python files scattered across the tree will be
added to <em>mozbuild</em> and exposed with a clean, reusable, and testable
API.</p>
<p>Today, <em>BuildFaster</em> is the important project with all the attention.
When <em>mach</em> lands, it will (hopefully) gather a lot of attention. But,
it will be from a different group (the larger contributor community -
not just build system people).</p>
<p><em>mozbuild</em> today is only needed to support <em>mach</em>. But, once <em>mozbuild</em>
lands and <em>mach</em> is on its own, <em>mozbuild</em>'s purpose  will shift to support
<em>BuildFaster</em> and other activities under the <em>BuildSplendid</em> banner.</p>
<h2>Conclusion</h2>
<p>We have a lot of work ahead of us. Please look at the bugs linked above
and help out in any way you can.</p>]]></content:encoded>
    </item>
  </channel>
</rss>
