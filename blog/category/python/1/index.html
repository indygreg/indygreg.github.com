


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Pollinating  
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20101114

-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>Gregory Szorc's Digital Home
</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom" />
<link rel="stylesheet" href="/style/style.css" type="text/css" />
<link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />


  </head>
  <body>
    <div id="wrapper">
      
  <div id="menu">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/notes">Notes</a></li>
    <li><a href="/work.html">Work</a></li>
    <li><a href="/skills.html">Skills</a></li>
    <li><a href="/thoughts.html">Thoughts</a></li>
    <li><a href="/resume.pdf">Resume</a></li>
  </ul>
</div>


      <div id="page">
        <div id="page-bgtop">
          <div id="page-bgbtm">
              <div id="content">
                
  
<div class="blog_post">
  <a name="transferring-python-build-standalone-stewardship-to-astral"></a>
  <h2 class="blog_post_title"><a href="/blog/2024/12/03/transferring-python-build-standalone-stewardship-to-astral" rel="bookmark" title="Permanent Link to Transferring Python Build Standalone Stewardship to Astral">Transferring Python Build Standalone Stewardship to Astral</a></h2>
  <small>December 03, 2024 at 11:30 AM | categories: 

<a href='/blog/category/python'>Python</a>
</small><p/>
  <div class="post_prose">
    
  <p>My <a href="/docs/python-build-standalone/main/">Python Standalone Builds</a> (PBS)
<a href="https://github.com/indygreg/python-build-standalone">project</a> provides
self-contained Python distributions that aim to <em>just work</em>.</p>
<p>PBS Python distributions are used by
<a href="https://github.com/astral-sh/uv">uv</a>, <a href="https://github.com/astral-sh/rye">Rye</a>,
<a href="https://github.com/bazelbuild/rules_python">Bazel's rules_python</a>, and
other tools in the Python ecosystem. The GitHub release artifacts have been
downloaded over 70,000,000 times.</p>
<p>With ruff and uv, Charlie Marsh and the folks at <a href="https://astral.sh/">Astral</a>
have been speedrunning building world class tooling for the Python ecosystem.</p>
<p>As I wrote in <a href="/blog/2024/03/17/my-shifting-open-source-priorities/">My Shifting Open Source Priorities</a>
in March 2024, changes in my life have resulted in me paring back my
open source activities.</p>
<p>Since that post, uv has exploded onto the scene. There have been over 50
million downloads of PBS release assets since March.</p>
<p>Charlie and Astral have stepped up and been outstanding open source
citizens when it comes to evolving PBS to support their work. When I
told Charlie I could use assistance supporting PBS, Astral employees
started contributing to the project. They have built out various
functionality, including Python 3.13 support (including free-threaded
builds), turnkey automated release publishing, and debug symbol stripped
builds to further reduce the download/install size. Multiple Astral
employees now have GitHub permissions to approve/merge PRs and publish
releases. All <a href="https://github.com/indygreg/python-build-standalone/releases">releases</a>
since April have been performed by Astral employees.</p>
<p>PBS today is effectively an Astral maintained project and has been that
way for months. As far as I can tell there have been only positive side effects
of this transition. When I ask myself why I should continue being the GitHub
maintainer, every answer distills down to personal pride or building a personal
brand. I need neither.</p>
<p>I agree with Charlie that formally transferring stewardship of my standalone
Python builds project to Astral is in the best interest of not only the
project itself but of the wider Python community.</p>
<p>On 2024-12-17 I will transfer
<a href="https://github.com/indygreg/python-build-standalone">indygreg/python-build-standalone</a>
into the <a href="https://github.com/astral-sh">astral-sh</a> GitHub organization. From
there, Astral will lead its development and evolution.</p>
<p>I will retain my GitHub permissions on the project and hope to stay involved
in its development, if nothing more than a periodic advisor.</p>
<p>Astral has clearly demonstrated competency for execution and has the needs of
Python developers at heart. I have no doubt that PBS will thrive under Astral's
stewardship. I can't wait to see what they do next.</p>
<p>Astral has <a href="https://astral.sh/blog/python-build-standalone">also blogged</a> about
this announcement and I encourage interested parties to read it as well.</p>

  </div>
</div>



  <hr class="interblog" />
  
<div class="blog_post">
  <a name="my-user-experience-porting-off-setup.py"></a>
  <h2 class="blog_post_title"><a href="/blog/2023/10/30/my-user-experience-porting-off-setup.py" rel="bookmark" title="Permanent Link to My User Experience Porting Off setup.py">My User Experience Porting Off setup.py</a></h2>
  <small>October 30, 2023 at 06:00 AM | categories: 

<a href='/blog/category/python'>Python</a>
</small><p/>
  <div class="post_prose">
    
  <p>In the past week I went to add Python 3.12 support to my
<a href="https://github.com/indygreg/python-zstandard">zstandard</a> Python package.
A few hours into the unexpected yak shave / rat hole, I decided to start
chronicling my experience so that I may share it with the broader Python
community. My hope is that by sharing my (unfortunately painful) end-user
experience that I can draw attention to aspects of Python packaging that
are confusing so that better informed and empowered people can improve
matters and help make future Python packaging decisions to help scenarios
like what I'm about to describe.</p>
<p>This blog post is purposefully verbose and contains a very lightly edited
stream of my mental thoughts. Think of it as a self-assessed user experience
study of Python packaging.</p>
<h2>Some Background</h2>
<p>I'm no stranger to the Python ecosystem or Python packaging. I've been
programming Python for 10+ years. I've even authored a Python application
packaging tool, <a href="https://gregoryszorc.com/docs/pyoxidizer/main/">PyOxidizer</a>.</p>
<p>When programming, I strive to understand how things work. I try to not blindly
copy-paste or cargo cult patterns unless I understand how they work. This
means I often scope bloat myself and slow down velocity in the short term.
But I justify this practice because I find it often pays dividends in the long
term because I actually understand how things work.</p>
<p>I also have a passion for security and supply chain robustness. After you've
helped maintain complex CI systems for multiple companies, you learn the hard
way that it is important to do things like transitively pin dependencies and
reduce surface area for failures so that build automation breaks in reaction
to code changes in your version control, not spooky-action-at-a-distance when
state on a third party server changes (e.g. a new package version is uploaded).</p>
<p>I've been aware of the emergence of <code>pyproject.toml</code>. But I've largely sat on
the sidelines and held off adopting them, mainly for <em>if it isn't broken, don't
fix it</em> reasons. Plus, my perception has been that the tooling still hasn't
stabilized: I'm not going to incur work now if it is going to invite avoidable
churn that could be avoided by sitting on my hands a little longer.</p>
<p>Now, on to my user experience of adding Python 3.12 to python-zstandard and
the epic packaging yak shave that entailed.</p>
<h2>The Journey Begins</h2>
<p>When I attempted to run CI against Python 3.12 on GitHub Actions, running
<code>python setup.py</code>complained that <code>setuptools</code> couldn't be imported.</p>
<p>Huh? I thought <code>setuptools</code> was installed in pretty much every Python
distribution by default? It was certainly installed in all previous Python
versions by the <a href="https://github.com/actions/setup-python">actions/setup-python</a>
GitHub Action. I was aware <code>distutils</code> was removed from the Python 3.12
standard library. But setuptools and distutils are not the same! Why did
<code>setuptools</code> disappear?</p>
<p>I look at the CI logs for the passing Python 3.11 job and notice a message:</p>
<div class="pygments_murphy"><pre><span></span>********************************************************************************
Please avoid running ``setup.py`` directly.
Instead, use pypa/build, pypa/installer or other
standards-based tools.

See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
********************************************************************************
</pre></div>

<p>I had several immediate reactions:</p>
<ol>
<li>OK, maybe this is a sign I should be modernizing to <code>pyproject.toml</code> and
   moving away from <code>python setup.py</code>. Maybe the missing <code>setuptools</code> in the
   3.12 CI environment is a side-effect of this <em>policy</em> shift?</li>
<li>What are <code>pypa/build</code> and <code>pypa/installer</code>? I've never heard of them. I know
   <code>pypa</code> is the Python Packaging Authority (I suspect most Python developers
   don't know this). Are these GitHub <em>org/repo</em> identifiers?</li>
<li>What exactly is a <em>standards-based tool</em>? Is pip not a <em>standards-based tool</em>?</li>
<li>Speaking of pip, why isn't it mentioned? I thought pip was the de facto
   packaging tool and had been for a while!</li>
<li>It's linking a URL for more info. But why is this a link to what looks like
   an individual's blog and not to some more official site, like the setuptools
   or pip docs? Or anything under python.org?</li>
</ol>
<h2>Learning That I Shouldn't Invoke <code>python setup.py</code></h2>
<p>I open <a href="https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html">https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html</a>
in my browser and see a 4,000+ word blog post. Oof. Do I really want/need to read
this? Fortunately, the author included a tl;dr and linked to a
<a href="https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html#summary">summary</a>
section telling me a lot of useful information! It informs me (my commentary in
parentheses):</p>
<ol>
<li><em>The setuptools project has stopped maintaining all direct invocations of setup.py
   years ago</em>. (What?!)</li>
<li><em>There are undoubtedly many ways that your setup.py-based system is broken today,
   even if it's not failing loudly or obviously.</em>. (What?! Surely this can't be
   true. I didn't see any warnings from tooling until recently. How was I supposed
   to know this?)</li>
<li><em>PEP 517, 518 and other standards-based packaging are the future of the Python
   ecosystem</em>. (A ha - a definition of <em>standards-based</em> tooling. I guess I have
   to look at PEP 517 and PEP 518 in more detail. I'm pretty sure these are
   the PEPs that define <code>pyproject.toml</code>.)</li>
<li><em>At this point you may be expecting me to give you a canonical list of the right
   way to do everything that setup.py used to do, and unfortunately the answer here
   is that it's complicated.</em> (You are telling me that we had a working
   <code>python setup.py</code> solution for 10+ years, this workflow is now quasi deprecated,
   and the recommended replacement is <em>it's complicated</em>?! I'm just trying to get my
   package modernized. Why does that need to be <em>complicated</em>?)</li>
<li><em>That said, I can give you some simple "works for most people" recommendations for
   some of the common commands.</em> (Great, this is exactly what I was looking for!)</li>
</ol>
<p>Then I look at the table mapping old ways to new ways. In the <em>new</em> column, it
references the following tools: <a href="https://pypa-build.readthedocs.io/en/stable/">build</a>,
pytest, <a href="https://tox.wiki/en/latest/">tox</a>, <a href="https://tox.wiki/en/latest/">nox</a>,
pip, and <a href="https://twine.readthedocs.io/en/latest/">twine</a>. That's quite the
tooling salad! (And that <code>build</code> tool must be the <em>pypa/build</em> referenced in the
setuptools warning message. One mystery solved!)</p>
<p>I scroll back to the top of the article and notice the date: October 2021. Two
years old. The summary section also mentioned that there's been a lot of
activity around packaging tooling occurring. So now I'm wondering if this blog
post is outdated. Either way, it is clear I have to perform some additional
research to figure out how to migrate off <code>python setup.py</code> so I can be
compliant with the new world order.</p>
<h2>Learning About <code>pyproject.toml</code> and Build Systems</h2>
<p>I had pre-existing knowledge of <code>pyproject.toml</code> as the modern way to define
build system metadata. So I decide to start my research by Googling
<code>pyproject.toml</code>. The first results are:</p>
<ol>
<li><a href="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/">https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/</a></li>
<li><a href="https://stackoverflow.com/questions/62983756/what-is-pyproject-toml-file-for">https://stackoverflow.com/questions/62983756/what-is-pyproject-toml-file-for</a></li>
<li><a href="https://python-poetry.org/docs/pyproject/">https://python-poetry.org/docs/pyproject/</a></li>
<li><a href="https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html">https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html</a></li>
<li><a href="https://godatadriven.com/blog/a-practical-guide-to-setuptools-and-pyproject-toml/">https://godatadriven.com/blog/a-practical-guide-to-setuptools-and-pyproject-toml/</a></li>
<li><a href="https://towardsdatascience.com/pyproject-python-9df8cc092f61">https://towardsdatascience.com/pyproject-python-9df8cc092f61</a></li>
</ol>
<p>I click pip's documentation first because pip is known to me and it seems a
canonical source. Pip's documentation proceeds to link to
<a href="https://peps.python.org/pep-0518/">PEP-518</a>, <a href="https://peps.python.org/pep-0517/">PEP-517</a>,
<a href="https://peps.python.org/pep-0621/">PEP-621</a>, and <a href="https://peps.python.org/pep-0660/">PEP-660</a>
before telling me how projects with <code>pyproject.toml</code> are built, without giving
me - a package maintainer - much useful advice for what to do or how to port from
<code>setup.py</code>. This seems like a dead end.</p>
<p>Then I look at the Stack Overflow link. Again, telling me a lot of what I don't
really care about. (I've somewhat lost faith in Stack Overflow and only really
skimmed this page: I would much prefer to get an answer from a first party
source.)</p>
<p>I click on the <a href="https://python-poetry.org/docs/pyproject/">Poetry</a> link. It
documents TOML fields. But only for the <code>[tool.poetry]</code> section. While I've
heard about Poetry, I know that I probably don't want to scope bloat myself
to learn how Poetry works so I can use it. (No offence meant to the Poetry
project here but I don't perceive my project as needing whatever features
Poetry provides: I'm <em>just</em> trying to publish a simple library package.) I
go back to the search results.</p>
<p>I click on the <a href="https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html">setuptools</a>
link. I'm using setuptools via <code>setup.py</code> so this content looks promising! It gives
me a nice example TOML of how to configure a <code>[build-system]</code> and <code>[project]</code>
metadata. It links to PyPA's <a href="https://packaging.python.org/en/latest/specifications/declaring-project-metadata/">Declaring project metadata</a>
content, which I open in a new tab, as the content seems useful. I continue
reading setuptools documentation. I land on its
<a href="https://setuptools.pypa.io/en/latest/userguide/quickstart.html">Quickstart</a>
documentation, which seems useful. I start reading it and it links to the
<a href="https://pypa-build.readthedocs.io/en/latest/">build</a> tool documentation.
That's the second link to the <code>build</code> tool. So I open that in a new tab.</p>
<p>At this point, I think I have all the documentation on <code>pyproject.toml</code>. But
I'm still trying to figure out what to replace <code>python setup.py</code> with. The
<code>build</code> tool certainly seems like a contender since I've seen multiple
references to it. But I'm still looking for <em>modern</em>, actively maintained
documentation pointing me in a blessed direction.</p>
<p>The next Google link is <a href="https://godatadriven.com/blog/a-practical-guide-to-setuptools-and-pyproject-toml/">A Practical Guide to Setuptools and Pyproject.toml</a>.
I start reading that. I'm immediately confused because it is recommending I
put setuptools metadata in <code>setup.cfg</code> files. But I just read all about defining
this metadata in <code>pyproject.toml</code> files in setuptools' own documentation! Is
this blog post out of date? March 12, 2022. Seems pretty modern. I look at the
setuptools documentation again and see the <code>pyproject.toml</code> metadata pieces are
in version 61.0.0 and newer. I go to
<a href="https://github.com/pypa/setuptools/releases/tag/v61.0.0">https://github.com/pypa/setuptools/releases/tag/v61.0.0</a>
and see version 61.0.0 was released on March 25, 2022. So the fifth Google link
was seemingly obsoleted 13 days after it was published. Good times. I pretend I
never read this content because it seems out of date.</p>
<p>The next Google link is
<a href="https://towardsdatascience.com/pyproject-python-9df8cc092f61">https://towardsdatascience.com/pyproject-python-9df8cc092f61</a>.
I click through. But Medium wants me to log in to read it all and it is unclear
it is going to tell me anything important, so I back out.</p>
<h2>Learning About the <code>build</code> Tool</h2>
<p>I give up on Google for the moment and start reading up on the <code>build</code> tool
from its docs.</p>
<p>The only usage documentation for the <code>build</code> tool is on its
<a href="https://pypa-build.readthedocs.io/en/latest/index.html">root documentation page</a>.
And that documentation basically prints what <code>python -m build --help</code> would
print: says what the tool does but doesn't give any guidance or where I should
be using it or how to replace existing tools (like <code>python setup.py</code> invocations).
Yes, I can piece the parts together and figure out that <code>python -m build</code> can be
used as a replacement for <code>python setup.py sdist</code> and <code>python setup.py bdist_wheel</code>
(and maybe <code>pip wheel</code>?). But <em>should</em> it be the replacement I choose? I make
use of <code>python setup.py develop</code> and the aforementioned blog post recommended
replacing that with <code>python -m pip install -e</code>. Perhaps I can use <code>pip</code> as the
singular replacement for building source distributions and binary wheels so I
have N-1 packaging tools? I keep researching.</p>
<h2>Exploring the Python Packaging User Guide</h2>
<p>I had previously opened <a href="https://packaging.python.org/en/latest/specifications/declaring-project-metadata/">https://packaging.python.org/en/latest/specifications/declaring-project-metadata/</a>
in a browser tab without really looking at it. On second glance, I see it is part
of a broader <a href="https://packaging.python.org/en/latest/">Python Packaging User Guide</a>.
Oh, this looks promising! A guide on how to do what I'm seeking maintained by the
Python Packaging Authority (PyPA), the group who I know to be the, well, authorities
on Python packaging. It is is published under the canonical <code>python.org</code> domain.
Surely the answer will be here.</p>
<p>I immediately click on the link to
<a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/">Packaging Python Projects</a>
to hopefully see what the PyPA folks are recommending.</p>
<h3>Is Hatch the Answer?</h3>
<p>I skim through. I see recommendations to use a <code>pyproject.toml</code> with a
<code>[build-system]</code> to define the build backend. This matches my expectations.
But they are using <em>Hatchling</em> as their build backend. Another tool I don't
really know about. I click through some inline links and eventually arrive
at <a href="https://github.com/pypa/hatch">https://github.com/pypa/hatch</a>. (I'm kind of
confused why the PyPA tutorial said <em>Hatchling</em> when the project and tool is
apparently named <em>Hatch</em>. But whatever.)</p>
<p>I skim Hatch's GitHub README. It looks like a unified packaging tool. Build
system. Package uploading/publishing. Environment management (sounds like a
virtualenv alternative?). This tool actually seems quite nice! I start skimming
the docs. Like Poetry, it seems like this is yet another new tool that I'd need
to learn and would require me to blow up my existing <code>setup.py</code> in order to
adopt. Do I really want to put in that effort? I'm just trying to get
python-zstandard back on the paved road and avoid seemingly deprecated workflows:
I'm not looking to adopt new tooling stacks.</p>
<p>I'm also further confused by the existence of Hatch under the
<a href="https://github.com/pypa">PyPA GitHub Organization</a>. That's the same
GitHub organization hosting the Python packaging tools that are known to
me, namely
<a href="https://github.com/pypa/build">build</a>, <a href="https://github.com/pypa/pip">pip</a>,
and <a href="https://github.com/pypa/setuptools">setuptools</a>. Those three projects
are pinned repositories. (The other three pinned repositories are
<a href="https://github.com/pypa/virtualenv">virtualenv</a>,
<a href="https://github.com/pypa/wheel">wheel</a>, and
<a href="https://github.com/pypa/twine">twine</a>.) Hatch is seemingly a replacement
for pip, setuptools, virtualenv, twine, and possibly other tools. But it isn't
a pinned repository. Yet it is the default tool used in the PyPA maintained
<a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/">Packaging Python Projects</a>
guide. (That guide also suggests using other tools like setuptools,
<a href="https://github.com/pypa/flit">flit</a>, and
<a href="https://github.com/pdm-project/pdm/.">pdm</a>. But the default is Hatch and that has me asking questions. Also,
I didn't initially notice that
<a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/#creating-pyproject-toml">Creating pyproject.toml</a>
has multiple tabs for different backends.)</p>
<p>While Hatch looks interesting, I'm just not getting a strong signal that Hatch
is sufficiently stable or warrants my time investment to switch to. So I go
back to reading the
<a href="https://packaging.python.org/en/latest/">Python Packaging User Guide</a>.</p>
<h3>The PyPA User Guide Search Continues</h3>
<p>As I click around the User Guide, it is clear the PyPA folks really want me
to use <code>pyproject.toml</code> for packaging. I suppose that's the future and that's
a fair ask. But I'm still confused how I should migrate my <code>setup.py</code> to it.
What are the risks with replacing my <code>setup.py</code> with <code>pyproject.toml</code>? Could
I break someone installing my package on an old Linux distribution or old
virtualenv using an older version of setuptools or pip? Will my adoption of
build, hatch, poetry, whatever constitute a one way door where I lock out
users in older environments? My package is downloaded over one million times
per month and if I break packaging <em>someone</em> is likely to complain.</p>
<p>I'm desperately looking for guidance from the PyPA at
<a href="https://packaging.python.org/">https://packaging.python.org/</a> on how to
manage this migration. But I just... can't find it.
<a href="https://packaging.python.org/en/latest/guides/">Guides</a> surprisingly has
nothing on the topic.</p>
<h3>Outdated Tool Recommendations from the PyPA</h3>
<p>Finally I find <a href="https://packaging.python.org/en/latest/guides/tool-recommendations/">Tool recommendations</a>
in the PyPA User Guide. Under
<a href="https://packaging.python.org/en/latest/guides/tool-recommendations/#packaging-tool-recommendations">Packaging tool recommendations</a>
it says:</p>
<ul>
<li><em>Use setuptools to define projects.</em></li>
<li><em>Use build to create Source Distributions and wheels.</em></li>
<li><em>If you have binary extensions and want to distribute wheels for multiple
  platforms, use cibuildwheel as part of your CI setup to build distributable
  wheels.</em></li>
<li><em>Use twine for uploading distributions to PyPI.</em></li>
</ul>
<p>Finally, some canonical documentation from the PyPA that comes out and
suggests what to use!</p>
<p>But my relief immediately turns to questioning whether this tooling
recommendations documentation is up to date:</p>
<ol>
<li>If setuptools is recommended, why does the
   <a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/">Packaging Python Projects</a>
   tutorial use Hatch?</li>
<li>How exactly should I be using setuptools to define projects? Is this
   referring to setuptools as a <code>[build-system]</code> backend? The existence of
   <em>define</em> seemingly implies using <code>setup.py</code> or <code>setup.cfg</code> to define metadata.
   But I thought these distutils/setuptools specific mechanisms were deprecated
   in favor of the more generic <code>pyproject.toml</code>?</li>
<li>Why aren't other tools like Hatch, pip, poetry, flit, and pdm mentioned on
   this page? Where's the guidance on when to use these alternative tools?</li>
<li>There are footnotes referencing <code>distutils</code> as if it is still a modern
   practice. No mention that it was removed from the standard library in
   Python 3.12.</li>
<li>But the <code>build</code> tool is referenced and that tool is relatively new. So the
   docs have to be somewhat up-to-date, right?</li>
</ol>
<p>Sadly, I reach the conclusion that this
<a href="https://packaging.python.org/en/latest/guides/tool-recommendations/">Tool recommendations</a>
documentation is inconsistent with newer documentation and can't be trusted.
But it did mention the <code>build</code> tool and we now have multiple independent
sources steering me in the direction of the <code>build</code> tool (at least for source
distribution and wheel building), so it seems like we have a winner on our
hands.</p>
<h2>Initial Failures Running <code>build</code></h2>
<p>So let's use the <code>build</code> tool. I remember docs saying to invoke it with
<code>python -m build</code>, so I try that:</p>
<div class="pygments_murphy"><pre><span></span>$ python3.12 -m build --help
No module named build.__main__; &#39;build&#39; is a package and cannot be directly executed
</pre></div>

<p>So the <code>build</code> package exists but it doesn't have a <code>__main__</code>. Ummm.</p>
<div class="pygments_murphy"><pre><span></span>$ python3.12R
Python 3.12.0 (main, Oct 23 2023, 19:58:35) [Clang 15.0.0 (clang-1500.0.40.1)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import build
&gt;&gt;&gt; build.__spec__
ModuleSpec(name=&#39;build&#39;, loader=&lt;_frozen_importlib_external.NamespaceLoader object at 0x10d403bc0&gt;, submodule_search_locations=_NamespacePath([&#39;/Users/gps/src/python-zstandard/build&#39;]))
</pre></div>

<p>Oh, it picked up the <code>build</code> directory from my source checkout because
<code>sys.path</code> has the current directory by default. Good times.</p>
<div class="pygments_murphy"><pre><span></span>$ (cd ~ &amp;&amp; python3.12 -m build)
/Users/gps/.pyenv/versions/3.12.0/bin/python3.12: No module named build
</pre></div>

<p>I guess <code>build</code> isn't installed in my Python distribution / environment.
You used to be able to build packages using just the Python standard library.
I guess this battery is no longer included in the stdlib. I shrug and continue.</p>
<h2>Installing <code>build</code></h2>
<p>I go to the <a href="https://pypa-build.readthedocs.io/en/latest/installation.html">Build installation docs</a>.
It says to <code>pip install build</code>. (I thought I read years ago that one should
use <code>python3 -m pip</code> to invoke pip. Strange that a PyPA maintained tool is
telling me to invoke <code>pip</code> directly since I'm pretty sure a lot of the reasons
to use <code>python -m</code> to invoke tools are still valid. But I digress.)</p>
<p>I follow the instructions, installing it to the global <code>site-packages</code>
because I figure I'll use this tool a lot and I'm not a virtual environment
purist:</p>
<div class="pygments_murphy"><pre><span></span>$ python3.12 -m pip install build
Collecting build
  Obtaining dependency information for build from https://files.pythonhosted.org/packages/93/dd/b464b728b866aaa62785a609e0dd8c72201d62c5f7c53e7c20f4dceb085f/build-1.0.3-py3-none-any.whl.metadata
  Downloading build-1.0.3-py3-none-any.whl.metadata (4.2 kB)
Collecting packaging&gt;=19.0 (from build)
  Obtaining dependency information for packaging&gt;=19.0 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata
  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)
Collecting pyproject_hooks (from build)
  Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)
Using cached build-1.0.3-py3-none-any.whl (18 kB)
Using cached packaging-23.2-py3-none-any.whl (53 kB)
Installing collected packages: pyproject_hooks, packaging, build
Successfully installed build-1.0.3 packaging-23.2 pyproject_hooks-1.0.0
</pre></div>

<p>That downloads and installs wheels for <code>build</code>, <code>packaging</code>, and
<code>pyproject_hooks</code>.</p>
<p>At this point the security aware part of my brain is screaming because we
didn't pin versions or SHA-256 digests of any of these packages
anywhere. So if a malicious version of any of these packages is somehow
uploaded to PyPI that's going to be a nightmare software supply chain
vulnerability having similar industry impact as
<a href="https://en.wikipedia.org/wiki/Log4Shell">log4shell</a>. Nowhere in build's
documentation does it mention this or say how to securely install build.
I suppose you have to just know about the supply chain gotchas with
<code>pip install</code> in order to mitigate this risk for yourself.</p>
<h2>Initial Results With <code>build</code> Are Promising</h2>
<p>After getting <code>build</code> installed, <code>python3.12 -m build --help</code> works now
and I can build a wheel:</p>
<div class="pygments_murphy"><pre><span></span>$ python3.12 -m build --wheel .
* Creating venv isolated environment...
* Installing packages in isolated environment... (setuptools &gt;= 40.8.0, wheel)
* Getting build dependencies for wheel...
...
* Installing packages in isolated environment... (wheel)
* Building wheel...
running bdist_wheel
running build
running build_py
...
Successfully built zstandard-0.22.0.dev0-cp312-cp312-macosx_14_0_x86_64.whl
</pre></div>

<p>That looks promising! It seems to have invoked my <code>setup.py</code> without me
having to define a <code>[build-system]</code> in my <code>pyproject.toml</code>! Yay for backwards
compatibility.</p>
<h2>The Mystery of the Missing <code>cffi</code> Package</h2>
<p>But I notice something.</p>
<p>My <code>setup.py</code> script conditionally builds a <code>zstandard._cffi</code> extension
module if <code>import cffi</code> succeeds. Building with <code>build</code> isn't building this
extension module.</p>
<p>Before using <code>build</code>, I had to run <code>setup.py</code> using a <code>python</code> having the
<code>cffi</code> package installed, usually a project-local virtualenv. So let's try
that:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install build cffi
...
$ venv/bin/python -m build --wheel .
...
</pre></div>

<p>And I get the same behavior: no CFFI extension module.</p>
<p>Staring at the output, I see what looks like a smoking gun:</p>
<div class="pygments_murphy"><pre><span></span>* Creating venv isolated environment...
* Installing packages in isolated environment... (setuptools &gt;= 40.8.0, wheel)
* Getting build dependencies for wheel...
...
* Installing packages in isolated environment... (wheel)
</pre></div>

<p>OK. So it looks like <code>build</code> is creating its own isolated environment
(disregarding the invoked Python environment having <code>cffi</code> installed),
installing <code>setuptools &gt;= 40.8.0</code> and <code>wheel</code> into it, and then executing
the build from that environment.</p>
<p>So <code>build</code> sandboxes builds in an ephemeral build environment. This actually
seems like a useful feature to help with deterministic and reproducible
builds: I like it! But at this moment it stands in the way of progress. So
I run <code>python -m build --help</code>, spot a <code>--no-isolation</code> argument and do the
obvious:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m build --wheel --no-isolation .
...
building &#39;zstandard._cffi&#39; extension
...
</pre></div>

<p>Success!</p>
<p>And I don't see any deprecation warnings either. So I <em>think</em> I'm all good.</p>
<p>But obviously I've ventured off the paved road here, as we had to violate
the default constraints of <code>build</code> to get things to work. I'll get back to that
later.</p>
<h2>Reproducing Working Wheel Builds With <code>pip</code></h2>
<p>Just for good measure, let's see if we can use <code>pip wheel</code> to produce wheels,
as I've seen references that this is a supported mechanism for building wheels.</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip wheel .
Processing /Users/gps/src/python-zstandard
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Building wheels for collected packages: zstandard
  Building wheel for zstandard (pyproject.toml) ... done
  Created wheel for zstandard: filename=zstandard-0.22.0.dev0-cp312-cp312-macosx_14_0_x86_64.whl size=407841 sha256=a2e1cc1ad570ab6b2c23999695165a71c8c9e30823f915b88db421443749f58e
  Stored in directory: /Users/gps/Library/Caches/pip/wheels/eb/6b/3e/89aae0b17b638c9cdcd2015d98b85ee7fb3ef00325bb44a572
Successfully built zstandard
</pre></div>

<p>That output is a bit terse, since the setuptools build logs are getting swallowed.
That's fine. Rather than run with <code>-v</code> to get those logs, I manually inspect
the built wheel:</p>
<div class="pygments_murphy"><pre><span></span>$ unzip -lv zstandard-0.22.0.dev0-cp312-cp312-macosx_14_0_x86_64.whl
Archive:  zstandard-0.22.0.dev0-cp312-cp312-macosx_14_0_x86_64.whl
 Length   Method    Size  Cmpr    Date    Time   CRC-32   Name
--------  ------  ------- ---- ---------- ----- --------  ----
    7107  Defl:N     2490  65% 10-23-2023 08:36 7bb42fff  zstandard/__init__.py
   13938  Defl:N     2498  82% 10-23-2023 08:36 8d8d1316  zstandard/__init__.pyi
  919352  Defl:N   366631  60% 10-26-2023 08:28 3aeefc48  zstandard/backend_c.cpython-312-darwin.so
  152430  Defl:N    32528  79% 10-26-2023 05:37 fc1a3c0c  zstandard/backend_cffi.py
       0  Defl:N        2   0% 12-26-2020 16:12 00000000  zstandard/py.typed
    1484  Defl:N      784  47% 10-26-2023 08:28 facba579  zstandard-0.22.0.dev0.dist-info/LICENSE
    2863  Defl:N      847  70% 10-26-2023 08:28 b8d80875  zstandard-0.22.0.dev0.dist-info/METADATA
     111  Defl:N      106   5% 10-26-2023 08:28 878098e6  zstandard-0.22.0.dev0.dist-info/WHEEL
      10  Defl:N       12 -20% 10-26-2023 08:28 a5f38e4e  zstandard-0.22.0.dev0.dist-info/top_level.txt
     841  Defl:N      509  40% 10-26-2023 08:28 e9a804ae  zstandard-0.22.0.dev0.dist-info/RECORD
--------          -------  ---                            -------
 1098136           406407  63%                            10 files
</pre></div>

<p>(Python wheels are just zip files with certain well-defined paths having special
meanings. I know this because I wrote Rust code for <em>parsing</em> wheels as part of
developing PyOxidizer.)</p>
<p>Looks like the <code>zstandard/_cffi.cpython-312-darwin.so</code> extension module is missing.
Well, at least <code>pip</code> is consistent with <code>build</code>! Although somewhat confusingly I don't
see any reference to a separate build environment in the pip output. But I suspect
it is there because <code>cffi</code> is installed in the virtual environment I invoke pip from!</p>
<p>Reading pip help output, I find the relevant argument to not spawn a new
environment and try again:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip wheel --no-build-isolation .
&lt;same exact output except the wheel size and digest changes&gt;

$ unzip -lv zstandard-0.22.0.dev0-cp312-cp312-macosx_14_0_x86_64.whl
...
 1002664  Defl:N   379132  62% 10-26-2023 08:33 48afe5ba  zstandard/_cffi.cpython-312-darwin.so
...
</pre></div>

<p>(I'm happy to see <code>build</code> and <code>pip</code> agreeing on the <em>no isolation</em> terminology.)</p>
<p>OK, so I got <code>build</code> and <code>pip</code> to behave nearly identically. I feel like I
finally understand this!</p>
<p>I also run <code>pip -v wheel</code> and <code>pip -vv wheel</code> to peek under the covers and see
what it's doing. Interestingly, I don't see any hint of a virtual environment
or temporary directory until I go to <code>-vv</code>. I find it interesting that <code>build</code>
presents details about this by default but you have to put <code>pip</code> in very verbose
mode to get it. I'm glad I used <code>build</code> first because the ephemeral build
environment was the source of my missing dependency and <code>pip</code> buried this
important detail behind a ton of other output in <code>-vv</code>, making it much harder
to discover!</p>
<h2>Understanding How <code>setuptools</code> Gets Installed</h2>
<p>When looking at pip's verbose output, I also see references to installing the
<code>setuptools</code> and <code>wheel</code> packages:</p>
<div class="pygments_murphy"><pre><span></span>Processing /Users/gps/src/python-zstandard
  Running command pip subprocess to install build dependencies
  Collecting setuptools&gt;=40.8.0
    Using cached setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)
  Collecting wheel
    Using cached wheel-0.41.2-py3-none-any.whl.metadata (2.2 kB)
  Using cached setuptools-68.2.2-py3-none-any.whl (807 kB)
  Using cached wheel-0.41.2-py3-none-any.whl (64 kB)
  Installing collected packages: wheel, setuptools
  Successfully installed setuptools-68.2.2 wheel-0.41.2
  Installing build dependencies ... done
</pre></div>

<p>There's that <code>setuptools&gt;=40.8.0</code> constraint again. (We also saw it in <code>build</code>.)
I <code>rg 40.8.0</code> my source checkout (note: the <code>.</code> in there are wildcard characters
since <code>40.8.0</code> is a regexp so this could over match) and come up with nothing.
If it's not coming from my code, where is it coming from?</p>
<p>In the pip documentation, <a href="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/#fallback-behaviour">Fallback behaviour</a>
says that a missing <code>[build-system]</code> from <code>pyproject.toml</code> is implicitly
translated to the following:</p>
<div class="pygments_murphy"><pre><span></span><span class="k">[build-system]</span>
<span class="n">requires</span> <span class="o">=</span> <span class="k">[&quot;setuptools&gt;=40.8.0&quot;, &quot;wheel&quot;]</span>
<span class="n">build-backend</span> <span class="o">=</span> <span class="s">&quot;setuptools.build_meta:__legacy__&quot;</span>
</pre></div>

<p>For <code>build</code>, I go to the source code and discover that
<a href="https://github.com/pypa/build/commit/7504e2a7a8ac956b8f2991ae28aa45d8d73b9740">similar functionality</a>
was added in May 2020.</p>
<p>I'm not sure if this default behavior is specified in a PEP or what. But
<code>build</code> and <code>pip</code> seem to be agreeing on the behavior of adding
<code>setuptools&gt;=40.8.0</code> and <code>wheel</code> to their ephemeral build environments and
invoking <code>setuptools.build_meta:__legacy__</code> as the build backend as
implicit defaults if your <code>pyproject.toml</code> lacks a <code>[build-system]</code>. OK.</p>
<h2>Being Explicit About The Build System</h2>
<p>Perhaps I should consider defining <code>[build-system]</code> and being explicit
about things? After all, the tools aren't printing anything indicating they
are assuming implicit defaults and for all I know the defaults could change
in a backwards incompatible manner in any release and break my build. (Although
I would hope to see a deprecation warning before that occurs.)</p>
<p>So I modify my <code>pyproject.toml</code> accordingly:</p>
<div class="pygments_murphy"><pre><span></span><span class="k">[build-system]</span>
<span class="n">requires</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&quot;cffi==1.16.0&quot;</span><span class="p">,</span>
    <span class="s">&quot;setuptools==68.2.2&quot;</span><span class="p">,</span>
    <span class="s">&quot;wheel==0.41.2&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">build-backend</span> <span class="o">=</span> <span class="s">&quot;setuptools.build_meta:__legacy__&quot;</span>
</pre></div>

<p>I pinned all the dependencies to specific versions because I like determinism
and reproducibility. I really don't like when the upload of a new package version
breaks my builds!</p>
<h2>Software Supply Chain Weaknesses in <code>pyproject.toml</code></h2>
<p>When I pinned dependencies in <code>[build-system]</code> in <code>pyproject.toml</code>, the
security part of my brain is screaming over the lack of SHA-256
digest pinning.</p>
<p>How am I sure that we're using well-known, trusted versions of
these dependencies? Are all the transitive dependencies even pinned?</p>
<p>Before <code>pyproject.toml</code>, I used <code>pip-compile</code> from
<a href="https://github.com/jazzband/pip-tools">pip-tools</a> to generate a <code>requirements.txt</code>
containing SHA-256 digests for all transitive dependencies. I would use
<code>python3 -m venv</code> to create a virtualenv,
<code>venv/bin/python -m pip install -r requirements.txt</code> to materialize a (highly
deterministic) set of packages, then run <code>venv/bin/python setup.py</code> to invoke
a build in this stable and securely created environment. (Some) software supply chain
risks averted! But, uh, how do I do that with <code>pyproject.toml</code>
<code>build-system.requires</code>? Does it even support pinning SHA-256 digests?</p>
<p>I skim the PEPs related to <code>pyproject.toml</code> and don't see anything. Surely
I'm missing something.</p>
<p>In desperation I check the pip-tools project and sure enough they
<a href="https://github.com/jazzband/pip-tools#requirements-from-pyprojecttoml">document pyproject.toml integration</a>.
However, they tell you how to feed <code>requirements.txt</code> files into the dynamic
dependencies consumed by the build backend: there's nothing on how to securely
install the build backend itself.</p>
<p>As far as I can tell <code>pyproject.toml</code> has no facilities for securely
installing (read: pinning content digests for all transitive dependencies)
the build backend itself. This is left as an exercise to the reader. But,
um, the build frontend (which I was also instructed to download insecurely
via <code>python -m pip install</code>) is the thing installing the build backend. How am
I supposed to subvert the build frontend to securely install the build backend?
Am I supposed to disable default behavior of using an ephemeral environment
in order to get secure backend installs? Doesn't the ephemeral environment
give me additional, desired protections for build determinism and
reproducibility? That seems <em>wrong</em>.</p>
<p>It kind of looks like <code>pyproject.toml</code> wasn't designed with software supply
chain risk mitigation as a criteria. This is extremely surprising for a build
system abstraction designed in the past few years. I shrug my shoulders and
move on.</p>
<h2>Porting <code>python setup.py develop</code> Invocations</h2>
<p>Now that I figure I have a working <code>pyproject.toml</code>, I move onto removing
<code>python setup.py</code> invocations.</p>
<p>First up is a <code>python setup.py develop --rust-backend</code> invocation.</p>
<p>My <code>setup.py</code> performs <a href="https://github.com/indygreg/python-zstandard/blob/f17569c645618a786ad11a3d51c3baa0b49a311c/setup.py#L65">very crude scanning</a>
of <code>sys.argv</code> looking for command arguments like <code>--system-zstd</code> and
<code>--rust-backend</code> as a way to influence the build. We just sniff these special
arguments and remove them from <code>sys.argv</code> so they don't confuse the setuptools
options parser. (I don't believe this is a blessed way of doing custom options
handling in distutils/setuptools. But it is simple and has worked since I
introduced the pattern in 2016.)</p>
<h2>Is <code>--global-option</code> the Answer?</h2>
<p>With <code>python setup.py</code> invocations going away and a build frontend invoking
<code>setup.py</code>, I need to find an alternative mechanism to pass settings into my
<code>setup.py</code>.</p>
<p><a href="https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html#summary">Why you shouldn't invoke setup.py directly</a>
tells me I should use <code>pip install -e</code>. I'm guessing there's a way to instruct
<code>pip install</code> to pass arguments to <code>setup.py</code>.</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --help
...
  -C, --config-settings &lt;settings&gt;
                              Configuration settings to be passed to the PEP 517 build backend. Settings take the form KEY=VALUE. Use multiple --config-settings options to pass multiple keys to the backend.
  --global-option &lt;options&gt;   Extra global options to be supplied to the setup.py call before the install or bdist_wheel command.
...
</pre></div>

<p>Hmmm. Not really sure which of these to use. But<code>--global-option</code> mentions
<code>setup.py</code> and I'm using <code>setup.py</code>. So I try that:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --global-option --rust-backend -e .
Usage:
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] &lt;requirement specifier&gt; [package-index-options] ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] -r &lt;requirements file&gt; [package-index-options] ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] [-e] &lt;vcs project url&gt; ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] [-e] &lt;local project path&gt; ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] &lt;archive url/path&gt; ...

no such option: --rust-backend
</pre></div>

<p>Oh, duh, <code>--rust-backend</code> looks like an argument and makes pip's own argument
parsing ambiguous as to how to handle it. Let's try that again with
<code>--global-option=--rust-backend</code>:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --global-option=--rust-backend -e .
DEPRECATION: --build-option and --global-option are deprecated. pip 24.0 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859
WARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.
Obtaining file:///Users/gps/src/python-zstandard
  Installing build dependencies ... done
  Checking if build backend supports build_editable ... done
  Getting requirements to build editable ... done
  Preparing editable metadata (pyproject.toml) ... done
Building wheels for collected packages: zstandard
  WARNING: Ignoring --global-option when building zstandard using PEP 517
  Building editable for zstandard (pyproject.toml) ... done
  Created wheel for zstandard: filename=zstandard-0.22.0.dev0-0.editable-cp312-cp312-macosx_14_0_x86_64.whl size=4379 sha256=05669b0a5fd8951cac711923d687d9d4192f6a70a8268dca31bdf39012b140c8
  Stored in directory: /private/var/folders/dd/xb3jz0tj133_hgnvdttctwxc0000gn/T/pip-ephem-wheel-cache-6amdpg21/wheels/eb/6b/3e/89aae0b17b638c9cdcd2015d98b85ee7fb3ef00325bb44a572
Successfully built zstandard
Installing collected packages: zstandard
Successfully installed zstandard-0.22.0.dev0
</pre></div>

<p>I immediately see the three <code>DEPRECATION</code> and <code>WARNING</code> lines (which are color
highlighted in my terminal, yay):</p>
<div class="pygments_murphy"><pre><span></span>DEPRECATION: --build-option and --global-option are deprecated. pip 24.0 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859
WARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.
WARNING: Ignoring --global-option when building zstandard using PEP 517
</pre></div>

<p>Yikes. It looks like <code>--global-option</code> is deprecated and will be removed in pip 24.0.
And, later it says <code>--global-option</code> was ignored. Is that true?!</p>
<div class="pygments_murphy"><pre><span></span>$ ls -al zstandard/*cpython-312*.so
-rwxr-xr-x  1 gps  staff  1002680 Oct 27 11:35 zstandard/_cffi.cpython-312-darwin.so
-rwxr-xr-x  1 gps  staff   919352 Oct 27 11:35 zstandard/backend_c.cpython-312-darwin.so
</pre></div>

<p>Not seeing a <code>backend_rust</code> library like I was expecting. So, yes, it does look
like <code>--global-option</code> was ignored.</p>
<p>This behavior is actually pretty concerning to me. It certainly
seems like at one time <code>--global-option</code> (and a <code>--build-option</code> which doesn't
exist on the <code>pip install</code> command I guess) did get threaded through to <code>setup.py</code>.
However, it no longer does.</p>
<p>I find an entry in the <a href="https://pip.pypa.io/en/stable/news/#v23-1">pip 23.1 changelog</a>:
<code>Deprecate --build-option and --global-option. Users are invited to switch
to --config-settings. (#11859)</code>. <em>Deprecate</em>. What is pip's definition of
<em>deprecate</em>? I click the link to <a href="https://github.com/pypa/pip/pull/11859">#11859</a>.
An open issue with a lot of comments. I scan the issue history to find
referenced PRs and click on <a href="https://github.com/pypa/pip/pull/11861">#11861</a>.
OK, it is just an advertisement. Maybe <code>--global-option</code> never got threaded
through to <code>setup.py</code>? But its help usage text clearly says it is related to
<code>setup.py</code>! Maybe the presence of <code>[build-system]</code> in <code>pyproject.toml</code> is
somehow engaging different semantics that result in <code>--global-option</code> not
being passed to <code>setup.py</code>? The warning message did say
<code>Ignoring --global-option when building zstandard using PEP 517</code>.</p>
<p>I try commenting out the <code>[build-system]</code> section in my <code>pyproject.toml</code>
and trying again. Same result. Huh? Reading the <code>pip install --help</code> output,
I see <code>--no-use-pep517</code> and try it:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --global-option=--rust-backend --no-use-pep517 -e .
...
$ ls -al zstandard/*cpython-312*.so
-rwxr-xr-x  1 gps  staff  1002680 Oct 27 11:35 zstandard/_cffi.cpython-312-darwin.so
-rwxr-xr-x  1 gps  staff   919352 Oct 27 11:35 zstandard/backend_c.cpython-312-darwin.so
-rwxr-xr-x  1 gps  staff  2727920 Oct 27 11:53 zstandard/backend_rust.cpython-312-darwin.so
</pre></div>

<p>Ahh, so pip's default PEP-517 build mode is causing <code>--global-option</code> to get
ignored. So I guess older versions of pip honored <code>--global-option</code> and when
pip switched to PEP-517 build mode by default <code>--global-option</code> just stopped
working and emitted a warning instead. That's quite the backwards incompatible
behavior break! I really wish tools would fail fast when making these kinds of
breaks or at least offer a <code>--warnings-as-errors</code> mode so I can opt into fatal
errors when these kinds of breaks / deprecations are introduced. I would 100%
opt into this since these warnings are often the figurative needle in a haystack
of CI logs and easy to miss. Especially if the build environment is
non-deterministic and new versions of tools like pip get installed <em>randomly</em>
without a version control commit.</p>
<p>Pip's allowing me to specify <code>--global-option</code> but then only issuing a
warning when it is ignored doesn't sit well with me. But what can I do?</p>
<p>It is obvious <code>--global-option</code> is a non-starter here.</p>
<h2>Attempts at Using <code>--config-setting</code></h2>
<p>Fortunately, pip's deprecation message suggests a path forward:</p>
<div class="pygments_murphy"><pre><span></span>A possible replacement is to use --config-settings. Discussion can be found
at https://github.com/pypa/pip/issues/11859
</pre></div>

<p>First, kudos for actionable warning messages. However, the wording says
<em>possible replacement</em>. Are there other alternatives I didn't see in the
<code>pip install --help</code> output?</p>
<p>Anyway, I decide to go with that <code>--config-settings</code> suggestion.</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --config-settings=--rust-backend -e .

Usage:
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] &lt;requirement specifier&gt; [package-index-options] ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] -r &lt;requirements file&gt; [package-index-options] ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] [-e] &lt;vcs project url&gt; ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] [-e] &lt;local project path&gt; ...
  /Users/gps/src/python-zstandard/venv/bin/python -m pip install [options] &lt;archive url/path&gt; ...

Arguments to --config-settings must be of the form KEY=VAL
</pre></div>

<p>Hmmm. Let's try adding a trailing <code>=</code>?</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --config-settings=--rust-backend= -e .
Obtaining file:///Users/gps/src/python-zstandard
  Installing build dependencies ... done
  Checking if build backend supports build_editable ... done
  Getting requirements to build editable ... done
  Preparing editable metadata (pyproject.toml) ... done
Building wheels for collected packages: zstandard
  Building editable for zstandard (pyproject.toml) ... done
  Created wheel for zstandard: filename=zstandard-0.22.0.dev0-0.editable-cp312-cp312-macosx_14_0_x86_64.whl size=4379 sha256=619db9806bc4c39e973c3197a0ddb9b03b49fff53cd9ac3d7df301318d390b5e
  Stored in directory: /private/var/folders/dd/xb3jz0tj133_hgnvdttctwxc0000gn/T/pip-ephem-wheel-cache-gtsvw78d/wheels/eb/6b/3e/89aae0b17b638c9cdcd2015d98b85ee7fb3ef00325bb44a572
Successfully built zstandard
Installing collected packages: zstandard
  Attempting uninstall: zstandard
    Found existing installation: zstandard 0.22.0.dev0
    Uninstalling zstandard-0.22.0.dev0:
      Successfully uninstalled zstandard-0.22.0.dev0
Successfully installed zstandard-0.22.0.dev0
</pre></div>

<p>No warnings or deprecations. That's promising. Did it work?</p>
<div class="pygments_murphy"><pre><span></span>$ ls -al zstandard/*cpython-312*.so
-rwxr-xr-x  1 gps  staff  1002680 Oct 27 12:11 zstandard/_cffi.cpython-312-darwin.so
-rwxr-xr-x  1 gps  staff   919352 Oct 27 12:11 zstandard/backend_c.cpython-312-darwin.so
</pre></div>

<p>No <code>backend_rust</code> extension module. Boo. So what actually happened?</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip -v install --config-settings=--rust-backend= -e .
</pre></div>

<p>I don't see <code>--rust-backend</code> anywhere in that log output. I try with
more verbosity:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip -vvvvv install --config-settings=--rust-backend= -e .
</pre></div>

<p>Still nothing!</p>
<p>Maybe That <code>--</code> prefix is wrong?</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip -vvvvv install --config-settings=rust-backend= -e .
</pre></div>

<p>Still nothing!</p>
<p>I have no clue how <code>--config-settings=</code> is getting passed
to <code>setup.py</code> nor where it is seemingly getting dropped on the floor.</p>
<h2>How Does setuptools Handle <code>--config-settings</code>?</h2>
<p>This must be documented in the setuptools project. So I open those docs in
my web browser and do a <a href="https://setuptools.pypa.io/en/latest/search.html?q=settings&amp;check_keywords=yes&amp;area=default">search for settings</a>.
I open the first three results in separate tabs:</p>
<ol>
<li><a href="https://setuptools.pypa.io/en/latest/deprecated/commands.html?highlight=settings">Running setuptools commands</a></li>
<li><a href="https://setuptools.pypa.io/en/latest/deprecated/commands.html?highlight=settings#configuration-file-options">Configuration File Options</a></li>
<li><a href="https://setuptools.pypa.io/en/latest/deprecated/commands.html?highlight=settings#develop-deploy-the-project-source-in-development-mode">develop - Deploy the project source in "Development Mode"</a></li>
</ol>
<p>That first link has docs on the deprecated setuptools commands and how to
invoke <code>python setup.py</code> directly. (Note: there is a warning box here saying
that <code>python setup.py</code> is deprecated. I guess I somehow missed this document
when looking at setuptools documentation earlier! In hindsight, it appears to
be buried at the figurative bottom of the docs tree as the last item under
a <code>Backward compatibility &amp; deprecated practice section</code>. Talk about burying
the lede!) These docs aren't useful.</p>
<p>The second link also takes me to deprecated documentation related to direct
<code>python setup.py</code> command invocations.</p>
<p>The third link is also useless.</p>
<p>I continue opening search results in new tabs. Surely the answer is in here.</p>
<p>I find an <a href="https://setuptools.pypa.io/en/latest/userguide/extension.html#adding-arguments">Adding Arguments</a>
section telling me that <code>Adding arguments to setup is discouraged as such
arguments are only supported through imperative execution and not supported
through declarative config.</code>. I <em>think</em> that's an obtuse of saying that
<code>sys.argv</code> arguments are only supported via <code>python setup.py</code> invocations
and not via <code>setup.cfg</code> or <code>pyproject.toml</code>? But the example only shows me
how to use <code>setup.cfg</code> and doesn't have any mention of <code>pyproject.toml</code>. So
is this documentation even relevant to <code>pyproject.toml</code>?</p>
<p>Eventually I stumble across
<a href="https://setuptools.pypa.io/en/latest/build_meta.html">Build System Support</a>.
In the <a href="https://setuptools.pypa.io/en/latest/build_meta.html#dynamic-build-dependencies-and-other-build-meta-tweaks">Dynamic build dependencies and other build_meta tweaks</a>
section, I notice the following example code:</p>
<div class="pygments_murphy"><pre><span></span><span class="kn">from</span> <span class="nn">setuptools</span> <span class="kn">import</span> <span class="n">build_meta</span> <span class="k">as</span> <span class="n">_orig</span>
<span class="kn">from</span> <span class="nn">setuptools.build_meta</span> <span class="kn">import</span> <span class="o">*</span>

<span class="k">def</span> <span class="nf">get_requires_for_build_wheel</span><span class="p">(</span><span class="n">config_settings</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_orig</span><span class="o">.</span><span class="n">get_requires_for_build_wheel</span><span class="p">(</span><span class="n">config_settings</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_requires_for_build_sdist</span><span class="p">(</span><span class="n">config_settings</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_orig</span><span class="o">.</span><span class="n">get_requires_for_build_sdist</span><span class="p">(</span><span class="n">config_settings</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
</pre></div>

<p><code>config_settings=None</code>. OK, this might be the <code>--config-settings</code>
values passed to the build frontend getting fed into the build backend.
I Google <code>get_requires_for_build_wheel</code>. One of the top results is
<a href="https://peps.python.org/pep-0517/">PEP-517</a>, which I click on.</p>
<p>I see that the <a href="https://peps.python.org/pep-0517/#build-backend-interface">Build backend interface</a>
consists of a handful of functions that are invoked by the build frontend.
These functions all seem to take a <code>config_settings=None</code> argument. Great,
now I know the interface between build frontends and backends at the Python
API level. Where was I in this yak shave?</p>
<p>I remember from <code>pyproject.toml</code> that one of the lines is
<code>build-backend = "setuptools.build_meta:__legacy__"</code>. That
<code>setuptools.build_meta:__legacy__</code> bit looks like a Python symbol reference.
Since the setuptools documentation didn't answer my question on how to
thread <code>--config-settings</code> into <code>setup.py</code> invocations, I
<a href="https://github.com/pypa/setuptools/blob/2384d915088b960999ca74fb81ce70bffd17b082/setuptools/build_meta.py">open the build_meta.py source code</a>.
(Aside: experience has taught me that when in doubt on how something works,
consult the source code: code doesn't lie.)</p>
<p>I search for <code>config_settings</code>. I immediately see
<code>class _ConfigSettingsTranslator:</code> whose purported job is
<code>Translate config_settings into distutils-style command arguments.
Only a limited number of options is currently supported.</code> Oh, this looks
relevant. But there's a fair bit of code in here. Do I really need to grok
it all? I keep scanning the source.</p>
<p>In a <code>def _build_with_temp_dir()</code> I spot the following code:</p>
<div class="pygments_murphy"><pre><span></span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span> <span class="o">=</span> <span class="p">[</span>
    <span class="o">*</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span>
    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_args</span><span class="p">(</span><span class="n">config_settings</span><span class="p">),</span>
    <span class="o">*</span><span class="n">setup_command</span><span class="p">,</span>
    <span class="s2">&quot;--dist-dir&quot;</span><span class="p">,</span>
    <span class="n">tmp_dist_dir</span><span class="p">,</span>
    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_arbitrary_args</span><span class="p">(</span><span class="n">config_settings</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>

<p>Ahh, cool. It looks to be calling <code>self._global_args()</code> and
<code>self._arbitrary_args()</code> and adding the arguments those functions return
to <code>sys.argv</code> before evaluating <code>setup.py</code> in the current interpreter.</p>
<p>I look at the definition of <code>_arbitrary_args()</code> and I'm onto something:</p>
<div class="pygments_murphy"><pre><span></span><span class="k">def</span> <span class="nf">_arbitrary_args</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_settings</span><span class="p">:</span> <span class="n">_ConfigSettings</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Users may expect to pass arbitrary lists of arguments to a command</span>
<span class="sd">  via &quot;--global-option&quot; (example provided in PEP 517 of a &quot;escape hatch&quot;).</span>
<span class="sd">  ...</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config</span><span class="p">(</span><span class="s2">&quot;--global-option&quot;</span><span class="p">,</span> <span class="n">config_settings</span><span class="p">)</span>
  <span class="n">global_opts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_valid_global_options</span><span class="p">()</span>
  <span class="n">bad_args</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">arg</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">global_opts</span><span class="p">:</span>
          <span class="n">bad_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
          <span class="k">yield</span> <span class="n">arg</span>

  <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config</span><span class="p">(</span><span class="s2">&quot;--build-option&quot;</span><span class="p">,</span> <span class="n">config_settings</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">bad_args</span><span class="p">:</span>
      <span class="n">SetuptoolsDeprecationWarning</span><span class="o">.</span><span class="n">emit</span><span class="p">(</span>
          <span class="s2">&quot;Incompatible `config_settings` passed to build backend.&quot;</span><span class="p">,</span>
          <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">          The arguments </span><span class="si">{bad_args!r}</span><span class="s2"> were given via `--global-option`.</span>
<span class="s2">          Please use `--build-option` instead,</span>
<span class="s2">          `--global-option` is reserved for flags like `--verbose` or `--quiet`.</span>
<span class="s2">          &quot;&quot;&quot;</span><span class="p">,</span>
          <span class="n">due_date</span><span class="o">=</span><span class="p">(</span><span class="mi">2023</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">26</span><span class="p">),</span>  <span class="c1"># Warning introduced in v64.0.1, 11/Aug/2022.</span>
      <span class="p">)</span>
</pre></div>

<p>It looks to peek inside <code>config_settings</code> and handle <code>--global-option</code>
and <code>--build-option</code> specially. But we clearly see <code>--global-option</code> is
deprecated in favor of <code>--build-option</code>.</p>
<p>So is the <code>--config-settings</code> key name <code>--build-option</code> and its value
the <code>setup.py</code> argument we want to insert?</p>
<p>I try that:</p>
<div class="pygments_murphy"><pre><span></span>$ venv/bin/python -m pip install --config-settings=--build-option=--rust-backend -e .
...
$ ls -al zstandard/*cpython-312*.so
-rwxr-xr-x  1 gps  staff  1002680 Oct 27 12:54 zstandard/_cffi.cpython-312-darwin.so
-rwxr-xr-x  1 gps  staff   919352 Oct 27 12:53 zstandard/backend_c.cpython-312-darwin.so
-rwxr-xr-x  1 gps  staff  2727920 Oct 27 12:54 zstandard/backend_rust.cpython-312-darwin.so
</pre></div>

<p>It worked!</p>
<h2>Disbelief Over <code>--config-settings=--build-option=</code></h2>
<p>But, um, <code>--config-settings=--build-option=--rust-backend</code>. We've triple encoded
command arguments here. This feels exceptionally weird. Is that really the
supported/preferred interface? Surely there's something simpler.</p>
<p><code>def _arbitrary_args()</code>'s docstring mentioned <em>escape hatch</em> in the context
of PEP-517. I open PEP-517 and search for that term, finding
<a href="https://peps.python.org/pep-0517/#config-settings">Config settings</a>. Sure
enough, it is describing the mechanism I just saw the source code to. And its
pip example is using <code>pip install</code>'s <code>--global-option</code> and <code>--build-option</code>
arguments. So this all seems to check out. (Although these pip arguments are
deprecated in favor of <code>-C/--config-settings</code>.)</p>
<p>Thinking I missed some obvious documentation, I search the setuptools
documentation for <a href="https://setuptools.pypa.io/en/latest/search.html?q=%22--build-option%22&amp;check_keywords=yes&amp;area=default#">--build-option</a>.
The only hits are in the <a href="https://setuptools.pypa.io/en/latest/history.html#v64-0-0">v64.0.0 changelog entry</a>.
So you are telling me this feature of passing arbitrary config settings into
<code>setup.py</code> via PEP-517 build frontends is only documented in the <em>changelog</em>?!</p>
<p>Ok, I know my <code>setup.py</code> is abusing <code>sys.argv</code>. I'm off the paved road for
passing settings into <code>setup.py</code>. What is the preferred <code>pyproject.toml</code>
era mechanism for passing settings into <code>setup.py</code>? These settings can't
be file based because they are dynamic. There must be a <code>config_settings</code>
mechanism to thread dynamic settings into <code>setup.py</code> that doesn't rely on
these magical <code>--build-option</code> and <code>--global-option</code> settings keys.</p>
<p>I stare and stare at the
<a href="https://github.com/pypa/setuptools/blob/2384d915088b960999ca74fb81ce70bffd17b082/setuptools/build_meta.py">build_meta.py source code</a>
looking for find an answer. But all I see is the <code>def _build_with_temp_dir()</code>
calling into <code>self._global_args()</code> and <code>self._arbitrary_args()</code> to append
arguments to <code>sys.argv</code>. Huh? Surely this isn't the only solution. Surely
there's a simpler way. The setuptools documentation said <em>Adding arguments
to setup is discouraged</em>, seemingly implying a better way of doing it. And
yet the only code I'm seeing in <code>build_meta.py</code> for passing custom
<code>config_settings</code> values in is literally via additional <code>setup.py</code> process
arguments. This can't be right.</p>
<p>I start unwinding my mental stack and browser tabs trying to come across
something I missed.</p>
<p>I again look at
<a href="https://setuptools.pypa.io/en/latest/build_meta.html#dynamic-build-dependencies-and-other-build-meta-tweaks">Dynamic build dependencies and other build_meta tweaks</a>
and see its code is defining a custom <code>[build-system]</code> backend that
does a <code>from setuptools.build_meta import *</code> and defines some custom
build backend interface APIs (which receive <code>config_settings</code>) and then
proxy into the original implementations. While the example is related to
build metadata, I'm thinking <em>do I need to implement my own setuptools
wrapping build backend that implements a custom
<a href="https://peps.python.org/pep-0517/#build-wheel">def build_wheel()</a> to
intercept <code>config_settings</code></em>? Surely this is avoidable complexity.</p>
<h2>Pip's Eager Deprecations</h2>
<p>I keep unwinding context and again notice pip's warning message telling
me <em>A possible replacement is to use <code>--config-settings</code>. Discussion can
be found at https://github.com/pypa/pip/issues/11859</em>.</p>
<p>I open <a href="https://github.com/pypa/pip/issues/11859">pip issue #11859</a>.
Oh, that's the same issue tracking the <code>--global-option</code> deprecation I
encountered earlier. I again scan the issue timeline. It is mostly
references from other GitHub projects. Telltale sign that this
deprecation is creating waves.</p>
<p>The issue is surprisingly light on comments for how many references it
has.</p>
<p>The comment with
<a href="https://github.com/pypa/pip/issues/11859#issuecomment-1664649395">the most emoji reactions</a>
says:</p>
<div class="pygments_murphy"><pre><span></span>Is there an example showing how to use --config-settings with setup.py
and/or newer alternatives? The setuptools documentation is awful and the
top search results are years/decades out-of-date and wildly contradictory.`
</pre></div>

<p>I don't know who you are, @alexchandel, but we're on the same wavelength.</p>
<p>Then the next comment says:</p>
<div class="pygments_murphy"><pre><span></span>Something like this seems to work to pass global options to setuptools.

pip -vv install   --config-setting=&quot;--global-option=--verbose&quot;  .

Passing --build-option in the same way does not work, as setuptools
attempts to pass these to the egg_info command where they are not supported.
</pre></div>

<p>So there it seemingly is, confirmation that my independently derived
solution of <code>--config-settings=--build-option=-...</code> is in fact the way to
go. But this commenter says to use <code>--global-option</code>, which appears to
be deprecated in modern setuptools. Oof.</p>
<p>The next comment links to <a href="https://github.com/pypa/setuptools/issues/3896">pypa/setuptools#3896</a>
where apparently there's been an ongoing conversation since April about how
setuptools should <em>design and document a stable mechanism to pass <code>config_settings</code>
to PEP517 backend</em>.</p>
<p>If I'm interpreting this correctly, it looks like distutils/setuptools - the
primary way to define Python packages for the better part of twenty years -
doesn't have a stable mechanism for passing configuration settings from
modern <code>pyproject.toml</code> <code>[build-system]</code> frontends. Meanwhile pip is deprecating
long-working mechanisms to pass options to <code>setup.py</code> and forcing people to
use a mechanism that setuptools doesn't explicitly document much less say is
stable. This is all taking place <a href="https://mail.python.org/pipermail/distutils-sig/2017-September/031548.html">six years</a>
after PEP-517 was accepted.</p>
<p>I'm kind of at a loss for words here. I understand pip's desire to delete some
legacy code and standardize on the new way of doing things. But it really looks
like they are breaking backwards compatibility for <code>setup.py</code> a bit too
eagerly. That's a <em>questionable</em> decision in my mind, so I
<a href="https://github.com/pypa/pip/issues/11859#issuecomment-1778620671">write a detailed comment on the pip issue</a>
explaining how the interface works and asking the pip folks to hold off on
deprecation until setuptools has a stable, documented solution. Time will
tell what happens.</p>
<h2>In Summary</h2>
<p>What an adventure that Python packaging yak shave was! I feel
like I just learned a whole lot of things that I shouldn't have needed to learn
in order to keep my Python package building without deprecation warnings.
Yes, I scope bloated myself to understanding how things worked because
that's my ethos. But even without that extra work, there's a lot here that I
feel I shouldn't have needed to do, like figure out the undocumented
<code>--config-settings=--build-option=</code> interface.</p>
<p>Despite having ported my <code>python setup.py</code> invocation to modern, PEP-517 build
frontends (<code>build</code> and <code>pip</code>) and gotten rid of various deprecation messages
and warnings, I'm still not sure the implications of that transition. I really
want to understand the trade-offs for adopting <code>pyproject.toml</code> and using the
modern build frontends for doing things. But I couldn't find any documentation
on this anywhere! I don't know basic things like whether my adoption of
<code>pyproject.toml</code> will break end-users stuck on older Python versions or what.
I still haven't ported my project metadata from <code>setup.py</code> to <code>pyproject.toml</code>
because I don't understand the implications. I feel like I'm flying blind and
am bound to make mistakes with undesirable impacts to end-users of my package.</p>
<p>But at least I was able to remove deprecation warnings from my packaging CI
with <em>just</em> several hours of work.</p>
<p>I recognize this post is light on constructive feedback and suggestions
for how to improve matters.</p>
<p>One reason is that I think a lot of the improvements are self-explanatory -
clearer warning messages, better documentation, not deprecating things
prematurely, etc. I prefer to just submit PRs instead of long blog posts. But
I just don't know what is appropriate in some cases: one of the themes of this
post is I just don't grok the state of Python packaging right now.</p>
<p>This post did initially contain a few thousand words expanding on what all I
thought was broken and how it should be fixed. But I stripped the content
because I didn't want my (likely controversial) opinions to distract from
the self-assessed user experience study documented in this post. This content
is probably better posted to a PyPA mailing list anyway, otherwise I'm just
another guy complaining on the Internet.</p>
<p>I've <a href="https://discuss.python.org/t/user-experience-with-porting-off-setup-py/37502">posted a link</a>
to this post to the
<a href="https://discuss.python.org/c/packaging/14">packaging category</a> on
<a href="https://discuss.python.org">discuss.python.org</a> so the PyPA (and other
subscribed parties) are aware of all the issues I stumbled over. Hopefully
people with more knowledge of the state of Python packaging see this post,
empathize with my struggles, and enact meaningful improvements so others
can port off <code>setup.py</code> with a fraction of the effort as it took me.</p>

  </div>
</div>



  <hr class="interblog" />
  
<div class="blog_post">
  <a name="announcing-the-pyoxy-python-runner"></a>
  <h2 class="blog_post_title"><a href="/blog/2022/05/10/announcing-the-pyoxy-python-runner" rel="bookmark" title="Permanent Link to Announcing the PyOxy Python Runner">Announcing the PyOxy Python Runner</a></h2>
  <small>May 10, 2022 at 08:00 AM | categories: 

<a href='/blog/category/python'>Python</a>, <a href='/blog/category/pyoxidizer'>PyOxidizer</a>
</small><p/>
  <div class="post_prose">
    
  <p>I'm pleased to announce the initial release of
<a href="https://pyoxidizer.readthedocs.io/en/latest/pyoxy.html">PyOxy</a>.
Binaries are <a href="https://github.com/indygreg/PyOxidizer/releases/tag/pyoxy%2F0.1.0">available on GitHub</a>.</p>
<p>(Yes, I used my <a href="/blog/2022/04/25/expanding-apple-ecosystem-access-with-open-source,-multi-platform-code-signing/">pure Rust Apple code signing implementation</a>
to remotely sign the macOS binaries from GitHub Actions using a YubiKey
plugged into my Windows desktop: that experience still feels magical
to me.)</p>
<p>PyOxy is all of the following:</p>
<ul>
<li>An executable program used for running Python interpreters.</li>
<li>A single file and highly portable (C)Python distribution.</li>
<li>An alternative <code>python</code> driver providing more control over the
  interpreter than what <code>python</code> itself provides.</li>
<li>A way to make some of PyOxidizer's technology more broadly available without
  using PyOxidizer.</li>
</ul>
<p>Read the following sections for more details.</p>
<h2><code>pyoxy</code> Acts Like <code>python</code></h2>
<p>The <code>pyoxy</code> executable has a <code>run-python</code> sub-command that will essentially
do what <code>python</code> would do:</p>
<pre><code>$ pyoxy run-python
Python 3.9.12 (main, May  3 2022, 03:29:54)
[Clang 14.0.3 ] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;
</code></pre>
<p>A Python REPL. That's familiar!</p>
<p>You can even pass <code>python</code> arguments to it:</p>
<pre><code>$ pyoxy run-python -- -c 'print("hello, world")'
hello, world
</code></pre>
<p>When a <code>pyoxy</code> executable is renamed to any filename beginning with <code>python</code>,
it implicitly behaves like <code>pyoxy run-python --</code>.</p>
<pre><code>$ mv pyoxy python3.9
$ ls -al python3.9
-rwxrwxr-x  1 gps gps 120868856 May 10  2022 python3.9

$ ./python3.9
Python 3.9.12 (main, May  3 2022, 03:29:54)
[Clang 14.0.3 ] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;
</code></pre>
<h2>Single File Python Distributions</h2>
<p>The official <code>pyoxy</code> executables are built with PyOxidizer and leverage the
Python distributions provided by my
<a href="https://github.com/indygreg/python-build-standalone/">python-build-standalone</a>
project. On Linux and macOS, a fully featured Python interpreter and its library
dependencies are statically linked into <code>pyoxy</code>. The <code>pyoxy</code> executable also embeds
a copy of the Python standard library and imports it from memory using the
<a href="https://pyoxidizer.readthedocs.io/en/latest/oxidized_importer.html">oxidized_importer</a>
Python extension module.</p>
<p>What this all means is that the official <code>pyoxy</code> executables can function as
single file CPython distributions! Just download a <code>pyoxy</code> executable, rename it
to <code>python</code>, <code>python3</code>, <code>python3.9</code>, etc and it should behave just like a normal
<code>python</code> would!</p>
<p>Your Python installation has never been so simple. And fast: <code>pyoxy</code> should be
a few milliseconds faster to initialize a Python interpreter mostly because of
<code>oxidized_importer</code> and it avoiding filesystem overhead to look for and load
<code>.py[c]</code> files.</p>
<h2>Low-Level Control Over the Python Interpreter with YAML</h2>
<p>The <code>pyoxy run-yaml</code> command is takes the path to a YAML file defining the
embedded Python interpreter configuration and then launches that Python
interpreter in-process:</p>
<pre><code>$ cat &gt; hello_world.yaml &lt;&lt;EOF
---
allocator_debug: true
interpreter_config:
  run_command: 'print("hello, world")'
...
EOF

$ pyoxy run-yaml hello_world.yaml
hello, world
</code></pre>
<p>Under the hood, PyOxy uses the
<a href="https://docs.rs/pyembed/0.20.0/pyembed/">pyembed</a> Rust crate to manage embedded
Python interpreters. The YAML document that PyOxy uses is simply deserialized
into a
<a href="https://docs.rs/pyembed/0.20.0/pyembed/struct.OxidizedPythonInterpreterConfig.html">pyembed::OxidizedPythonInterpreterConfig</a>
Rust struct, which <code>pyembed</code> uses to spawn a Python interpreter. This Rust struct
offers near complete control over how the embedded Python interpreter behaves: it
even allows you to tweak settings that are impossible to change from environment
variables or <code>python</code> command arguments! (Beware: this power means you can
easily cause the interpreter to crash if you feed it a bad configuration!)</p>
<h2>YAML Based Python Applications</h2>
<p><code>pyoxy run-yaml</code> ignores all file content before the YAML <code>---</code> start document
delimiter. This means that on UNIX-like platforms
you can create <em>executable YAML</em> files defining your Python application. e.g.</p>
<pre><code>$ mkdir -p myapp
$ cat &gt; myapp/__main__.py &lt;&lt; EOF
print("hello from myapp")
EOF

$ cat &gt; say_hello &lt;&lt;"EOF"
#!/bin/sh
"exec" "`dirname $0`/pyoxy" run-yaml "$0" -- "$@"
---
interpreter_config:
  run_module: 'myapp'
  module_search_paths: ["$ORIGIN"]
...
EOF

$ chmod +x say_hello

$ ./say_hello
hello from myapp
</code></pre>
<p>This means that to <em>distribute</em> a Python application, you can drop a copy
of <code>pyoxy</code> in a directory then define an executable YAML file masquerading
as a shell script and you can run Python code with as little as two files!</p>
<h2>The Future of PyOxy</h2>
<p>PyOxy is very young. I hacked it together on a weekend in September 2021.
I wanted to shore up some functionality before releasing it then. But I
got perpetually sidetracked and never did the work. I figured it would be
better to make a smaller splash with a lesser-baked product now than wait
even longer. Anyway...</p>
<p>As part of building
<a href="https://pyoxidizer.readthedocs.io/en/stable/pyoxidizer.html">PyOxidizer</a> I've
built some peripheral technology:</p>
<ul>
<li>Standalone and highly distributable Python builds via the
  <a href="https://github.com/indygreg/python-build-standalone">python-build-standalone</a>
  project.</li>
<li>The <a href="https://docs.rs/pyembed/0.20.0/pyembed/">pyembed</a> Rust crate for managing
  an embedded Python interpreter.</li>
<li>The <a href="https://pyoxidizer.readthedocs.io/en/stable/oxidized_importer.html">oxidized_importer</a>
  Python package/extension for importing modules from memory, among other
  things.</li>
<li>The <a href="https://pyoxidizer.readthedocs.io/en/latest/oxidized_importer_packed_resources.html">Python packed resources</a>
  data format for representing a collection of Python modules and resource
  files for efficient loading (by <code>oxidized_importer</code>).</li>
</ul>
<p>I conceived PyOxy as a vehicle to enable people to leverage PyOxidizer's
technology without imposing PyOxidizer onto them. I feel that PyOxidizer's
broader technology is generally useful and too valuable to be gated behind
using PyOxidizer.</p>
<p>PyOxy is only officially released for Linux and macOS for the moment.
It definitely builds on Windows. However, I want to improve the single file
executable experience before officially releasing PyOxy on Windows. This
requires an extensive overhaul to <code>oxidized_importer</code> and the way it
serializes Python resources to be loaded from memory.</p>
<p>I'd like to add a sub-command to produce a
<a href="https://pyoxidizer.readthedocs.io/en/latest/oxidized_importer_packed_resources.html">Python packed resources</a>
payload. With this, you could bundle/distribute a Python application as
<code>pyoxy</code> plus a file containing your application's packed resources alongside
YAML configuring the Python interpreter. Think of this as a more modern and
faster version of the venerable <code>zipapp</code> approach. This would enable PyOxy to
satisfy packaging scenarios provided by tools like Shiv, PEX, and XAR.
However, unlike Shiv and PEX, <code>pyoxy</code> also provides an embedded Python
interpreter, so applications are much more portable since there isn't
reliance on the host machine having a Python interpreter installed.</p>
<p>I'm really keen to see how others want to use <code>pyoxy</code>.</p>
<p>The YAML based control over the Python interpreter could be super useful for
testing, benchmarking, and general Python interpreter configuration
experimentation. It essentially opens the door to things previously only
possible if you wrote code interfacing with Python's C APIs.</p>
<p>I can also envision tools that hide the existence of Python wanting to
leverage the single file Python distribution property of <code>pyoxy</code>. For
example, tools like Ansible could copy <code>pyoxy</code> to a remote machine to provide
a well-defined Python execution environment without having to rely on what
packages are installed. Or <code>pyoxy</code> could be copied into a container or
other sandboxed/minimal environment to provide a Python interpreter.</p>
<p>And that's PyOxy. I hope you find it useful. Please file any bug reports
or feature requests in <a href="https://github.com/indygreg/PyOxidizer/issues">PyOxidizer's issue tracker</a>.</p>

  </div>
</div>



  <hr class="interblog" />
  
<div class="blog_post">
  <a name="announcing-the-0.9-release-of-pyoxidizer"></a>
  <h2 class="blog_post_title"><a href="/blog/2020/10/18/announcing-the-0.9-release-of-pyoxidizer" rel="bookmark" title="Permanent Link to Announcing the 0.9 Release of PyOxidizer">Announcing the 0.9 Release of PyOxidizer</a></h2>
  <small>October 18, 2020 at 10:00 PM | categories: 

<a href='/blog/category/python'>Python</a>, <a href='/blog/category/pyoxidizer'>PyOxidizer</a>
</small><p/>
  <div class="post_prose">
    
  <p>I have decided to make up for the 6 month lull between PyOxidizer's
0.7 and 0.8 releases by releasing
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/">PyOxidizer</a> 0.9 just 1 week
after 0.8!</p>
<p>The full 0.9 changelog is found
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/history.html#version-0-9-0">in the docs</a>.
First time user? See the
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/getting_started.html">Getting Started</a>
documentation.</p>
<p>While the 0.9 release is far smaller in terms of features compared to 0.8,
it is an important release because of progress closing compatibility gaps.</p>
<h2>Build a <code>python</code> Executable</h2>
<p>PyOxidizer 0.8 quietly shipped the ability to build executables that
behave like <code>python</code> executables via enhancements to the configurability of
embedded Python interpreters.</p>
<p>PyOxidizer 0.9 made some minor changes to make this scenario work better
and there is even
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/packaging_python_executable.html">official documentation</a>
on how to achieve this. So now you can emit a <code>python</code> executable next to your
application's executable. Or you could use PyOxidizer to build a highly portable,
self-contained <code>python</code> executable and ship your Python scripts next to it,
using PyOxidizer's <code>python</code> in your <code>#!</code>.</p>
<h2>Support Packaging Files as Files for Maximum Compatibility</h2>
<p>There is a long-tail of Python packages that don't <em>just work</em> with
PyOxidizer. A subset of these packages don't work because of bugs with how
PyOxidizer attempts to classify files as specific types of Python resources.</p>
<p>The way that normal Python works is you materialize a bunch of files on
the filesystem and at run-time the filesystem-based importer <code>stat()</code>s a
bunch of paths until it finds a candidate file satisfying the <code>import</code>
request. This works of course. But it is inefficient. Since PyOxidizer has
awareness of every resource being packaged at build time, it attempts to
index all known resources and serialize them to an efficient data structure
so finding and loading a resource can be extremely quick (effectively just a
hashmap lookup in Rust code to resolve the memory address of data).</p>
<p>PyOxidizer's approach does work in the majority of cases. But there are
edge cases. For example, NumPy's binary wheels have installed file paths
like <code>numpy.libs/libopenblasp-r0-ae94cfde.3.9.dev.so</code>. The <code>numpy.libs</code>
directory is not a valid Python package directory since it has a <code>.</code> and
since it doesn't have an <code>__init__.py[c]</code> file. This is a case where
PyOxidizer's code for turning files into <em>resources</em> is currently confused.</p>
<p>It is tempting to argue that file layouts like NumPy's are <em>wrong</em>. But
there doesn't seem to be any formal specification preventing the use of
such layouts. The arbiter of truth here is what Python packaging tools
accept and the current code for installing <em>wheels</em> gladly accepts file
layouts like these. So I've accepted that PyOxidizer is just going to have
to support edge cases like this. (I've captured more details about this
particular issue
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/technotes.html#ambiguous-file-classification">in the docs</a>).</p>
<p>Anyway, PyOxidizer 0.9 ships a new, simpler mode for handling files:
<em>files mode</em>. In <a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/packaging_resources.html#classified-resources-versus-files">files mode</a>,
PyOxidizer disables its code for <em>classifying</em> files as typed Python
resources (like module sources and extension modules) and instead treats
a file as... a file.</p>
<p>When in files mode, actions that invoke Python packaging tools return
files objects instead of classified resources. If you then add these files
for packaging, those files are materialized on the filesystem next to your
built executable. You can then use Python's standard filesystem importer
to load these files at run-time.</p>
<p>This allows you to use PyOxidizer with packages like NumPy that were
previously incompatible due to bugs with file/resource classification.
In fact, getting NumPy working with PyOxidizer is
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/packaging_additional_files.html#installing-unclassified-files-on-the-filesystem">now in the official documentation</a>!</p>
<p><em>Files mode</em> is still in its infancy. There exists code for embedding
files data in the produced executable. I plan to eventually teach PyOxidizer's
run-time code to extract these embedded files to a temporary directory,
SquashFS FUSE filesystem, etc. This is the approach that other Python
packaging tools like PyInstaller and XAR use. While it is less efficient, this
approach is highly compatible with Python code in the wild since you sidestep
issues with <code>__file__</code> and other assumptions about installed file layouts. So
it makes sense for PyOxidizer to provide support for this so you can still
achieve the friendliness of a self-contained executable without worrying
about compatibility. Look for improvements to <em>files mode</em> in future releases.</p>
<p>And to help debug issues with PyOxidizer's file handling and resource
classification, the new
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/managing_projects.html#debugging-resource-scanning-and-identification-with-find-resources">pyoxidizer find-resources</a>
command can be used to invoke PyOxidizer's code for scanning and classifying
files. Hopefully this makes it easier to diagnose bugs in this critical
component of PyOxidizer!</p>
<h2>Some Important Bug Fixes</h2>
<p>PyOxidizer 0.8 shipped with some pretty annoying bugs and behavior quirks.</p>
<p>The ability to set custom <code>sys.path</code> values via Starlark was broken. How I
managed to ship that, I'm not sure. But it is fixed in 0.9.</p>
<p>Another bug I can't believe I shipped was
the <code>PythonExecutable.read_virtualenv()</code> Starlark method being broken due to
a typo. You can read from virtualenvs again in PyOxidizer 0.9.</p>
<p>Another important improvement is in the default Python interpreter
configuration. We now automatically initialize Python's locales configuration
by default. Without this, the encoding of filesystem paths and <code>sys.argv</code> may
not have been correct. If someone passed a non-ASCII argument, the Python <code>str</code>
value was likely mangled. PyOxidizer built binaries should behave reasonably
by default now. The <a href="https://github.com/indygreg/PyOxidizer/issues/294">issue</a>
is a good read if the subtle behaviors of how encodings work in Python and on
different operating systems is interesting to you.</p>
<h2>Better Binary Portability Documentation</h2>
<p>The documentation on
<a href="https://pyoxidizer.readthedocs.io/en/v0.9.0/packaging_binary_compatibility.html">binary portability</a>
has been overhauled. Hopefully it is much more clear about the capabilities
of PyOxidizer to produce a binary that <em>just works</em> on other machines.</p>
<p>I eventually want to get PyOxidizer to a point where users don't have to
think about binary portability. But until PyOxidizer starts generating
installers and providing the ability to run builds in deterministic and
reproducible environments, it is sadly a problem that is being externalized
to end users.</p>
<h2>In Conclusion</h2>
<p>PyOxidizer 0.9 is a small release representing just 1 week of work. But
it contains some notable features that I wanted to get out the door.</p>
<p>As always, please report any issues or feedback in the
<a href="https://github.com/indygreg/PyOxidizer/issues/new">GitHub issue tracker</a>
or the <a href="https://groups.google.com/forum/#!forum/pyoxidizer-users">users mailing list</a>.</p>

  </div>
</div>



  <hr class="interblog" />
  
<div class="blog_post">
  <a name="announcing-the-0.8-release-of-pyoxidizer"></a>
  <h2 class="blog_post_title"><a href="/blog/2020/10/12/announcing-the-0.8-release-of-pyoxidizer" rel="bookmark" title="Permanent Link to Announcing the 0.8 Release of PyOxidizer">Announcing the 0.8 Release of PyOxidizer</a></h2>
  <small>October 12, 2020 at 12:45 AM | categories: 

<a href='/blog/category/python'>Python</a>, <a href='/blog/category/pyoxidizer'>PyOxidizer</a>
</small><p/>
  <div class="post_prose">
    
  <p>I am very excited to announce the 0.8 release of
<a href="https://pyoxidizer.readthedocs.io/en/stable/">PyOxidizer</a>, a modern
Python application packaging tool. You can find the full changelog
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/history.html">in the docs</a>.
First time user? See the
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/getting_started.html">Getting Started</a>
documentation.</p>
<p>Foremost, I apologize that this release took so long to publish (0.7 was
released on 2020-04-09). I fervently believe that frequent releases are
a healthy software development practice. And 6 months between PyOxidizer
releases was way too long. Part of the delay was due to world events
(it has proven difficult to focus on... anything given a global pandemic,
social unrest, and wildfires further undermining any resemblance of
lifestyle normalcy in California). Another contributing factor was I was
waiting on a few 3rd party Rust crates to have new versions published to
crates.io (you can't release a crate to crates.io unless all your
dependencies are also published there).</p>
<p>Release delay and general life hardships aside, the 0.8 release is here
and it is full of notable improvements!</p>
<h2>Python 3.8 and 3.9 Support</h2>
<p><strong>PyOxidizer 0.8 now targets Python 3.8 by default and support for Python
3.9 is available</strong> by tweaking configuration files. Previously, we only
supported Python 3.7 and this release drops support for Python 3.7. I feel
a bit bad for dropping compatibility. But Python 3.8 introduced a
<a href="https://docs.python.org/3/c-api/init_config.html">new C API</a> for initializing
Python interpreters (thank you Victor Stinner!) and this makes PyOxidizer's
run-time code for interfacing with Python interpreters vastly simpler.
I decided that given the beta nature of PyOxidizer, it wasn't worth
maintaining complexity to continue to support Python 3.7. I'm optimistic
that I'll be able to support Python 3.8 as a baseline for a while.</p>
<h1>Better Default Packaging Settings</h1>
<p>PyOxidizer started as a science experiment of sorts to see if I could
achieve the elusive goal of producing a single file executable providing
a Python application. I was successful in proving this hypothesis. But the
cost to achieving this outcome was rather high in terms of end-user
experience: in order to produce single file executables, you had to break
a lot of assumptions about how Python typically works and this in turn broke
a lot of Python code and packages in the wild.</p>
<p>In other words, <strong>PyOxidizer's opinionated defaults of producing a single file
executable were externalizing hardship on end-users and preventing them from
using PyOxidizer.</strong></p>
<p>PyOxidizer 0.8 contains a handful of changes to defaults that should hopefully
lessen the friction.</p>
<p>On Windows, the default Python distribution now has a more traditional
build configuration (using <code>.pyd</code> extension modules and a <code>pythonXY.dll</code>
file). <strong>This means that PyOxidizer can consume pre-built extension modules
without having to recompile them from source.</strong> If you publish a Windows
binary wheel on PyPI, in many cases it will <em>just work</em> with PyOxidizer
0.8! (There are some notable exceptions to this, such as <em>numpy</em>, which is
doing wonky things with the location of shared libraries in wheels - but
I aim to fix this soon.)</p>
<p>Also on Windows, we no longer attempt to embed Python extension modules
(<code>.pyd</code> files) and their shared library dependencies in the produced
binary and load them from memory by default. This is because PyOxidizer's
from-memory library loader didn't work in all cases. For example, some
OpenSSL functionality used by the <code>_ssl</code> module in the standard library
didn't work, preventing Python from establishing TLS connections. The old
mode enabling you to produce a single file executable on Windows is still
available. But you have to opt in to it (at the likely cost of more
packaging and compatibility pain).</p>
<h2>Starlark Configuration Overhaul</h2>
<p>PyOxidizer 0.8 contains a <strong>ton</strong> of changes to its Starlark configuration
files. There are so many changes that you may find it easier to port to
PyOxidizer 0.8 by creating a new configuration file rather than attempting
to port an existing one.</p>
<p>I apologize for this churn and recognize it will be disruptive. However,
this churn needed to happen for various reasons.</p>
<p>Much of the old Starlark configuration semantics was rooted in the days
when configuration files were static TOML files. Now that configuration
files provide the power of a (Python-inspired) programming language, we
are free to expose much more flexibility. But that flexibility requires
refactoring things so the experience feels more <em>native</em>.</p>
<p>Many changes to Starlark were rooted in necessity. For example,
the methods for invoking <code>setup.py</code> or <code>pip install</code> used to live on a
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/config_type_python_distribution.html">Python distribution type</a>
and have been moved to a
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/config_type_python_executable.html">type representing executables</a>.
This is because the binary we are targeting influences how
packaging actions behave. For example, if the binary only supports
loading resources from memory (as opposed to standalone files), we need
to know that when invoking the packaging tool so we can produce files
(notably Python extension modules) compatible with the destination.</p>
<p>A major change to Starlark in 0.8 is around resource location handling.
Before, you could define a static string denoting the <em>resources policy</em>
for where things should be placed. And there were 10+ methods for
adding different resource types (source, bytecode, extensions, package
data) to different load locations (memory, filesystem). This mechanism
is vastly simplified and more powerful in PyOxidizer 0.8!</p>
<p>In PyOxidizer 0.8, there is a single
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/config_type_python_executable.html#pythonexecutable-add-python-resource">add_python_resource()</a>
method for adding a resource to a binary and the Starlark objects you add
can denote where they should be added by
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/config_resource_add_attributes.html">defining attributes on those objects</a>.</p>
<p>Furthermore, you can
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/packaging_resources.html#using-callbacks-to-influence-resource-attributes">define a Starlark function</a>
that is called when resource objects are created to apply custom packaging
<em>rules</em> using custom Starlark code defined in your PyOxidizer config file.
So rather than having everyone try to abide by a few pre-canned <em>policies</em> for
packaging resources, you can define a proper function in your config file
that can be as complex as you want/need it to be! I feel this is vastly simpler
and more powerful than implementing a custom DSL in static configuration files
(like TOML, JSON, YAML, etc).</p>
<p>While the ability to implement your own arbitrarily complex packaging
policies is useful, there is a new
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/config_type_python_packaging_policy.html">PythonPackagingPolicy</a>
Starlark type with enough flexibility to suit most needs.</p>
<h2>Shipping <code>oxidized_importer</code></h2>
<p>During the development of PyOxidizer 0.8, I broke out the custom
Rust-based Python <em>meta-path importer</em> used by PyOxidizer's run-time code
into a standalone Python package. This sub-project is called
<code>oxidized_importer</code> and I previously
<a href="/blog/2020/05/10/using-rust-to-power-python-importing-with-oxidized_importer/">blogged about it</a>.</p>
<p>PyOxidizer 0.8 ships <code>oxidized_importer</code> and all of its useful APIs
available to Python. Read more in the
<a href="https://pyoxidizer.readthedocs.io/v0.8.0/latest/oxidized_importer.html">official docs</a>.
The new Python APIs should make debugging issues with PyOxidizer-packaged
applications vastly simpler: I found them invaluable when tracking down
user-reported bugs!</p>
<h2>Tons of New Tests and Refactored Code</h2>
<p>PyOxidizer was my first non-toy Rust project. And the quality of the Rust
code I produced in early versions of PyOxidizer clearly showed it. And when I
was in the rapid-prototyping phase of PyOxidizer, I eschewed writing tests
in favor of short-term progress.</p>
<p>PyOxidizer 0.8 pays down a ton of technical debt in the code base. Lots of
Rust code has been refactored and is using somewhat reasonable practices.
I'm not yet a Rust guru. But I'm at the point where I cringe when I look at
some of the early code I wrote, which is a good sign. I do have to say that
Rust has been a dream to work with during this transition. Despite being a
low-level language, my early <em>misuse</em> of Rust did not result in crashes like
you would see in languages like C/C++. And Rust's seemingly omniscient compiler
and IDE tools facilitating refactoring have ensured that code changes aren't
accompanied by subtle random bugs that would occur in dynamic programming
languages. I really need to write a dedicated post espousing the virtues of
Rust...</p>
<p>There are a <strong>ton</strong> of new tests in PyOxidizer 0.8 and I now feel somewhat
confident that the <code>main</code> branch of PyOxidizer should be considered
<em>production-ready</em> at any time assuming the tests pass. This will hopefully
lead to more rapid releases in the future.</p>
<p>There are now tests for the <code>pyembed</code> Rust crate, which provides the
run-time code for PyOxidizer-built binaries. We even have
<a href="https://github.com/indygreg/PyOxidizer/tree/main/pyembed/src/test">Python-based unit tests</a>
for validating the Python-exposed APIs behave as expected. These tests have
been invaluable for ensuring that the run-time code works as expected. So now
when someone files a bug I can easily write a test to capture it and keep
the code working as intended through various refactors.</p>
<p>The packaging-time Rust code has also gained its fair share of tests.
We now have fairly comprehensive test coverage around how resources
are added/packaged. Python extension modules have proved to be highly
nuanced in how they are handled. Tremendously helping testing of extension
modules is that we're able to run tests for platform non-native extensions!
While not yet exposed/supported by Starlark configuration files, <strong>I've taught
PyOxidizer's core Rust code to be cross-compiling aware</strong> so that we can
e.g. test Windows or macOS behavior from Linux. Before, I'd have to test
Windows wheel handling on Windows. But after writing a wheel parser in Rust
and teaching PyOxidizer to use a different Python distribution for the
host architecture from the target architecture, I'm now able to write
tests for platform-specific functionality that run on any platform that
PyOxidizer can run on. This <em>may</em> eventually lead to proper cross-compiling
support (at least in some configuration). Time will tell. But the foundation
is definitely there!</p>
<h2>New Rust Crates</h2>
<p>As part of the aforementioned refactoring of PyOxidizer's Rust code, I've
been extracting some useful/generic functionality built as part of
developing PyOxidizer to their own Rust crates.</p>
<p>As part of this release, I'm publishing the initial 0.1 release of the
<a href="https://crates.io/crates/python-packaging">python-packaging</a> crate
(<a href="https://docs.rs/python-packaging/0.1.0/python_packaging/">docs</a>). This crate
provides pure Rust code for various Python <em>packaging</em> related functionality.
This includes:</p>
<ul>
<li>Rust types representing Python resource types (source modules, bytecode
  modules, extension modules, package resources, etc).</li>
<li>Scanning the filesystem for Python resource files .</li>
<li>Configuring an embedded Python interpreter.</li>
<li>Parsing <code>PKG-INFO</code> and related files.</li>
<li>Parsing wheel files.</li>
<li>Collecting Python resources and serializing them to a data structure.</li>
</ul>
<p>The crate is somewhat PyOxidizer centric. But if others are interested
in improving its utility, I'll happily accept pull requests!</p>
<p>PyOxidizer's crates footprint now includes:</p>
<ul>
<li><a href="https://crates.io/crates/python-packed-resources">python-packed-resources</a></li>
<li><a href="https://crates.io/crates/python-packaging">python-packaging</a></li>
<li><a href="https://crates.io/crates/pyembed">pyembed</a></li>
<li><a href="https://crates.io/crates/pyoxidizer">pyoxidizer</a></li>
</ul>
<h2>Major Documentation Updates</h2>
<p>I strongly believe that software should be documented thoroughly and I strive
for PyOxidizer's documentation to be useful and comprehensive.</p>
<p>There have been a lot of changes to PyOxidizer's documentation since the
0.7 release.</p>
<p>All <a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/config.html">configuration file documentation</a>
has been consolidated.</p>
<p>Likewise, I've attempted to consolidate a lot of the <em>paved road</em> documentation
for how to use PyOxidizer in the
<a href="https://pyoxidizer.readthedocs.io/en/v0.8.0/packaging.html">Packaging User Guide</a>
section of the docs.</p>
<p>I'll be honest, since I have so much of PyOxidizer's workings internalized,
it can be difficult for me to empathize with PyOxidizer's users. So if you
have difficult with the <em>readability</em> of the documentation, please
<a href="https://github.com/indygreg/PyOxidizer/issues/new">file an issue</a> and report
what is confusing so the documentation can be improved!</p>
<h2>Mercurial Shipping With PyOxidizer 0.8</h2>
<p>PyOxidizer is arguably an epic yak shave of mine to help the
<a href="https://www.mercurial-scm.org/">Mercurial version control tool</a> transition
to Python 3 and Rust.</p>
<p>I'm pleased to report that Mercurial is
<a href="https://www.mercurial-scm.org/pipermail/mercurial/2020-October/052395.html">now shipping</a>
PyOxidizer-built distributions on Windows as of the 5.2.2 release a few days
ago! If a complex Python application like Mercurial can be
<a href="https://www.mercurial-scm.org/repo/hg/file/0627cd03b1e9/rust/hgcli/pyoxidizer.bzl">configured</a>
to work with PyOxidizer, chances are your Python application will work as
well.</p>
<h2>Whats Next</h2>
<p>I view PyOxidizer 0.8 as a pivotal release where PyOxidizer is turning the
corner from a prototyping science experiment to something more generally
usable. The investments in test coverage and refactoring of the Rust
internals are paving the way towards future features and bug fixes.</p>
<p>In upcoming releases, I'd like to close remaining known compatibility
gaps with popular Python packages (such as <em>numpy</em> and other packages in
the <em>scientific/data</em> space). I have a general idea of what work needs to
be done and I've been laying the ground work via various refactorings to
execute here.</p>
<p><strong>I want a general theme of future releases to be eliminating reasons why
people can't use PyOxidizer.</strong> PyOxidizer's historical origin was as a
science experiment to see if single file Python applications were possible.
It is clear that achieving this is fundamentally incompatible with
compatibility with tons of Python packages in the wild. I'd like to find a
way where PyOxidizer can achieve 99% package compatibility by default
so new users don't get discouraged when using PyOxidizer. And for the
subset of users who want single file executables, they can spend the
magnitude of additional effort to achieve that.</p>
<p>At some point, I also want to make a pivot towards focusing on producing
distributable artifacts (Debian/RPM packages, MSI installers, macOS DMG
files, etc). I'm slightly bummed that I haven't made much progress here.
But I have a vision in my mind of where I want to go (I'll be making
a standalone Rust crate + Starlark dialect to facilitate producing
distributable artifacts for <em>any</em> application) and I'm anticipating
starting this work in the next few months. In the mean time, PyOxidizer
0.8 should be able to give people a directory tree that they can coerce
into distributable artifacts using existing packaging tooling. That's not as
turnkey as I would like it to be. But the technical problems around
building a distributable Python application binary still needs some work
and I view that as the most pressing need for the Python ecosystem. So
I'll continue to focus there so there is a solid foundation to build upon.</p>
<p>In conclusion, I hope you enjoy the new release! Please report any issues
or feedback in the
<a href="https://github.com/indygreg/PyOxidizer/issues/new">GitHub issue tracker</a>.</p>

  </div>
</div>



  <hr class="interblog" />
 <a href="/blog/category/python/2">Next Page </a>

              </div>
              
          <div id="sidebar">
          <ul>
            <li>
              <h2>Categories</h2>
              <ul>
                <li><a href="/blog/category/apple">Apple</a></li>
                <li><a href="/blog/category/bugzilla">Bugzilla</a></li>
                <li><a href="/blog/category/ci">CI</a></li>
                <li><a href="/blog/category/clang">Clang</a></li>
                <li><a href="/blog/category/docker">Docker</a></li>
                <li><a href="/blog/category/firefox">Firefox</a></li>
                <li><a href="/blog/category/git">Git</a></li>
                <li><a href="/blog/category/javascript">JavaScript</a></li>
                <li><a href="/blog/category/mercurial">Mercurial</a></li>
                <li><a href="/blog/category/mozreview">MozReview</a></li>
                <li><a href="/blog/category/mozilla">Mozilla</a></li>
                <li><a href="/blog/category/personal">Personal</a></li>
                <li><a href="/blog/category/programming">Programming</a></li>
                <li><a href="/blog/category/puppet">Puppet</a></li>
                <li><a href="/blog/category/pyoxidizer">PyOxidizer</a></li>
                <li><a href="/blog/category/python">Python</a></li>
                <li><a href="/blog/category/review-board">Review Board</a></li>
                <li><a href="/blog/category/rust">Rust</a></li>
                <li><a href="/blog/category/sync">Sync</a></li>
                <li><a href="/blog/category/browsers">browsers</a></li>
                <li><a href="/blog/category/build-system">build system</a></li>
                <li><a href="/blog/category/code-review">code review</a></li>
                <li><a href="/blog/category/compilers">compilers</a></li>
                <li><a href="/blog/category/internet">internet</a></li>
                <li><a href="/blog/category/logging">logging</a></li>
                <li><a href="/blog/category/mach">mach</a></li>
                <li><a href="/blog/category/make">make</a></li>
                <li><a href="/blog/category/misc">misc</a></li>
                <li><a href="/blog/category/movies">movies</a></li>
                <li><a href="/blog/category/packaging">packaging</a></li>
                <li><a href="/blog/category/pymake">pymake</a></li>
                <li><a href="/blog/category/security">security</a></li>
                <li><a href="/blog/category/sysadmin">sysadmin</a></li>
                <li><a href="/blog/category/testing">testing</a></li>
              </ul>
            </li>
          </ul>
        </div>



              <div style="clear: both;">&nbsp;</div>
          </div>
        </div>
      </div>
      <div id="footer">
        
  <hr/>
  <p>Copyright (c) 2012- Gregory Szorc. All rights reserved. Design by <a href="http://www.freecsstemplates.org/"> CSS Templates</a>.</p>


      </div>
    </div>
  </body>
</html>





