


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Pollinating  
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20101114

-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>Gregory Szorc's Digital Home
</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom" />
<link rel="stylesheet" href="/style/style.css" type="text/css" />
<link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />


  </head>
  <body>
    <div id="wrapper">
      
  <div id="menu">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/notes">Notes</a></li>
    <li><a href="/work.html">Work</a></li>
    <li><a href="/skills.html">Skills</a></li>
    <li><a href="/thoughts.html">Thoughts</a></li>
    <li><a href="/resume.pdf">Resume</a></li>
  </ul>
</div>


      <div id="page">
        <div id="page-bgtop">
          <div id="page-bgbtm">
              <div id="content">
                
  
<div class="blog_post">
  <a name="mercurial-pushlog-is-now-robust-against-interrupts"></a>
  <h2 class="blog_post_title"><a href="/blog/2014/12/30/mercurial-pushlog-is-now-robust-against-interrupts" rel="bookmark" title="Permanent Link to Mercurial Pushlog Is Now Robust Against Interrupts">Mercurial Pushlog Is Now Robust Against Interrupts</a></h2>
  <small>December 30, 2014 at 12:25 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>
 | <a href="http://gregoryszorc.com/blog/2014/12/30/mercurial-pushlog-is-now-robust-against-interrupts#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p><a href="https://hg.mozilla.org">hg.mozilla.org</a> - Mozilla's Mercurial server -
has functionality called the <a href="https://mozilla-version-control-tools.readthedocs.org/en/latest/hgmo/pushlog.html">pushlog</a>
which records who pushed what when. Essentially, it's a log of when
a repository was changed. This is separate from the commit log because
the commit log can be spoofed and the commit log doesn't record when
commits were actually pushed.</p>
<p>Since its inception, the pushlog has suffered from data consistency
issues. If you aborted the push at a certain time, data was not inserted
in the pushlog. If you aborted the push at another time, data existed in
the pushlog but not in the repository (the repository would get rolled
back but the pushlog data wouldn't).</p>
<p><strong>I'm pleased to announce that the pushlog is now robust against
interruptions and its updates are consistent with what is recorded by
Mercurial.</strong> The pushlog database commit/rollback is tied to Mercurial's
own transaction API. What Mercurial does to the push transaction, the
pushlog follows.</p>
<p>This former inconsistency has caused numerous problems over the years.
When data was inconsistent, we often had to close trees until someone
could SSH into the machines and manually run SQL to fix the problems.
This also contributed to a culture of <em>don't press ctrl+c during push:
it could corrupt Mercurial.</em> (Ctrl+c should be safe to press any time: if
it isn't, there is a bug to be filed.)</p>
<p>Any time you remove a source of tree closures is a cause for celebration.
Please join me in celebrating your new freedom to abort pushes without
concern for data inconsistency.</p>
<p>In case you want to test things out, aborting pushes and (and rolling
back the pushlog) should now result in something like:</p>
<pre><code>pushing to ssh://hg.mozilla.org/mozilla-central
searching for changes
adding changesets
adding manifests
adding file changes
added 1 changesets with 1 changes to 1 files
Trying to insert into pushlog.
Inserted into the pushlog db successfully.
^C
rolling back pushlog
transaction abort!
rollback completed
</code></pre>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2014/12/30/mercurial-pushlog-is-now-robust-against-interrupts#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="using-docker-to-build-firefox"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/05/19/using-docker-to-build-firefox" rel="bookmark" title="Permanent Link to Using Docker to Build Firefox">Using Docker to Build Firefox</a></h2>
  <small>May 19, 2013 at 01:45 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>
 | <a href="http://gregoryszorc.com/blog/2013/05/19/using-docker-to-build-firefox#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>I have the privilege of having my desk located around a bunch of
really intelligent people from the Mozilla Services team. They've been
talking a lot about all the new technologies around server provisioning.
One that interested me is <a href="http://www.docker.io/">Docker</a>.</p>
<p>Docker is a pretty nifty piece of software. It's essentially a glorified
wrapper around <a href="http://lxc.sourceforge.net/">Linux Containers</a>. But,
calling it that is doing it an injustice.</p>
<p>Docker interests me because it allows simple environment isolation and
repeatability. I can create a run-time environment
once, package it up, then run it again on any other machine.
Furthermore, everything that runs in that environment is isolated from
the underlying host (much like a virtual machine). And best of all,
everything is fast and simple.</p>
<p>For my initial experimentation with Docker, I decided to create an
environment for building Firefox.</p>
<h2>Building Firefox with Docker</h2>
<p>To build Firefox with Docker, you'll first need to
<a href="http://www.docker.io/gettingstarted/">install</a> Docker. That's pretty
simple.</p>
<p>Then, it's just a matter of creating a new container with our build
environment:</p>
<div class="pygments_murphy"><pre><span></span>curl https://gist.github.com/indygreg/5608534/raw/30704c59364ce7a8c69a02ee7f1cfb23d1ffcb2c/Dockerfile <span class="p">|</span> docker build
</pre></div>

<p>The output will look something like:</p>
<div class="pygments_murphy"><pre><span></span>FROM ubuntu:12.10
MAINTAINER Gregory Szorc &quot;gps@mozilla.com&quot;
RUN apt-get update
===&gt; d2f4faba3834
RUN dpkg-divert --local --rename --add /sbin/initctl &amp;&amp; ln -s /bin/true /sbin/initctl
===&gt; aff37cc837d8
RUN apt-get install -y autoconf2.13 build-essential unzip yasm zip
===&gt; d0fc534feeee
RUN apt-get install -y libasound2-dev libcurl4-openssl-dev libdbus-1-dev libdbus-glib-1-dev libgtk2.0-dev libiw-dev libnotify-dev libxt-dev mesa-common-dev uuid-dev
===&gt; 7c14cf7af304
RUN apt-get install -y binutils-gold
===&gt; 772002841449
RUN apt-get install -y bash-completion curl emacs git man-db python-dev python-pip vim
===&gt; 213b117b0ff2
RUN pip install mercurial
===&gt; d3987051be44
RUN useradd -m firefox
===&gt; ce05a44dc17e
Build finished. image id: ce05a44dc17e
ce05a44dc17e
</pre></div>

<p>As you can see, it is essentially <em>bootstrapping</em> an environment to
build Firefox.</p>
<p>When this has completed, you can activate a shell in the container by
taking the image id printed at the end and running it:</p>
<div class="pygments_murphy"><pre><span></span>docker run -i -t ce05a44dc17e /bin/bash
<span class="c1"># You should now be inside the container as root.</span>
su - firefox
hg clone https://hg.mozilla.org/mozilla-central
<span class="nb">cd</span> mozilla-central
./mach build
</pre></div>

<p>If you want to package up this container for distribution, you just find
its ID then export it to a tar archive:</p>
<div class="pygments_murphy"><pre><span></span>docker ps -a
<span class="c1"># Find ID of container you wish to export.</span>
docker <span class="nb">export</span> 2f6e0edf64e8 &gt; image.tar
<span class="c1"># Distribute that file somewhere.</span>
docker import - &lt; image.tar
</pre></div>

<p>Simple, isn't it?</p>
<h2>Future use at Mozilla</h2>
<p>I think it would be rad if Release Engineering used Docker for managing
their Linux builder configurations. Want to develop against the exact
system configuration that Mozilla uses in its automation - you could do
that. No need to worry about custom apt repositories, downloading
custom toolchains, keeping everything isolated from the rest of your
system, etc: Docker does that all automatically. Mozilla simply needs to
publish Docker images on the Internet and anybody can come along and
reproduce the official environment with minimal effort. Once we do that,
there are few excuses for someone breaking Linux builds because of
an environment discrepancy.</p>
<p>Release Engineering could also use Docker to manage isolation of
environments between builds. For example, it could spin up a new
container for each build or test job. It could even save images from the
results of these jobs. Have a weird build failure like a segmentation
fault in the compiler? Publish the Docker image and have someone take a
look! No need to take the builder offline while someone SSH's into it.
No need to worry about the probing changing state because you can always
revert to the state at the time of the failure! And, builds would likely
start faster. As it stands, our automation <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=851294">spends minutes managing
packages</a> before
builds begin. This lag would largely be eliminated with Docker. If
nothing else, executing automation jobs inside a container would allow
us to extract accurate resource usage info (CPU, memory, I/O) since
the Linux kernel effectively gives containers their own namespace
independent of the global system's.</p>
<p>I might also explore publishing Docker images that construct an ideal
development environment (since getting recommended tools in the hands of
everybody is a hard problem).</p>
<p>Maybe I'll even consider hooking up build system glue to automatically
run builds inside containers.</p>
<p>Lots of potential here.</p>
<h2>Conclusion</h2>
<p>I encourage Linux users to play around with Docker. It enables some
new and exciting workflows and is a really powerful tool despite its
simplicity. So far, the only major faults I have with it are that the
docs say it should not be used in production (yet) and it only works on
Linux.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/05/19/using-docker-to-build-firefox#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="mozilla-build-system-brain-dump"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/05/13/mozilla-build-system-brain-dump" rel="bookmark" title="Permanent Link to Mozilla Build System Brain Dump">Mozilla Build System Brain Dump</a></h2>
  <small>May 13, 2013 at 05:25 PM | categories: 

<a href='/blog/category/build-system'>build system</a>, <a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>, <a href='/blog/category/mach'>mach</a>
 | <a href="http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>I hold a lot of context in my head when it comes to the future of
Mozilla's build system and the interaction with it. I wanted to
perform a brain dump of sorts so people have an idea of where I'm
coming from when I inevitably propose radical changes.</p>
<h2>The sad state of build system interaction and the history of mach</h2>
<p>I believe that Mozilla's build system has had a poor developer
experience for as long as there has been a Mozilla build system.
Getting started with Firefox development was a rite of passage. It
required following (often out-of-date) directions on MDN. It
required finding pages through MDN search or asking other people
for info over IRC. It was the kind of process that turned away
potential contributors because it was just too damn hard.</p>
<p>mach - while born out of my initial efforts to radically change
the build system proper - morphed into a generic command
dispatching framework by the time it landed in mozilla-central.
It has one overarching purpose: provide a single gateway point for
performing common developer tasks (such as building the tree and
running tests). The concept was nothing new - individual developers
had long coded up scripts and tools to streamline workflows. Some
even published these for others to use. What set mach apart was a
unified interface for these <em>commands</em> (the mach script in the
top directory of a checkout) and that these productivity gains
were <strong>in the tree</strong> and thus easily discoverable and usable by
<em>everybody</em> without significant effort (just run <em>mach help</em>).</p>
<p>While mach doesn't yet satisfy everyone's needs, it's slowly
growing new features and making developers' lives easier with
every one. All of this is happening despite that there
is not a single person tasked with working on mach full time.
Until a few months ago, mach was largely my work. Recently, Matt
Brubeck has been contributing a flurry of enhancements - thanks
Matt! Ehsan Akhgari and Nicholas Alexander have contributed a
few commands as well! There are also a few people with a single
command to their name. This is fulfilling my original vision of
facilitating developers to scratch their own itches by
contributing mach commands.</p>
<p>I've noticed more people referencing mach in IRC channels. And,
more people get angry when a mach command breaks or changes
behavior. So, I consider the mach experiment a success. Is it
perfect, no. If it's not good enough for you, please file a bug
and/or code up a patch. If nothing else, please tell me: I love to
know about everyone's subtle requirements so I can keep them in
mind when refactoring the build system and hacking on mach.</p>
<h2>The object directory is a black box</h2>
<p>One of the ideas I'm trying to advance is that the object directory
should be considered a black box for the majority of developers. In
my ideal world, developers don't need to look inside the object
directory. Instead, they interact with it through condoned and
supported tools (like mach).</p>
<p>I say this for a few reasons. First, as the build config module owner
I would like the ability to massively refactor the <em>internals</em> of
the object directory without disrupting workflows. If people are
interacting directly with the object directory, I get significant
push back if things change. This inevitably holds back much-needed
improvements and triggers resentment towards me, build peers, and
the build system. Not a good situation. Whereas if people are
indirectly interacting with the object directory, we simply need to
maintain a consistent interface (like mach) and nobody should care
if things change.</p>
<p>Second, I believe that the methods used when directly interacting
with the object directory are often sub-par compared with going
through a more intelligent tool and that productivity suffers as a
result. For example, when you type <em>make</em> in inside the object
directory you need to know to pass <em>-j8</em>, use make vs pymake,
and that you also need to build <em>toolkit/library</em>, etc.
Also, by invoking make directly, you bypass other handy features,
such as automatic compiler warning aggregation (which only happens
if you invoke the build system through mach). If you go through a
tool like <em>mach</em>, you <em>should</em> automatically get the most ideal
experience possible.</p>
<p>In order for this vision to be realized, we need massive
improvements to tools like mach to cover the missing workflows that
still require direct object directory interaction. We also need people
to start using mach. I think increased mach usage comes after mach
has established itself as obviously superior to the alternatives
(I already believe it offers this for tasks like running tests).</p>
<h2>I don't want to force mach upon people but...</h2>
<p>Nobody likes when they are forced to change a process that has been
familiar for years. Developers especially. I get it. That's why
I've always attempted to position mach as an alternative to
existing workflows. If you don't like mach, you can always fall
back to the previous workflow. Or, you can improve mach (patches
more than welcome!). Having gone down the
please-use-this-tool-it's-better road before at other
organizations, I strongly believe that the best method to incur
adoption of a new tool is to gradually sway people through
obvious superiority and praise (as opposed to a mandate to switch).
I've been trying this approach with mach.</p>
<p>Lately, more and more people have been saying things like
<em>we should have the build infrastructure build through mach
instead of client.mk</em> and <em>why do we need testsuite-targets.mk when
we have mach commands.</em> While I personally feel that client.mk
and testsuite-targets.mk are antiquated as a developer-facing
interface compared to mach, I'm reluctant to eliminate them because
I don't like forcing change on others. That being said, there are
compelling reasons to eliminate or at least refactor how they work.</p>
<p>Let's take <em>testsuite-targets.mk</em> as an example. This is the make
file that provides the targets to run tests (like <em>make xpcshell-test</em>
and <em>make mochitest-browser-chrome</em>). What's interesting about this
file is that it's only used in local builds: our automation
infrastructure does not use <em>testsuite-targets.mk</em>! Instead,
<em>mozharness</em> and the old buildbot configs manually build up the
command used to invoke the test harnesses. Initially, the mach
commands for running tests simply invoked make targets defined
in <em>testsuite-targets.mk</em>. Lately, we've been converting the mach
commands to invoke the Python test runners directly. I'd argue that
the logic for <em>invoke the test runner</em> only needs to live in one
place in the tree. Furthermore as a build module peer, I have little
desire to support multiple implementations. Especially considering
how fragile they can be.</p>
<p>I think we're trending towards an outcome where mach (or the code
behind mach commands) transitions into the authoratitive invocation
method and <em>legacy</em> interfaces like <em>client.mk</em> and
<em>testsuite-targets.mk</em> are reimplemented to either call mach
commands or the same routine that powers them. Hopefully this
will be completely transparent to developers.</p>
<h2>The future of mozconfigs and environment configuration</h2>
<p><em>mozconfig</em> files are shell scripts used to define variables consumed
by the build system. They are the only officially supported mechanism
for configuring how the build system works.</p>
<p>I'd argue mozconfig files are a mediocre solution at best. First,
there's the issue of mozconfig statements that don't actually do
anything. I've seen no-op mozconfig content cargo culted into the
in-tree mozconfigs (used for the builder configurations)! Oops.
Second, doing things in mozconfig files is just awkward. Defining
the object directory requires <em>mk_add_options MOZ_OBJDIR=some-path</em>.
What's <em>mk_add_options</em>? If <em>some-path</em> is relative, what is it
relative <em>to</em>? While certainly addressable, the documentation on
how mozconfig files work is not terrific and fails to explain many
pitfalls. Even with proper documentation, there's still the issue
of the file format allowing no-op variable assignments to persist.</p>
<p>I'm very tempted to reinvent build configuration as something not
mozconfigs. What exactly, I don't know. mach has support for ini-like
configuration files. We could certainly have mach and the build
system pull configs from the same file.</p>
<p>I'm not sure what's going to happen here. But deprecating mozconfig
files as they are today is part of many of the options.</p>
<h2>Handling multiple mozconfig files</h2>
<p>A lot of developers only have a single mozconfig file (per source tree
at least). For these developers, life is easy. You simply install
your mozconfig in one of the default locations and it's automagically
used when you use mach or client.mk. Easy peasy.</p>
<p>I'm not sure what the relative numbers are, but many developers
maintain multiple mozconfig files per source tree. e.g. they'll
have one mozconfig to build desktop Firefox and another one for
Android. They may have debug variations of each.</p>
<p>Some developers even have a single mozconfig file but leverage the
fact that mozconfig files are shell scripts and have their
mozconfig dynamically do things depending on the current working
directory, value of an environment variable, etc.</p>
<p>I've also seen wrapper scripts that glorify setting environment
variables, changing directory, etc and invoke a command.</p>
<p>I've been thinking a lot about providing a common and well-supported
solution for switching between active build configurations.
<a href="https://developer.mozilla.org/en-US/docs/Developer_Guide/mach#Adding_mach_to_your_shell%27s_search_path">Installing mach on $PATH</a>
goes a long way to facilitate this. If you are in an object
directory, the mozconfig used when that object directory was
created is automatically applied. Simple enough. However, I want
people to start treating object directories as black boxes. So, I'd
rather not see people have their shell inside the object directory.</p>
<p>Whenever I think about solutions, I keep arriving at a
virtualenv-like solution. Developers would potentially need to
<em>activate</em> a Mozilla build environment (similar to how Windows
developers need to launch MozillaBuild). Inside this environment,
the shell prompt would contain the name of the current build
configuration. Users could switch between configurations using
<em>mach switch</em> or some other magic command on the $PATH.</p>
<p>Truth be told, I'm skeptical if people would find this useful. I'm
not sure it's that much better than exporting the MOZCONFIG
environment variable to define the active config. This one requires
more thought.</p>
<h2>The integration between the build environment and Python</h2>
<p>We use Python extensively in the build system and for common
developer tasks. mach is written in Python. moz.build processing
is implemented in Python. Most of the test harnesses are written in
Python.</p>
<p>Doing practically anything in the tree requires a Python
interpreter that knows about all the Python code in the tree and
how to load it.</p>
<p>Currently, we have two very similar Python environments. One is
a virtualenv created while running configure at the beginning of
a build. The other is essentially a cheap knock-off that mach
creates when it is launched.</p>
<p>At some point I'd like to consolidate these Python environments.
From any Python process we should have a way to automatically
bootstrap/activate into a well-defined Python environment. This
certainly sounds like establishing a unified Python virtualenv
used by both the build system and mach.</p>
<p>Unfortunately, things aren't straightforward. The virtualenv today
is constructed in the object directory. How do we determine the
current object directory? By loading the mozconfig file. How do we
do that? Well, if you are mach, we use Python. And, how does mach
know where to find the code to load the mozconfig file? You can
see the dilemma here.</p>
<p>A related issue is that of portable build environments. Currently, a
lot of our automation recreates the build system's virtualenv from
its own configuration (not that from the source tree). This has
and will continue to bite us. We'd <em>really</em> like to package up the
virtualenv (or at least its config) with tests so there is no
potential for discrepancy.</p>
<p>The inner workings of how we integrate with Python should be
invisible to most developers. But, I figured I'd capture it
here because it's an annoying problem. And, it's also related
to an <em>activated</em> build environment. What if we required all
developers to <em>activate</em> their shell with a Mozilla build
environment (like we do on Windows)? Not only would this solve
Python issues, but it would also facilitate simpler config
switching (outlined above). Hmmm...</p>
<h2>Direct interaction with the build system considered harmful</h2>
<p>Ever since there was a build system developers have been typing
<em>make</em> (or <em>make.py</em>) to build the tree. One of the goals of the
transition to <em>moz.build</em> files is to facilitate building the tree
with Tup. <em>make</em> will do nothing when you're not using Makefiles!
Another goal of the <em>moz.build</em> transition is to start
derecursifying the make build system such that we build things in
parallel. It's likely we'll produce monolithic make files and then
process <em>all</em> targets for a related class <em>IDLs</em>, <em>C++ compilation</em>,
etc in one invocation of <em>make</em>. So, uh, what happens during a partial
tree build? If a .cpp file from <em>/dom/src/storage</em> is being handled by
a monolithic make file invoked by the Makefile at the top of the
tree, how does a partial tree build pick that up? Does it build just
that target or every target in the monolithic/non-recursive make file?</p>
<p>Unless the build peers go out of our way to install redundant targets
in leaf Makefiles, directly invoking <em>make</em> from a subdirectory of
the tree won't do what it's done for years.</p>
<p>As I said above, I'm sympathetic to forced changes in procedure, so
it's likely we'll provide backwards-compatibile behavior. But, I'd
prefer to not do it. I'd first prefer partial-tree builds are not
necessary and a full tree build finishes quickly. But, we're not going
to get there for a bit. As an alternative, I'll take people building
through <em>mach build</em>. That way, we have an easily extensible interface
on which to build partial tree logic. We saw this recently when
dumbmake/smartmake landed. And, going through <em>mach</em> also reinforces my
ideal that the object directory is a black box.</p>
<h2>Semi-persistent state</h2>
<p>Currently, most state as it pertains to a checkout or build is in the
object directory. This is fine for artifacts from the build system.
However, there is a whole class of state that arguably shouldn't be in
the object directory. Specifically, it shouldn't be clobbered when you
rebuild. This includes logs from previous builds, the warnings database,
previously failing tests, etc. The list is only going to grow over time.</p>
<p>I'd like to establish a location for semi-persistant state related to
the tree and builds. Perhaps we change the clobber logic to ignore a
specific directory. Perhaps we start storing things in the user's home
directory. Perhaps we could establish a second <em>object directory</em> named
the <em>state directory</em>? How would this interact with <em>build environments</em>?</p>
<p>This will probably sit on the backburner until there is a compelling use
case for it.</p>
<h2>The battle against C++</h2>
<p>Compiling C++ consumes the bulk of our build time. Anything we can do to
speed up C++ compilation will work wonders for our build times.</p>
<p>I'm optimistic things like precompiled headers and compiling multiple
.cpp files with a single process invocation will drastically decrease
build times. However, no matter how much work we put in to make C++
compilation faster, we still have a giant issue: dependency hell.</p>
<p>As <a href="/presentations/2012-11-29-firefox-build-system/#34">shown</a> in my
build system presentation a few months back, we have dozens of header
files included by hundreds if not thousands of C++ files. If you change
one file: you invalidate build dependencies and trigger a rebuild. This
is why whenever files like mozilla-config.h change you are essentially
confronted with a full rebuild. ccache may help if you are lucky. But, I
fear that as long as headers proliferate the way they do, there is
little the build system by itself can do.</p>
<p>My attitude towards this is to wait and see what we can get out of
precompiled headers and the like. Maybe that makes it good enough. If
not, I'll likely be making a lot of noise at Platform meetings
requesting that C++ gurus brainstorm on a solution for reducing
header proliferation.</p>
<h2>Conclusion</h2>
<p>Belive it or not, these are only some of the topics floating around in
my head! But I've probably managed to bore everyone enough so I'll
call it a day.</p>
<p>I'm always interested in opinions and ideas, especially if they are
different from mine. I encourage you to leave a comment if you have
something to say.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/05/13/mozilla-build-system-brain-dump#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="bulk-analysis-of-mozilla's-build-and-test-data"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/04/01/bulk-analysis-of-mozilla's-build-and-test-data" rel="bookmark" title="Permanent Link to Bulk Analysis of Mozilla's Build and Test Data">Bulk Analysis of Mozilla's Build and Test Data</a></h2>
  <small>April 01, 2013 at 01:12 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>
 | <a href="http://gregoryszorc.com/blog/2013/04/01/bulk-analysis-of-mozilla's-build-and-test-data#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>When you push code changes to Firefox and other similar Mozilla
projects, a flood of automated jobs is triggered on Mozilla's
infrastructure. It works like any other continuous integration
system. First you build, then you run tests, etc. What sets it
apart from other continuous integration systems is the size:
Mozilla runs thousands of jobs per week and the combined output
sums into the tens of gigabytes.</p>
<p>Most of the data from Mozilla's continuous integration is
available on public servers, notably ftp.mozilla.org. This includes
compiled binaries, logs, etc.</p>
<p>While there are tools that can sift through this mountain of data
(like <a href="https://tbpl.mozilla.org">TBPL</a>), they don't allow ad-hoc
queries over the raw data. Furthermore, these tools are very
function-specific and there are many data views they don't expose.
This <em>missing</em> data has always bothered me because, well, there
are cool and useful things I'd like to do with this data.</p>
<p>This itch has been bothering me for well over a year. The
persistent burning sensation coupled with rain over the weekend
caused me to scratch it.</p>
<p>The <a href="https://github.com/indygreg/mozilla-build-analyzer">product of my weekend labor</a>
is a system facilitating bulk storage and analysis of Mozilla's
build data. While it's currently very alpha, it's already showing
promise for more throrough data analysis.</p>
<p>Essentially, the tool works by collecting the dumps of all the jobs
executed on Mozilla's infrastructure. It can optionally supplement
this with the raw logs from those jobs. Then, it combs through this
data, extracts useful bits, and stores them. Once the initial
fetching has completed, you simply need to re-"parse" the data set
into useful data. And, since all data is stored locally, the
performance of this is not bound by Internet bandwidth. In practice,
this means that you can obtain a new metric faster than would have
been required before. The downside is you will likely be storing
gigabytes of raw data locally. But, disks are cheap. And, you have
control over what gets pulled in, so you can limit it to what you
need.</p>
<p>Please note the project is very alpha and is only currently serving
my personal interests. However, I know there is talk about <em>TBPL2</em>
and what I have built could evolve into the data store for the next
generation TBPL tool. Also, most of the work so far has centered on
data import. There is tons of analysis code waiting to be written.</p>
<p>If you are interested in improving the tool, please file a GitHub
pull request.</p>
<p>I hope to soon blog about useful information I've obtained through this
tool.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/04/01/bulk-analysis-of-mozilla's-build-and-test-data#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  
<div class="blog_post">
  <a name="omnipresent-mach"></a>
  <h2 class="blog_post_title"><a href="/blog/2013/03/03/omnipresent-mach" rel="bookmark" title="Permanent Link to Omnipresent mach">Omnipresent mach</a></h2>
  <small>March 03, 2013 at 12:30 PM | categories: 

<a href='/blog/category/mozilla'>Mozilla</a>, <a href='/blog/category/firefox'>Firefox</a>, <a href='/blog/category/mach'>mach</a>
 | <a href="http://gregoryszorc.com/blog/2013/03/03/omnipresent-mach#disqus_thread">View Comments</a>
</small><p/>
  <div class="post_prose">
    
  <p>Matt Brubeck recently landed an awesome patch for mach in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=840588">bug 840588</a>:
it allows mach to be used by any directory. I'm calling it
<em>omnipresent mach</em>.</p>
<p>Essentially, Matt changed the <em>mach</em> driver (the script in the root
directory of mozilla-central) so instead of having it look in hard-coded
relative paths for all its code, it walks up the directory tree and
looks for signs of the source tree or the object directory.</p>
<p>What this all means is that if you have the <em>mach</em> script installed in
your $PATH and you just type <em>mach</em> in your shell from within any source
directory or object directory, <em>mach</em> should just work. So, no more
typing <em>./mach</em>: just copy <em>mach</em> to <em>~/bin</em>, <em>/usr/local/bin</em> or some
other directory on your $PATH and you should just be able to type
<em>mach</em>.</p>
<p>Unfortunately, there are bound to be bugs here. Since <em>mach</em>
traditionally was only executed with the current working directory as
the top source directory, some commands are not prepared to handle a
variable current working directory. Some commands will likely get
confused when it comes resolving relative paths, etc. If you find
an issue, please report it! A temporary workaround is to just invoke
mach from the top source directory like you've always been doing.</p>
<p>If you enjoy the feature, thank Matt: this was completely his idea and
he saw it through from conception to implementation.</p>

  </div>
</div>



  <div class="after_post"><a href="http://gregoryszorc.com/blog/2013/03/03/omnipresent-mach#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="/blog/category/firefox/2">Next Page Â»</a>

              </div>
              
          <div id="sidebar">
          <ul>
            <li>
              <h2>Categories</h2>
              <ul>
                <li><a href="/blog/category/apple">Apple</a></li>
                <li><a href="/blog/category/bugzilla">Bugzilla</a></li>
                <li><a href="/blog/category/clang">Clang</a></li>
                <li><a href="/blog/category/docker">Docker</a></li>
                <li><a href="/blog/category/firefox">Firefox</a></li>
                <li><a href="/blog/category/git">Git</a></li>
                <li><a href="/blog/category/javascript">JavaScript</a></li>
                <li><a href="/blog/category/mercurial">Mercurial</a></li>
                <li><a href="/blog/category/mozreview">MozReview</a></li>
                <li><a href="/blog/category/mozilla">Mozilla</a></li>
                <li><a href="/blog/category/puppet">Puppet</a></li>
                <li><a href="/blog/category/python">Python</a></li>
                <li><a href="/blog/category/review-board">Review Board</a></li>
                <li><a href="/blog/category/sync">Sync</a></li>
                <li><a href="/blog/category/browsers">browsers</a></li>
                <li><a href="/blog/category/build-system">build system</a></li>
                <li><a href="/blog/category/code-review">code review</a></li>
                <li><a href="/blog/category/compilers">compilers</a></li>
                <li><a href="/blog/category/internet">internet</a></li>
                <li><a href="/blog/category/logging">logging</a></li>
                <li><a href="/blog/category/mach">mach</a></li>
                <li><a href="/blog/category/make">make</a></li>
                <li><a href="/blog/category/misc">misc</a></li>
                <li><a href="/blog/category/movies">movies</a></li>
                <li><a href="/blog/category/pymake">pymake</a></li>
                <li><a href="/blog/category/security">security</a></li>
                <li><a href="/blog/category/sysadmin">sysadmin</a></li>
                <li><a href="/blog/category/testing">testing</a></li>
              </ul>
            </li>
          </ul>
        </div>



              <div style="clear: both;">&nbsp;</div>
          </div>
        </div>
      </div>
      <div id="footer">
        
  <hr/>
  <p>Copyright (c) 2017 Gregory Szorc. All rights reserved. Design by <a href="http://www.freecsstemplates.org/"> CSS Templates</a>.</p>


      </div>
    </div>
  </body>
</html>





